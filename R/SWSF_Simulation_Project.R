
#' List of objects to export which are required by simulate_SOILWAT2_experiment and are
#'  not in rSWSF (sorted alphabetically)
#' @export
global_args_simulate_SOILWAT2_experiment <- function() {
  c("GISSM_species_No", "GISSM_params", "include_YN", "sw_input_treatments",
    "sw_input_treatments_use", "Index_RunInformation", "sw_input_prod",
    "sw_input_site", "sw_input_weather")
}

if (getRversion() >= "2.15.1")
  utils::globalVariables(global_args_simulate_SOILWAT2_experiment())



#' Setup infrastructure (skeleton) for a new rSWSF simulation experiment
#'
#' @param dir_prj A character string. The path to the new simulation project. Folders are
#'  recursively created if not already existing.
#' @param verbose A logical value.
#' @return Invisibly \code{dir_prj} on success
#'
#' @export
setup_rSWSF_project_infrastructure <- function(dir_prj, verbose = TRUE) {

  if (verbose) {
    t1 <- Sys.time()
    print(paste0("SWSF's ", shQuote(match.call()[1]), ": started at ", t1))
    print(paste("A new rSWSF project is prepared for:", sQuote(basename(dir_prj))))
  }

  if (verbose)

  dir_safe_create(dir_prj)

  # 'definf' object stored in R/sysdata.rda and generated by
  #   data-raw/prepare_default_project_infrastructure.R
  if (exists("definf") && length(definf) == 0)
    stop("'setup_rSWSF_project_infrastructure': no default project infrastructure ",
      "object located; the installation of the package 'rSWSF' may be faulty.")

  for (di in definf) {
    dtemp <- file.path(dir_prj, di[["path"]])

    if (!dir.exists(dtemp))
       dir_safe_create(dtemp)

    ftemp <- file.path(dtemp, di[["fname"]])

    if (file.exists(ftemp)) {
      print(paste("File", shQuote(ftemp), "already exists in project; it is not",
        "replaced by the default."))

    } else {
      writeLines(memDecompress(di[["data"]], type = "gzip", asChar = TRUE),
        con = file.path(dtemp, di[["fname"]]))
    }
  }

  if (verbose)
    print(paste("The new rSWSF project was successfully prepared at:", sQuote(dir_prj)))


  # Copy demo scripts
  temp <- system.file("demo", package = "rSWSF")

  ftemps <- list.files(temp, pattern = ".R", full.names = TRUE)
  if (length(ftemps) == 0)
    stop("'setup_rSWSF_project_infrastructure': no folder 'demo' found in package; ",
      "the installation of the package 'rSWSF' may be faulty.")

  for (f in ftemps)
    file.copy(from = f, to = file.path(dir_prj, basename(f)), overwrite = FALSE)

  if (verbose)
    print(paste0("SWSF's ", shQuote(match.call()[1]), ": ended after ",
      round(difftime(Sys.time(), t1, units = "secs"), 2), " s"))

  invisible(dir_prj)
}


#' Initialize a rSWSF project (setup description file)
#'
#' @param SWSF_prj_meta A list or environment as generated from a file comparable to
#'  \code{file.path(system.file("demo", package = "rSWSF"), "SWSF_project_descriptions.R")}
#' @return An updated version of \code{SWSF_prj_meta}
#'
#' @export
init_rSWSF_project <- function(SWSF_prj_meta, fmeta, verbose = TRUE) {
  if (verbose) {
    t1 <- Sys.time()
    print(paste0("SWSF's ", shQuote(match.call()[1]), ": started at ", t1))
  }

  #--- Delete objects from 'SWSF_prj_meta' which were used to create initial input
  try(rm(list = c("d", "dir_big", "dir_ex", "dir_in", "dir_out", "dir_prj", "endyr",
    "scorp", "startyr", "temp"), envir = SWSF_prj_meta), silent = TRUE)

  #--- Update project paths and file names
  dir_safe_create(SWSF_prj_meta[["project_paths"]])

  SWSF_prj_meta[["fnames_in"]][["fmeta"]] <- fmeta
  SWSF_prj_meta[["fnames_in"]] <- complete_with_defaultpaths(SWSF_prj_meta[["project_paths"]],
    SWSF_prj_meta[["fnames_in"]])

  init_timer(SWSF_prj_meta[["fnames_out"]][["timerfile"]])

  #--- Update simulation time
  SWSF_prj_meta[["sim_time"]] <- setup_simulation_time(SWSF_prj_meta[["sim_time"]],
    add_st2 = TRUE, adjust_NS = SWSF_prj_meta[["opt_agg"]][["adjust_NorthSouth"]])

  #--- Determine scenario names
  SWSF_prj_meta[["sim_scens"]] <- setup_scenarios(SWSF_prj_meta[["req_scens"]],
    SWSF_prj_meta[["sim_time"]][["future_yrs"]])

  #--- Prior calculations
  SWSF_prj_meta[["pcalcs"]] <- convert_to_todo_list(SWSF_prj_meta[["opt_input"]][["prior_calculations"]])

  #--- External data extraction
  SWSF_prj_meta[["exinfo"]] <- convert_to_todo_list(SWSF_prj_meta[["opt_input"]][["req_data"]])

  #--- Matrix to track progress with input preparations
  SWSF_prj_meta[["input_status"]] <- init_intracker()

  if (verbose)
    print(paste0("SWSF's ", shQuote(match.call()[1]), ": ended after ",
      round(difftime(Sys.time(), t1, units = "secs"), 2), " s"))

  SWSF_prj_meta
}



#' Populate rSWSF project with input data
#' @export
populate_rSWSF_project_with_data <- function(SWSF_prj_meta, opt_behave, opt_parallel,
  opt_chunks, opt_out_run, opt_verbosity) {

  if (opt_verbosity[["verbose"]]) {
    t1 <- Sys.time()
    print(paste0("SWSF's ", shQuote(match.call()[1]), ": started at ", t1))
  }
  on.exit({if (opt_verbosity[["verbose"]]) {
      print(paste0("SWSF's ", shQuote(match.call()[1]), ": ended after ",
        round(difftime(Sys.time(), t1, units = "secs"), 2), " s with tracker status:"))
      print(SWSF_prj_meta[["input_status"]])
    }}, add = TRUE)


  #--- Import data
  if (!exists("SWSF_prj_inputs") || is.null(SWSF_prj_inputs) ||
    todo_intracker(SWSF_prj_meta, "load_inputs", "prepared")) {

    SWSF_prj_inputs <- process_inputs(SWSF_prj_meta[["project_paths"]],
      SWSF_prj_meta[["fnames_in"]], use_preprocin = opt_behave[["use_preprocin"]],
      verbose = opt_verbosity[["verbose"]])

    SWSF_prj_meta[["input_status"]] <- update_intracker(SWSF_prj_meta[["input_status"]],
      tracker = "load_inputs", prepared = TRUE,
      checked = !SWSF_prj_inputs[["do_check_include"]],
      clean_subsequent = SWSF_prj_inputs[["do_check_include"]])
  }


  if (all(stats::na.exclude(SWSF_prj_meta[["input_status"]][, "prepared"])) &&
    exists("SWSF_prj_inputs")) {
    # Return if all is prepared (from a previous run) and input object exists and haven't
    # been changed since last time ('do_check_include' is FALSE)

    return(list(SWSF_prj_meta = SWSF_prj_meta, SWSF_prj_inputs = SWSF_prj_inputs))
  }

  # From here on: objects 'SWSF_prj_meta' and 'SWSF_prj_inputs' will be manipulated, i.e.,
  #   save them to disk upon exiting function (by error to save intermediate state) or
  #   by final 'return'
  on.exit(saveRDS(SWSF_prj_meta, file = SWSF_prj_meta[["fnames_in"]][["fmeta"]]),
    add = TRUE)
  on.exit(saveRDS(SWSF_prj_inputs, file = SWSF_prj_meta[["fnames_in"]][["fpreprocin"]]),
    add = TRUE)


  #--- Determine size of simulation runs
  if (todo_intracker(SWSF_prj_meta, "calc_size", "prepared")) {
    SWSF_prj_meta[["sim_size"]] <- determine_simulation_size(
      SWSF_prj_inputs[["SWRunInformation"]], SWSF_prj_inputs[["include_YN"]],
      SWSF_prj_inputs[["sw_input_experimentals"]], SWSF_prj_meta[["sim_scens"]])

    SWSF_prj_meta[["input_status"]] <- update_intracker(SWSF_prj_meta[["input_status"]],
      tracker = "calc_size", prepared = TRUE, clean_subsequent = TRUE)
  }


  #--- Spatial setup of simulations
  if (todo_intracker(SWSF_prj_meta, "spatial_setup", "prepared")) {
    use_sim_spatial <- actions[["check_inputs"]] ||
      (todo_intracker(SWSF_prj_meta, "soil_data", "prepared") &&
        (SWSF_prj_meta[["exinfo"]][["ExtractSoilDataFromCONUSSOILFromSTATSGO_USA"]] ||
        SWSF_prj_meta[["exinfo"]][["ExtractSoilDataFromISRICWISEv12_Global"]])) ||
      (todo_intracker(SWSF_prj_meta, "elev_data", "prepared") &&
        (SWSF_prj_meta[["exinfo"]][["ExtractElevation_NED_USA"]] ||
        SWSF_prj_meta[["exinfo"]][["ExtractElevation_HWSD_Global"]])) ||
      (todo_intracker(SWSF_prj_meta, "climnorm_data", "prepared") &&
        (SWSF_prj_meta[["exinfo"]][["ExtractSkyDataFromNOAAClimateAtlas_USA"]] ||
        SWSF_prj_meta[["exinfo"]][["ExtractSkyDataFromNCEPCFSR_Global"]]))

    SWSF_prj_meta[["sim_space"]] <- setup_spatial_simulation(SWSF_prj_inputs[["SWRunInformation"]],
      SWSF_prj_meta[["sim_space"]], SWSF_prj_meta[["sim_size"]],
      SWSF_prj_meta[["fnames_in"]][["fsimraster"]], use_sim_spatial)

    SWSF_prj_meta[["input_status"]] <- update_intracker(SWSF_prj_meta[["input_status"]],
      tracker = "spatial_setup", prepared = TRUE, clean_subsequent = TRUE)
  }


  #--- Setup/connect to dbWork
  if (todo_intracker(SWSF_prj_meta, "dbWork", "prepared")) {
    temp <- setup_dbWork(path = SWSF_prj_meta[["project_paths"]][["dir_out"]],
      sim_size = SWSF_prj_meta[["sim_size"]], include_YN = SWSF_prj_inputs[["include_YN"]],
      resume = opt_behave[["resume"]])

    if (!temp)
      stop("Work database failed to setup or an existing one is from a different",
        "simulation design")

    SWSF_prj_meta[["input_status"]] <- update_intracker(SWSF_prj_meta[["input_status"]],
      tracker = "dbWork", prepared = TRUE)
  }


  #------ DAILY WEATHER
  if (todo_intracker(SWSF_prj_meta, "dbW_paths", "prepared")) {
    SWSF_prj_meta <- set_paths_to_dailyweather_datasources(SWSF_prj_meta)

    SWSF_prj_meta[["input_status"]] <- update_intracker(SWSF_prj_meta[["input_status"]],
      tracker = "dbW_paths", prepared = TRUE)
  }


  #--- Determine sources of daily weather
  if (todo_intracker(SWSF_prj_meta, "dbW_sources", "prepared")) {

    if (SWSF_prj_meta[["opt_input"]][["how_determine_sources"]] == "SWRunInformation" &&
      "dailyweather_source" %in% colnames(SWSF_prj_inputs[["SWRunInformation"]])) {

      dw_source <- factor(SWSF_prj_inputs[["SWRunInformation"]][SWSF_prj_meta[["sim_size"]][["runIDs_sites"]], "dailyweather_source"],
        levels = SWSF_prj_meta[["opt_input"]][["dw_source_priority"]])
      do_weather_source <- anyNA(dw_source)

    } else {
      dw_source <- factor(rep(NA, SWSF_prj_meta[["sim_size"]][["runsN_sites"]]),
        levels = SWSF_prj_meta[["opt_input"]][["dw_source_priority"]])
      do_weather_source <- TRUE
    }

    if (do_weather_source) {
      SWSF_prj_inputs[["SWRunInformation"]] <- dw_determine_sources(dw_source,
        SWSF_prj_meta[["exinfo"]], SWSF_prj_meta[["opt_input"]][["dw_source_priority"]],
        SWSF_prj_inputs, SWSF_prj_inputs[["SWRunInformation"]],
        SWSF_prj_meta[["sim_size"]], SWSF_prj_meta[["sim_time"]], SWSF_prj_meta[["fnames_in"]],
        SWSF_prj_meta[["project_paths"]], verbose = opt_verbosity[["verbose"]])

        SWSF_prj_meta[["input_status"]] <- update_intracker(SWSF_prj_meta[["input_status"]],
          tracker = "load_inputs", prepared = TRUE, checked = FALSE)
    }

    SWSF_prj_meta[["input_status"]] <- update_intracker(SWSF_prj_meta[["input_status"]],
      tracker = "dbW_sources", prepared = TRUE, clean_subsequent = TRUE)
  }


  #--- Create weather database and populate with weather for current conditions
  if (todo_intracker(SWSF_prj_meta, "dbW_current", "prepared")) {

    if (SWSF_prj_meta[["exinfo"]][["ExtractClimateChangeScenarios"]]) {
      SWSF_prj_meta[["opt_sim"]][["use_dbW_future"]] <- TRUE
      SWSF_prj_meta[["opt_sim"]][["use_dbW_current"]] <- TRUE
    }
    if (SWSF_prj_meta[["opt_sim"]][["use_dbW_future"]])
      SWSF_prj_meta[["opt_sim"]][["use_dbW_current"]] <- TRUE

    if (SWSF_prj_meta[["opt_sim"]][["use_dbW_current"]]) {
      make_dbW(SWSF_prj_meta, SWRunInformation = SWSF_prj_inputs[["SWRunInformation"]],
        opt_parallel, opt_chunks, opt_behave,
        deleteTmpSQLFiles = opt_out_run[["deleteTmpSQLFiles"]],
        verbose = opt_verbosity[["verbose"]])

      SWSF_prj_meta[["input_status"]] <- update_intracker(SWSF_prj_meta[["input_status"]],
        tracker = "dbW_current", prepared = TRUE, clean_subsequent = TRUE)

    } else {
      SWSF_prj_meta[["input_status"]] <- update_intracker(SWSF_prj_meta[["input_status"]],
        tracker = "dbW_current", prepared = NA, checked = NA)
    }
  }


  #------ DATA EXTRACTIONS
  #--- Soil data
  if (SWSF_prj_meta[["exinfo"]][["ExtractSoilDataFromCONUSSOILFromSTATSGO_USA"]] ||
    SWSF_prj_meta[["exinfo"]][["ExtractSoilDataFromISRICWISEv12_Global"]]) {

    if (todo_intracker(SWSF_prj_meta, "soil_data", "prepared")) {

      SWSF_prj_inputs <- ExtractData_Soils(SWSF_prj_meta[["exinfo"]], SWSF_prj_meta,
        SWSF_prj_inputs, opt_parallel, resume = opt_behave[["resume"]],
        verbose = opt_verbosity[["verbose"]])

      SWSF_prj_meta[["input_status"]] <- update_intracker(SWSF_prj_meta[["input_status"]],
        tracker = "soil_data", prepared = TRUE)
    }

  } else {
    SWSF_prj_meta[["input_status"]] <- update_intracker(SWSF_prj_meta[["input_status"]],
      tracker = "soil_data", prepared = NA, checked = NA)
  }


  #--- Mean monthly climate data
  if (SWSF_prj_meta[["exinfo"]][["ExtractSkyDataFromNOAAClimateAtlas_USA"]] ||
    SWSF_prj_meta[["exinfo"]][["ExtractSkyDataFromNCEPCFSR_Global"]]) {

    if (todo_intracker(SWSF_prj_meta, "climnorm_data", "prepared")) {

      SWSF_prj_inputs <- ExtractData_MeanMonthlyClimate(SWSF_prj_meta[["exinfo"]],
        SWSF_prj_meta, SWSF_prj_inputs, opt_parallel, opt_chunks,
        resume = opt_behave[["resume"]], verbose = opt_verbosity[["verbose"]])

      SWSF_prj_meta[["input_status"]] <- update_intracker(SWSF_prj_meta[["input_status"]],
        tracker = "climnorm_data", prepared = TRUE)
    }

  } else {
    SWSF_prj_meta[["input_status"]] <- update_intracker(SWSF_prj_meta[["input_status"]],
      tracker = "climnorm_data", prepared = NA, checked = NA)
  }


  #--- Topographic data
  if (SWSF_prj_meta[["exinfo"]][["ExtractElevation_NED_USA"]] ||
    SWSF_prj_meta[["exinfo"]][["ExtractElevation_HWSD_Global"]]) {

    if (todo_intracker(SWSF_prj_meta, "elev_data", "prepared")) {

      SWSF_prj_inputs <- ExtractData_Elevation(SWSF_prj_meta[["exinfo"]],
        SWSF_prj_meta, SWSF_prj_inputs, resume = opt_behave[["resume"]],
        verbose = opt_verbosity[["verbose"]])

      SWSF_prj_meta[["input_status"]] <- update_intracker(SWSF_prj_meta[["input_status"]],
        tracker = "elev_data", prepared = TRUE)
    }

  } else {
    SWSF_prj_meta[["input_status"]] <- update_intracker(SWSF_prj_meta[["input_status"]],
      tracker = "elev_data", prepared = NA, checked = NA)
  }


  #--- Climate scenarios and downscaling
  if (SWSF_prj_meta[["exinfo"]][["ExtractClimateChangeScenarios"]]) {

    if (todo_intracker(SWSF_prj_meta, "dbW_scenarios", "prepared")) {

      SWSF_prj_inputs <- PrepareClimateScenarios(SWSF_prj_meta, SWSF_prj_inputs,
        opt_parallel, opt_verbosity)

      SWSF_prj_meta[["input_status"]] <- update_intracker(SWSF_prj_meta[["input_status"]],
        tracker = "dbW_scenarios", prepared = TRUE)
    }

  } else {
    SWSF_prj_meta[["input_status"]] <- update_intracker(SWSF_prj_meta[["input_status"]],
      tracker = "dbW_scenarios", prepared = NA, checked = NA)
  }



  #------ CALCULATIONS PRIOR TO SIMULATION RUNS

  if (any(unlist(SWSF_prj_meta[["pcalcs"]])))
    runIDs_adjust <- seq_len(SWSF_prj_meta[["sim_size"]][["runsN_master"]])  # if not all, then runIDs_sites

  if (SWSF_prj_meta[["pcalcs"]][["AddRequestedSoilLayers"]]) {
    if (todo_intracker(SWSF_prj_meta, "req_soillayers", "prepared")) {

      temp <- calc_ExtendSoilDatafileToRequestedSoilLayers(SWSF_prj_meta, SWSF_prj_inputs,
        runIDs_adjust, verbose = opt_verbosity[["verbose"]])

      SWSF_prj_meta <- temp[["SWSF_prj_meta"]]
      SWSF_prj_inputs <- temp[["SWSF_prj_inputs"]]

      SWSF_prj_meta[["input_status"]] <- update_intracker(SWSF_prj_meta[["input_status"]],
        tracker = "req_soillayers", prepared = TRUE)
    }

  } else {
    SWSF_prj_meta[["input_status"]] <- update_intracker(SWSF_prj_meta[["input_status"]],
      tracker = "req_soillayers", prepared = NA, checked = NA)
  }


  if (SWSF_prj_meta[["pcalcs"]][["CalculateBareSoilEvaporationCoefficientsFromSoilTexture"]]) {
    if (todo_intracker(SWSF_prj_meta, "calc_bsevap", "prepared")) {

      SWSF_prj_inputs <- calc_CalculateBareSoilEvaporationCoefficientsFromSoilTexture(
        SWSF_prj_meta, SWSF_prj_inputs, runIDs_adjust, resume = opt_behave[["resume"]],
        verbose = opt_verbosity[["verbose"]])

      SWSF_prj_meta[["input_status"]] <- update_intracker(SWSF_prj_meta[["input_status"]],
        tracker = "calc_bsevap", prepared = TRUE)
    }

  } else {
    SWSF_prj_meta[["input_status"]] <- update_intracker(SWSF_prj_meta[["input_status"]],
      tracker = "calc_bsevap", prepared = NA, checked = NA)
  }


  #--- The following will be calculated by each simulation run: set flags here
  # TODO(drs): they require knowledge of site climate which is not available at this point
  #   by the code; such calculations can be carried out here once dbW summarizes/contains
  #   climate variables and SWSF_prj_inputs can store inputs for each run (instead of
  #   sites and experimentalDesign separately)
  if (SWSF_prj_meta[["pcalcs"]][["EstimateConstantSoilTemperatureAtUpperAndLowerBoundaryAsMeanAnnualAirTemperature"]]) {

    # Set use-flags so that function 'SiteClimate' is called by each SOILWAT2-run
    SWSF_prj_inputs[["sw_input_site_use"]]["SoilTempC_atLowerBoundary"] <- TRUE
    SWSF_prj_inputs[["sw_input_site_use"]]["SoilTempC_atUpperBoundary"] <- TRUE
  }

  if (SWSF_prj_meta[["pcalcs"]][["EstimateInitialSoilTemperatureForEachSoilLayer"]]) {

    use.layers <- which(SWSF_prj_inputs[["sw_input_soils_use"]][paste0("Sand_L", swsf_glovars[["slyrs_ids"]])])
    index.soilTemp <- paste0("SoilTemp_L", swsf_glovars[["slyrs_ids"]])[use.layers]
    SWSF_prj_inputs[["sw_input_soils_use"]][index.soilTemp] <- TRUE
  }


  #------ OBTAIN INFORMATION FROM TABLES PRIOR TO SIMULATION RUNS
  # As specified by sw_input_treatments and sw_input_experimentals

  if (todo_intracker(SWSF_prj_meta, "table_lookup", "prepared")) {

    SWSF_prj_inputs <- do_prior_TableLookups(SWSF_prj_meta, SWSF_prj_inputs,
      resume = opt_behave[["resume"]], verbose = opt_verbosity[["verbose"]])

    SWSF_prj_meta[["input_status"]] <- update_intracker(SWSF_prj_meta[["input_status"]],
      tracker = "table_lookup", prepared = TRUE)
  }


  list(SWSF_prj_meta = SWSF_prj_meta, SWSF_prj_inputs = SWSF_prj_inputs)
}



#' Attempt to check input data of a rSWSF project for consistency
#' @export
check_rSWSF_project_input_data <- function(SWSF_prj_meta, SWSF_prj_inputs, opt_verbosity) {

  if (opt_verbosity[["verbose"]]) {
    t1 <- Sys.time()
    print(paste0("SWSF's ", shQuote(match.call()[1]), ": started at ", t1))
  }

  on.exit({if (opt_verbosity[["verbose"]]) {
      print(paste0("SWSF's ", shQuote(match.call()[1]), ": ended after ",
        round(difftime(Sys.time(), t1, units = "secs"), 2), " s with tracker status:"))
      print(SWSF_prj_meta[["input_status"]])
    }}, add = TRUE)

  if (all(stats::na.exclude(SWSF_prj_meta[["input_status"]][, "checked"]))) {
    # Return if all is checked (from a previous run)

    return(list(SWSF_prj_meta = SWSF_prj_meta, SWSF_prj_inputs = SWSF_prj_inputs))
  }

  on.exit(saveRDS(SWSF_prj_meta, file = SWSF_prj_meta[["fnames_in"]][["fmeta"]]),
    add = TRUE)
  on.exit(saveRDS(SWSF_prj_inputs, file = SWSF_prj_meta[["fnames_in"]][["fpreprocin"]]),
    add = TRUE)


  #--- Checking input 'SWRunInformation'
  if (todo_intracker(SWSF_prj_meta, "load_inputs", "checked")) {
    # Check that 'dailyweather_source' are specified
    itemp <- SWSF_prj_inputs[["SWRunInformation"]][SWSF_prj_meta[["sim_size"]][["runIDs_sites"]], ]
    icheck1 <- !anyNA(itemp[, "dailyweather_source"])
    if (!icheck1) {
      warning("There are sites without a specified daily weather data source. ",
        "Provide data for every requested run.")
    }

    # Check that INCLUDE_YN* are inclusive
    icheck2 <- check_requested_sites(
      SWSF_prj_inputs[["include_YN"]], SWSF_prj_inputs[["SWRunInformation"]],
      SWSF_prj_meta[["fnames_in"]], verbose = opt_verbosity[["verbose"]])

    SWSF_prj_inputs[["SWRunInformation"]] <- icheck2[["SWRunInformation"]]

    SWSF_prj_meta[["input_status"]] <- update_intracker(SWSF_prj_meta[["input_status"]],
      tracker = "load_inputs", checked = icheck1 && icheck2[["check"]])
  }


  #--- Check daily weather
  if (todo_intracker(SWSF_prj_meta, "dbW_current", "checked") ||
    todo_intracker(SWSF_prj_meta, "dbW_scenarios", "checked")) {

    if (SWSF_prj_meta[["opt_sim"]][["use_dbW_current"]] ||
      SWSF_prj_meta[["opt_sim"]][["use_dbW_future"]]) {

      icheck1 <- file.exists(SWSF_prj_meta[["fnames_in"]][["fdbWeather"]])
      icheck2 <- check_dbWeather_version(SWSF_prj_meta[["fnames_in"]][["fdbWeather"]])
      icheck <- icheck1 && icheck2

    } else {
      icheck <- any(all(SWSF_prj_inputs[["create_treatments"]] == "LookupWeatherFolder"),
      SWSF_prj_meta[["exinfo"]][["GriddedDailyWeatherFromMaurer2002_NorthAmerica"]],
      SWSF_prj_meta[["exinfo"]][["GriddedDailyWeatherFromDayMet_NorthAmerica"]])

      if (!icheck) {
        warning("Daily weather data must be provided through 'LookupWeatherFolder', ",
          "'Maurer2002_NorthAmerica', or 'DayMet_NorthAmerica' since no weather database ",
          "is used")
      }
    }

    SWSF_prj_meta[["input_status"]] <- update_intracker(SWSF_prj_meta[["input_status"]],
      tracker = "dbW_current", checked = icheck)

    if (todo_intracker(SWSF_prj_meta, "dbW_scenarios", "checked")) {
      SWSF_prj_meta[["input_status"]] <- update_intracker(SWSF_prj_meta[["input_status"]],
        tracker = "dbW_scenarios", checked = icheck)
    }
  }


 #---- Map input variables (for quality control)
  if (todo_intracker(SWSF_prj_meta, "soil_data", "checked")) {
    icheck <- map_input_variables(map_vars = c("SoilDepth", "Matricd", "GravelContent",
      "Sand", "Clay", "TOC_GperKG", "EvapCoeff"), SWSF_prj_meta, SWSF_prj_inputs,
      verbose = opt_verbosity[["verbose"]])

    SWSF_prj_meta[["input_status"]] <- update_intracker(SWSF_prj_meta[["input_status"]],
      tracker = "soil_data", checked = icheck)
  }

  if (todo_intracker(SWSF_prj_meta, "elev_data", "checked")) {
    icheck <- map_input_variables(map_vars = "ELEV_m", SWSF_prj_meta, SWSF_prj_inputs,
      verbose = opt_verbosity[["verbose"]])

    SWSF_prj_meta[["input_status"]] <- update_intracker(SWSF_prj_meta[["input_status"]],
      tracker = "elev_data", checked = icheck)
  }

  if (todo_intracker(SWSF_prj_meta, "climnorm_data", "checked")) {
    icheck <- map_input_variables(map_vars = c("RH", "SkyC", "Wind", "snowd"),
      SWSF_prj_meta, SWSF_prj_inputs, verbose = opt_verbosity[["verbose"]])

    SWSF_prj_meta[["input_status"]] <- update_intracker(SWSF_prj_meta[["input_status"]],
      tracker = "climnorm_data", checked = icheck)
  }


  list(SWSF_prj_meta = SWSF_prj_meta, SWSF_prj_inputs = SWSF_prj_inputs)
}





#' Carry out an entire rSWSF simulation experiment
#' @export
simulate_SOILWAT2_experiment <- function(actions, opt_behave, opt_sim,
  req_scens, req_out, opt_agg, project_paths, fnames_in, fnames_out, sim_space,
  opt_parallel, opt_chunks, opt_job_time, opt_verbosity) {

#---------------------------------------------------------------------------------------#
#------------------------PREPARE SOILWAT2 SIMULATIONS

  t_job_start <- Sys.time()
  if (opt_verbosity[["verbose"]]) {
    print(paste0("SWSF's ", shQuote(match.call()[1]), ": started at ", t_job_start,
      " for project ", sQuote(basename(project_paths[["dir_prj"]]))))
  }

  #--- SET UP PARALLELIZATION
  # used in:
  #   - loop calling do_OneSite
  #   - ensembles
  opt_parallel <- setup_SWSF_cluster(opt_parallel,
    dir_out = SWSF_prj_meta[["project_paths"]][["dir_prj"]],
    verbose = opt_verbosity[["verbose"]])
  on.exit(clean_SWSF_cluster(opt_parallel, verbose = opt_verbosity[["verbose"]]),
    add = TRUE)

  # Assigning objects from 'SWSF_prj_meta' to function environment for the time being;
  # a hack for convience
  for (k in ls(SWSF_prj_meta))
    assign(k, SWSF_prj_meta[[k]], envir = environment())

  ow_prev <- set_options_warn_error(opt_verbosity[["debug.warn.level"]],
    opt_verbosity[["debug.dump.objects"]], project_paths[["dir_prj"]])
  on.exit(options(ow_prev), add = TRUE)

  #--- Determine todos for simulation project
  prj_todos <- list(
    actions = actions,
    use_SOILWAT2 = any(unlist(actions[c("sim_create", "sim_execute", "sim_aggregate")])),
    EstimateConstantSoilTemperatureAtUpperAndLowerBoundaryAsMeanAnnualAirTemperature =
      SWSF_prj_meta[["pcalcs"]][["EstimateConstantSoilTemperatureAtUpperAndLowerBoundaryAsMeanAnnualAirTemperature"]],
    EstimateInitialSoilTemperatureForEachSoilLayer =
      SWSF_prj_meta[["pcalcs"]][["EstimateInitialSoilTemperatureForEachSoilLayer"]],

    # output aggregate overall
    aon = convert_to_todo_list(req_out[["overall_out"]]),
    # output aggregate daily
    adaily = setup_mean_daily_output_requests(req_out[["mean_daily"]], opt_agg),
    # output daily traces
    otrace = req_out[["traces"]]
  )

  #--- Update todo list
  prj_todos <- c(prj_todos, list(
    ex_besides_weather = {
      temp <- !grepl("GriddedDailyWeather", names(SWSF_prj_meta[["exinfo"]]))
      any(as.logical(SWSF_prj_meta[["exinfo"]])[temp])},

    need_cli_means = prj_todos[["use_SOILWAT2"]] && (
      any(sw_input_climscen_values_use) ||
      prj_todos[["EstimateConstantSoilTemperatureAtUpperAndLowerBoundaryAsMeanAnnualAirTemperature"]] ||
      sw_input_site_use["SoilTempC_atLowerBoundary"] ||
      sw_input_site_use["SoilTempC_atUpperBoundary"] ||
      prj_todos[["EstimateInitialSoilTemperatureForEachSoilLayer"]] ||
      any(create_treatments == "PotentialNaturalVegetation_CompositionShrubsC3C4_Paruelo1996") ||
      any(create_treatments == "AdjMonthlyBioMass_Temperature") ||
      any(create_treatments == "AdjMonthlyBioMass_Precipitation") ||
      any(create_treatments == "Vegetation_Biomass_ScalingSeason_AllGrowingORNongrowing")),


    wipe_dbOut = opt_out[["wipe_dbOutput"]] &&
      !(sum(prj_todos[["actions"]]) == 1 && prj_todos[["actions"]][["ensemble"]])
  ))

  #--- Update output aggregation options
  opt_agg <- setup_aggregation_options(opt_agg, GISSM_species_No = GISSM_species_No,
    GISSM_params = GISSM_params)

  #--- Determine which runs (still) need to be done for this round
  SWSF_prj_meta[["sim_size"]][["runIDs_todo"]] <- dbWork_todos(project_paths[["dir_out"]]) # elements of runIDs_total
  SWSF_prj_meta[["sim_size"]][["runsN_todo"]] <- length(SWSF_prj_meta[["sim_size"]][["runIDs_todo"]])

  #--- Determine requested ensembles across climate scenarios
  temp <- update_scenarios_with_ensembles(sim_scens, SWSF_prj_meta[["sim_time"]], prj_todos)
  prj_todos[["do_ensembles"]] <- temp[["do_ensembles"]]
  sim_scens <- temp[["sim_scens"]]


############################################


#append treatment information to the aggregated output in addition to selected Index_RunInformation
Index_RunInformation_Treatments <- NULL
if (length(create_treatments) > 0) {
	Index_RunInformation_Treatments <- match(create_treatments, names(sw_input_treatments))
}





#---------------------------------------------------------------------------------------#






  #----------------------------------------------------------------------------------------#
  #------------ORGANIZE DATABASES FOR SIMULATION OUTPUT



  #--- Prepare output database
  temp <- make_dbOutput(fnames_out[["dbOutput"]], prj_todos, opt_agg,
    SWSF_prj_inputs[["SWRunInformation"]], Index_RunInformation, SWSF_prj_meta[["sim_size"]], create_treatments,
    create_experimentals, sw_input_treatments, sw_input_treatments_use,
    sw_input_experimentals, sim_scens, SWSF_prj_meta[["sim_time"]], verbose = opt_verbosity[["verbose"]])

  SWSF_prj_meta[["sim_size"]][["ncol_dbOut_overall"]] <- temp


if (opt_verbosity[["verbose"]])
  print(paste("SWSF sets up the database: ended after",
    round(difftime(Sys.time(), t1, units = "secs"), 2), "s"))




#---------------------------------------------------------------------------------------#
#------------------------RUN RSOILWAT

  # print system information
  print(temp <- utils::sessionInfo())
  if (opt_behave[["check_blas"]])
    benchmark_BLAS(temp$platform)


# run the simulation experiment
if (prj_todos[["use_SOILWAT2"]] && SWSF_prj_meta[["sim_size"]][["runsN_todo"]] > 0) {
  swof <- sw_out_flags()
  swDataFromFiles <- read_SOILWAT2_FileDefaults(project_paths[["dir_in_sw"]])
  args_do_OneSite <- gather_args_do_OneSite()

  runs.completed <- run_simulation_experiment(SWSF_prj_meta[["sim_size"]], SWSF_prj_inputs[["SWRunInformation"]],
    sw_input_soillayers, sw_input_treatments, sw_input_cloud, sw_input_prod,
    sw_input_site, sw_input_soils, sw_input_weather, sw_input_climscen,
    sw_input_climscen_values, MoreArgs = args_do_OneSite)


} else {
  runs.completed <- 0
}
#------------------------

#------------------------
# NOTE(drs): 'concatenation' may be much faster if temporary text files are not constructed
# around SQL insert statements, but instead as data.frames. Text files containing
# data.frames may be much faster with checks for duplicate P_id entries and could be
# inserted at once (instead of line by line) with the command
#   RSQLite::dbWriteTable(con, name = table, value = "path/to/db-file", append = TRUE)

# NOTE: The variables 'pids_inserted' and 'pids2_inserted' become quickly very large and
#   may then be too large for available memory

t.outputDB <- Sys.time()

if (prj_todos[["actions"]][["concat_dbOut"]]) {

  has_time_to_concat <- (difftime(t.outputDB, t_job_start, units = "secs") +
    opt_job_time[["one_concat_s"]]) < opt_job_time[["wall_time_s"]]

  if (has_time_to_concat) {
    move_temporary_to_outputDB(project_paths[["dir_out_temp"]], fnames_out[["dbOutput"]],
      fnames_out[["dbOutput_current"]], t_job_start, opt_job_time,
      opt_out[["dbOutCurrent_from_tempTXT"]] && !opt_out[["dbOutCurrent_from_dbOut"]],
      opt_out[["wipe_dbOutput"]], opt_out[["deleteTmpSQLFiles"]], opt_behave[["resume"]],
      print.debug = opt_verbosity[["print.debug"]], verbose = opt_verbosity[["verbose"]])

  } else {
    print(paste("Need at least", opt_job_time[["one_concat_s"]], "seconds to put SQL in",
      "output DB."))
  }


  if (opt_out[["dbOutCurrent_from_dbOut"]] && !opt_out[["dbOutCurrent_from_tempTXT"]]) {
    has_time_to_concat <- {difftime(Sys.time(), t_job_start, units = "secs") +
      opt_job_time[["one_concat_s"]]} < opt_job_time[["wall_time_s"]]

    if (has_time_to_concat) {
      do_copyCurrentConditionsFromDatabase(fnames_out[["dbOutput"]],
        fnames_out[["dbOutput_current"]], verbose = opt_verbosity[["verbose"]])

    } else {
      print(paste("Need at least", opt_job_time[["one_concat_s"]], "seconds to put SQL",
        "in output DB."))
    }
  }
}

#timing of outputDB
delta.outputDB <- as.double(difftime(Sys.time(), t.outputDB, units = "secs"))


#---------------------------------------------------------------------------------------#
#------------------------CHECK COMPLETENESS OF OUTPUT DATABASE AND SIMULATION
t.check <- Sys.time()

if (prj_todos[["actions"]][["check_dbOut"]]) {
  check_outputDB_completeness(fnames_out[["dbOutput"]], fnames_out[["dbOutput_current"]],
    update_workDB = opt_behave[["check_updates_dbWork"]] || opt_out[["deleteTmpSQLFiles"]],
    do_DBcurrent = opt_out[["dbOutCurrent_from_dbOut"]] || opt_out[["dbOutCurrent_from_tempTXT"]],
    opt_parallel, project_paths[["dir_out"]], verbose = opt_verbosity[["verbose"]])
}

#timing of check
delta.check <- difftime(Sys.time(), t.check, units = "secs")

#---------------------------------------------------------------------------------------#
#------------------------ENSEMBLE GENERATION
t.ensembles <- Sys.time()	#timing of ensemble calculation

if (prj_todos[["do_ensembles"]]) {

	if (opt_verbosity[["verbose"]])
	  print(paste("SWSF calculates ensembles: started at", t.ensembles))


	con <- DBI::dbConnect(RSQLite::SQLite(), dbname = fnames_out[["dbOutput"]])

	Tables <- dbOutput_ListOutputTables(con)
	Tables <- Tables[-grep(pattern="_sd", Tables, ignore.case = T)]

	if (opt_parallel[["has_parallel"]]) {
		#call the simulations depending on parallel backend

		if(identical(opt_parallel[["parallel_backend"]], "mpi")) {

			ensembles.completed <- Rmpi::mpi.applyLB(X = Tables,
			  FUN = collect_EnsembleFromScenarios,
			  name.OutputDB = fnames_out[["dbOutput"]], t.overall = t_job_start,
			  opt_job_time = opt_job_time, opt_parallel = opt_parallel,
			  dir_out = project_paths[["dir_out"]], sim_scens = sim_scens,
			  opt_chunks = opt_chunks)

		} else if(identical(opt_parallel[["parallel_backend"]], "cluster")) {

      ensembles.completed <- parallel::clusterApplyLB(opt_parallel[["cl"]],
        x = Tables, fun = collect_EnsembleFromScenarios,
			  name.OutputDB = fnames_out[["dbOutput"]], t.overall = t_job_start,
			  opt_job_time = opt_job_time, opt_parallel = opt_parallel,
			  dir_out = project_paths[["dir_out"]], sim_scens = sim_scens,
			  opt_chunks = opt_chunks)
		}

	} else {
    ensembles.completed <- lapply(Tables, FUN = collect_EnsembleFromScenarios,
			  name.OutputDB = fnames_out[["dbOutput"]], t.overall = t_job_start,
			  opt_job_time = opt_job_time, opt_parallel = opt_parallel,
			  dir_out = project_paths[["dir_out"]], sim_scens = sim_scens,
			  opt_chunks = opt_chunks)
	}

  ensembles.completed <- sum(unlist(ensembles.completed))

  temp <- {if (sim_scens[["save.scenario.ranks"]]) 3 else 2} * length(Tables) *
    length(sim_scens[["ensemble.families"]]) * length(sim_scens[["ensemble.levels"]])

	if (ensembles.completed != temp)
	  print(paste("SWSF calculates ensembles: something went wrong with ensemble output:",
	    "ensembles.completed = ", ensembles.completed, " instead of ", temp, "."))

} else {
  ensembles.completed <- 0
}


#timing of ensemble calculation
delta.ensembles <- difftime(Sys.time(), t.ensembles, units="secs")
if (opt_verbosity[["verbose"]] && prj_todos[["do_ensembles"]])
  print(paste("SWSF calculates ensembles: ended after", round(delta.ensembles, 2), "s"))


#---------------------------------------------------------------------------------------#
#------------------------OVERALL TIMING
  delta.overall <- difftime(Sys.time(), t_job_start, units = "secs")

  compile_overall_timer(fnames_out[["timerfile"]], project_paths[["dir_out"]],
    opt_parallel[["workersN"]], runs.completed, sim_scens[["N"]], ensembles.completed,
    delta.overall, delta.outputDB, delta.check, delta.ensembles)

  if (opt_verbosity[["verbose"]]) {
    temp <- names(prj_todos[["actions"]])[prj_todos[["actions"]]]
    print(paste0("SWSF's ", shQuote(match.call()[1]), ": ended after ",
      round(delta.overall, 2), " s and completed actions = ",
      paste(temp, collapse = ", ")))
  }


#---------------------------------------------------------------------------------------#
#------------------------CODE CLEANUP

if (opt_parallel[["has_parallel"]]) {
  clean_SWSF_cluster(opt_parallel, verbose = opt_verbosity[["print.debug"]])
}


#---------------------------------------------------------------------------------------#
#---------------------------------------------------------------------------------------#
}
