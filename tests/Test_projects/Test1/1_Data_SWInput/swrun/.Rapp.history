#--------------------------------------------------------------------------------------------------##------------------------FRAMEWORK FOR SOILWAT SIMULATIONS: CREATING SIMULATION RUNS, EXECUTING SIMULATIONS, AND AGGREGATING OUTPUTS#--------------------------------------------------------------------------------------------------##------CODE developed and written by# - Daniel R Schlaepfer (dschlaep@uwyo.edu, drs): 2009-2014# - Donovan Miller (dlm): 2012# - Ryan Murphy (rjm): 2012-2015#for contact and further information see also: sites.google.com/site/drschlaepfer#The R code below was tested on R version 3.1.1#------DISCLAIMER: This program is distributed in the hope that it will be useful,#but WITHOUT ANY WARRANTY; without even the implied warranty of#MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.#------NOTES:#	- the code performs only rudimentary error checking and handling#	- SoilWat is forced by:#		- daily: rainfall (cm), maximum and minimum air temperature at 2-m height (C)#		- mean monthly: wind speed at 2-m height (miles/h before v24, m/s starting with v24), relative humidity at 2-m height (%), and cloud cover (%)#--------------------------------------------------------------------------------------------------##--------------------------------------------------------------------------------------------------##---------------------------------------------SETUP------------------------------------------------##------Clean the working environmentrm(list=ls(all=TRUE))#------Overall timingt.overall <- Sys.time()be.quiet <- FALSEprint.debug <- if(interactive()) TRUE else FALSE#------Mode of frameworkminVersionRsoilwat <- "1.0.1"minVersion_dbWeather <- "3.0.0"num_cores <- 2parallel_backend <- "snow" #"snow" or "multicore" or "mpi"parallel_runs <- if(interactive()) FALSE else TRUE#------Rmpi Jobs finish within Wall Time------#MaxRunDurationTime <- 1.5 * 60 *60 #Set the time duration for this job [in seconds], i.e. Wall time. As time runs out Rmpi will not send more work. Effects Insert into database and ensembles.MaxDoOneSiteTime <- (MaxRunDurationTime - 11*60) #This will stop new Rmpi jobs at 'x' seconds before MaxRunDuration expires.MinTimeConcat <- 10 * 60 * 60 #This is the minimum time remaining after execution needed to begin concatMaxConcatTime <- 35 * 60 #This will stop any new sql file concat job at 'x' seconds before MaxRunDuration expires.#------Repository in case installation of additional R packages is requiredurl.Rrepos <- "https://cran.us.r-project.org"#--------------------------------------------------------------------------------------------------##------------------------USER INPUT#------Set paths to simulation framework folders#parent folder of simulation projectdir.prj <- "~/Dropbox (Personal)/Work_Stuff/2_Research/Software/Code_Development/20160622_SOILWAT_R_WRAPPER_TestExample"#C dir.code <- "~/Dropbox (Personal)/Work_Stuff/2_Research/Software/GitHub_Projects/SoilWat_R_Wrapper"dir.code <- dir.prjif(interactive()) setwd(dir.prj)dir.prj <- dir.big <- getwd()#parent folder containing external datadir.external <- "/Volumes/YOURBIGDATA/SoilWat_SimulationFrameworks/SoilWat_DataSet_External"dir.external <- "/Volumes/BookDuo_12TB/BigData/GIS/Data"#paths to external subfolderdir.ex.weather <- file.path(dir.external,"Weather_Past")#historic weather data. Used with Livneh and Maurer Data and ClimateAtlas and NCEPCFSR data.dir.ex.fut <- file.path(dir.external,"Weather_Future")#future scenario data.dir.ex.soil <- file.path(dir.external,"Soils")dir.ex.dem <- file.path(dir.external,"Topography")#paths to sub-folder hierarchydir.in <- file.path(dir.prj, "1_Data_SWInput")	#path to input data of SoilWat-runs)dir.sw.dat <- file.path(dir.in, "datafiles")	#folder with datafiles to add information to SoilWat input filesdir.sw.in <- file.path(dir.in, "swrun")	#folder with complete SoilWat run setup (without yearly weather files, cloudin is in 'Input' folder and not in weather-folder: needs to be moved appropiately)dir.sw.in.tr <- file.path(dir.in, "treatments")	#folder with treatment input files according to treatment instructionsdir.sw.in.reg <- file.path(dir.in, "regeneration")	#folder with regeneration files, one for each species = run of 'dailyRegeneration_byTempSWPSnow'dir.sw.runs <- file.path(dir.big, "3_Runs")	#path to SoilWat-runsdir.out <- file.path(dir.big, "4_Data_SWOutputAggregated")	#path to aggregated output#
#------Define actions to be carried out by simulation framework#actions are at least one of c("external", "map_input", "create", "execute", "aggregate", "concatenate", "ensemble")#C actions <- c("external", "map_input", "create", "execute", "aggregate", "concatenate", "ensemble")##C actions <- c("external", "create", "execute", "aggregate", "concatenate", "ensemble")#actions <- c("create", "execute", "aggregate", "concatenate")##continues with unfinished part of simulation after abort if TRUE, i.e., #	- it doesn't delete an existing weather database, if a new one is requested#	- it doesn't re-extract external information (soils, elevation, climate normals) if already extracted#	- it doesn't repeat calls to 'do_OneSite' that are listed in 'runIDs_done'continueAfterAbort <- FALSE#use preprocessed input data if availableusePreProcessedInput <- TRUE#stores for each SoilWat simulation a folder with inputs and outputs if TRUEsaveSoilWatInputOutput <- TRUE#store data in big input files for experimental design x treatment designmakeInputForExperimentalDesign <- FALSE# fields/variables of input data for which to create maps if any(actions == "map_input")map_vars <- c("SoilDepth", "Matricd", "GravelContent", "Sand", "Clay", "RH", "SkyC", "Wind", "snowd")#check completeness of SoilWat simulation directories and of temporary output aggregation files; create a list with missing directories and filescheckCompleteness <- FALSE# check linked BLAS library before simulation runscheck.blas <- FALSE#------Define how aggregated output should be handled:cleanDB <- FALSE #This will wipe all the Tables at the begining of a run. Becareful not to wipe your data.deleteTmpSQLFiles <- TRUEcopyCurrentConditionsFromTempSQL <- TRUEcopyCurrentConditionsFromDatabase <- FALSE #Creates a copy of the main database containing the scenario==climate.ambient subsetensembleCollectSize <- 500 #This value is the chunk size for reads of 'runID' from the database, i.e., chunk size = ensembleCollectSize * scenario_No. Yellowstone 500 seems to work. Balance between available memory, cores, read/write times, etc..#------Define type of simulations and source of input data#Daily weather data: must be one of dailyweather_options; WeatherFolder in MasterInput.csv, treatmentDesign.csv, or experimentalDesign.csv# If a run has multiple sources for daily weather, then take the one in the first position of dailyweather_options if availble, if not then second etc.#	do not change/remove/add entries; only re-order to set different prioritiesdailyweather_options <- c("Maurer2002_NorthAmerica", "DayMet_NorthAmerica", "LookupWeatherFolder", "NRCan_10km_Canada", "NCEPCFSR_Global")#Daily weather databasegetCurrentWeatherDataFromDatabase <- TRUEgetScenarioWeatherDataFromDatabase <- TRUEdbWeatherDataFile <- file.path(dir.big, "1_Data_SWInput", "dbWeatherData_test1.sqlite3")#C createAndPopulateWeatherDatabase <- TRUE #TRUE, will create a new(!) database and populate with current datacreateAndPopulateWeatherDatabase <- FALSE #TRUE, will create a new(!) database and populate with current datadbW_compression_type <- "gzip" # one of eval(formals(memCompress)[[2]]); this only affects dbWeather if createAndPopulateWeatherDatabase#-Spatial setup of simulations# Should the locations of 'SWRunInformation' interpreted as 2D-cells of a raster/grid or as 1D-sites# sim_cells_or_points: currently, implemented for # - actions == "map_inputs"# - external extractions:#	- soils: "ExtractSoilDataFromISRICWISEv12_Global", "ExtractSoilDataFromCONUSSOILFromSTATSGO_USA",#	- elevation: "ExtractElevation_NED_USA", "ExtractElevation_HWSD_Global",#	- climate normals: "ExtractSkyDataFromNOAAClimateAtlas_USA" (NOTE: not implemented for 'ExtractSkyDataFromNCEPCFSR_Global')sim_cells_or_points <- "point" # one of c("point", "cell"), whether to extract for point locations or averaged over a cell areaif (sim_cells_or_points == "cell") {	# provide either path to raster file (takes precedence) or (grid resolution and grid crs)	fname_sim_raster <- file.path(dir.in, "YOURRASTER.FILE")	sim_res <- c(1e4, 1e4)	sim_crs <- sp::CRS("+init=epsg:5072") # NAD83(HARN) / Conus Albers} else {	sim_crs <- sp::CRS("+init=epsg:4326") # WGS84}#Indicate if actions contains "external" which external information (1/0) to obtain from dir.external, don't delete any labels; GIS extractions not supported on JANUS# if extract_determine_database == "order", then# - Elevation: 'ExtractElevation_NED_USA' has priority over 'ExtractElevation_HWSD_Global' on a per site basis if both are requested and data is available for both# - Soil texture: 'ExtractSoilDataFromCONUSSOILFromSTATSGO_USA' has priority over 'ExtractSoilDataFromISRICWISEv12_Global' on a per site basis if both are requested and data is available for both# - Climate normals: 'ExtractSkyDataFromNOAAClimateAtlas_USA' has priority over 'ExtractSkyDataFromNCEPCFSR_Global' on a per site basis if both are requested and data is available for both# if extract_determine_database == "SWRunInformation", then use information in suitable columns of spreadsheet 'SWRunInformation' if available; if not available, then fall back to option 'order'extract_determine_database <- "SWRunInformation" # one of c("order", "SWRunInformation")# External datasetsdo.ExtractExternalDatasets <- c(		#Daily weather data for current conditions#C		"GriddedDailyWeatherFromMaurer2002_NorthAmerica", 1,	#1/8-degree resolution		"GriddedDailyWeatherFromMaurer2002_NorthAmerica", 0,	#1/8-degree resolution		"GriddedDailyWeatherFromDayMet_NorthAmerica", 0,	#1-km resolution		"GriddedDailyWeatherFromNRCan_10km_Canada", 0,	# can only be used together with database		"GriddedDailyWeatherFromNCEPCFSR_Global", 0, # can only be used together with database		#Mean monthly PPT, Tmin, Tmax conditions: if using NEX or GDO-DCP-UC-LLNL, climate condition names must be of the form SCENARIO.GCM with SCENARIO being used for ensembles; if using climatewizard, climate condition names must be equal to what is in the respective directories		#CMIP3		"ExtractClimateChangeScenarios_CMIP3_ClimateWizardEnsembles_Global", 0, #50-km resolution for mean of 2070-2099		"ExtractClimateChangeScenarios_CMIP3_ClimateWizardEnsembles_USA", 0, #12-km resolution for mean change between 2070-2099 and 1971-2000		"ExtractClimateChangeScenarios_CMIP3_BCSD_GDODCPUCLLNL_USA", 0,	#1/8-degree resolution		"ExtractClimateChangeScenarios_CMIP3_BCSD_GDODCPUCLLNL_Global", 0,	#1/2-degree resolution		#CMIP5		"ExtractClimateChangeScenarios_CMIP5_BCSD_GDODCPUCLLNL_USA", 1,	#1/8-degree resolution		"ExtractClimateChangeScenarios_CMIP5_BCSD_GDODCPUCLLNL_Global", 0,	#1/2-degree resolution		"ExtractClimateChangeScenarios_CMIP5_BCSD_NEX_USA", 0,	#30-arcsec resolution; requires live internet access		#Mean monthly wind, relative humidity, and 100% - sunshine		"ExtractSkyDataFromNOAAClimateAtlas_USA", 1,		"ExtractSkyDataFromNCEPCFSR_Global", 0,		#Topography		"ExtractElevation_NED_USA", 1,	#1-arcsec resolution, National Elevation Dataset (ned.usgs.gov), currently downloaded only for western US		"ExtractElevation_HWSD_Global", 0, #30-arcsec resolution, Harmonized World Soil Database		#Soil texture		"ExtractSoilDataFromCONUSSOILFromSTATSGO_USA", 0,		"ExtractSoilDataFromISRICWISEv12_Global", 1)chunk_size.options <- list(		ExtractSkyDataFromNOAAClimateAtlas_USA = 10000,	# chunk_size == 1e4 && n_extract 6e4 will use about 30 GB of memory		ExtractSkyDataFromNCEPCFSR_Global = 100,	# this is also OS-limited by the number of concurrently open files (on 'unix' platforms, check with 'ulimit -a')		DailyWeatherFromNCEPCFSR_Global = 100	# this is also OS-limited by the number of concurrently open files (on 'unix' platforms, check with 'ulimit -a'))do.PriorCalculations <- c(		"EstimateConstantSoilTemperatureAtUpperAndLowerBoundaryAsMeanAnnualAirTemperature", 1,		"EstimateInitialSoilTemperatureForEachSoilLayer", 1,		"CalculateBareSoilEvaporationCoefficientsFromSoilTexture", 1)#------Time frames of simulation (if not specified in the treatment datafile)#	current simulation years = simstartyr:endyr#	years used for results = startyr:endyrsimstartyr  <- 1979getStartYear <- function(simstartyr) simstartyr + 1startyr <- getStartYear(simstartyr)endyr <- 2010#Future time period(s):#	future simulation years = delta + simstartyr:endyr#	future simulation years downscaled based on#		- current conditions = DScur_startyr:DScur_endyr#		- future conditions = DSfut_startyr:DSfut_endyr# NOTE: Multiple time periods doesn't work with external type 'ClimateWizardEnsembles'# Each row of 'future_yrs' will be applied to every climate.conditionsDScur_startyr <- startyrDScur_endyr <- endyrctemp <- c("delta", "DSfut_startyr", "DSfut_endyr")future_yrs <- matrix(c(c(d <- 40, startyr + d, endyr + d),						c(d <- 90, startyr + d, endyr + d - 1)), # most GCMs don't have data for 2100					ncol = length(ctemp), byrow = TRUE, dimnames = list(NULL, ctemp))rownames(future_yrs) <- make.names(paste0("d", future_yrs[, "delta"], "yrs"), unique = TRUE)#------Meta-information of input datadatafile.windspeedAtHeightAboveGround <- 2 #SoilWat requires 2 m, but some datasets are at 10 m, e.g., NCEP/CRSF: this value checks windspeed height and if necessary converts to u2adjust.soilDepth <- FALSE # [FALSE] fill soil layer structure from shallower layer(s) or [TRUE] adjust soil depth if there is no soil texture information for the lowest layersincrement_soiltemperature_deltaX_cm <- 5	# If SOILWAT soil temperature is simulated and the solution instable, then the soil profile layer width is increased by this value until a stable solution can be found or total failure is determined#Climate conditionsclimate.ambient <- "Current"	#Name of climatic conditions of the daily weather input when monthly climate perturbations are all off#names of climate conditions/scenarios in the order of data in the climate scenarios datafile; this must have at least one entry (e.g., climate.ambient) and climate.ambient is forced to be the first entry#All GCMs for CMIP5 by GDO-DCP-UC-LLNL: 37 RCP4.5, 35 RCP8.5#Excluded: 'HadCM3' and 'MIROC4h' because data only available until 2035climate.conditions <- c(climate.ambient,	"RCP45.CanESM2", "RCP45.CESM1-CAM5", "RCP45.HadGEM2-CC",											"RCP85.CanESM2", "RCP85.CESM1-CAM5", "RCP85.HadGEM2-CC")#climate.conditions <- c(climate.ambient)#Downscaling method: monthly scenario -> daily forcing variables#Will be applied to each climate.conditionsdownscaling.method			<- c("hybrid-delta-3mod")				#one or multiple of "raw", "delta" (Hay et al. 2002), "hybrid-delta" (Hamlet et al. 2010), or "hybrid-delta-3mod"downscaling.options <- list(	daily_ppt_limit = 1.5,							#	monthly_limit = 1.5,							#	ppt_type = "detailed",							# either "detailed" or "simple"	correct_spline = "attempt",						# one of "fail", "none" or "attempt"; only used if extrapol_type is using splines		#	- "fail": downscaling fails if spline extrapolations fall outside estimated monthly extremes		#	- "none": no correction for extrapolated monthly extreme values, but this will likely fail during correction of extreme daily PPT events		#	- "attempt": repeated attempts with jittering data to fit spline extrapolations within estimated monthly extreme values	extrapol_type = "linear_Thermessl2012CC.QMv1b",	# one of "linear_Boe", "linear_Thermessl2012CC.QMv1b", "linear_none", "tricub_fmm", "tricub_monoH.FC", "tricub_natural", "normal_anomalies"		#	- "linear": Gudmundsson et al. 2012: "If new model values (e.g. from climate projections) are larger than the training values used to estimate the empirical CDF, the correction found for the highest quantile of the training period is used (Boe ?? et al., 2007; Theme??l et al., 2012)."		#	- "tricub": I got really large output values, e.g., obs.hist = 54 cm, scen.fut = 64 cm, sbc.fut = 88 cm, hd.fut = 89 cm		#	- "linear" (i.e., using Boe et al.'s correction) resulted for the same site to: obs.hist = 54 cm, scen.fut = 64 cm, sbc.fut = 75 cm, hd.fut = 75 cm		# 	- "normal", but no implemented in qmap: Tohver et al. 2014, Appendix A, p. 6: "... values that are outside the observed quantile map (e.g. in the early parts of the 20th century) are interpolated using standard anomalies (i.e. number of standard deviations from the mean) calculated for the observed data and GCM data. Although this approach ostensibly assumes a normal distribution, it was found during testing to be much more stable than attempts to use more sophisticated approaches. In particular, the use of Extreme Value Type I or Generalized Extreme Value distributions for extending the tail of the probability distributions were both found to be highly unstable in practice and introduced unacceptable daily extremes in isolated grid cells. These errors occur because of irregularities in the shapes of the CDFs for observed and GCM data, which relates in part to the relatively small sample size used to construct the monthly CDFs (i.e. n = 30)."	sigmaN = 6,										# test whether data distributions are within sigmaN * sd of mean	PPTratioCutoff = 10								# above and below that value use additive instead of multiplicative adjustments for precipitation; 3 was too small -> resulting in too many medium-sized ppt-event)#Climate ensembles created across scenariosensemble.families <- NULL #c("RCP45", "RCP85") # NULL or from c("SRESA2", "SRESA1B", "SRESB1"); this variable defines the groups for which ensembles of climate scenarios are calculated; corresponds to first part of scenario nameensemble.levels <- c(2, 8, 15)  #if(!is.null(ensemble.families)) then this needs to have at least one value; this variable defines which ranked climate.conditions the ensembles are representing for each ensemble.familiessave.scenario.ranks <- TRUE #if TRUE then for each ensemble.levels a file is saved with the scenario numbers corresponding to the ensemble.levels#------Names of files that contain input data or treatment codesdatafile.SWRunInformation <- "SWRuns_InputMaster_Test1_v11.csv"datafile.soillayers <- "SWRuns_InputData_SoilLayers_v9.csv"datafile.treatments <- "SWRuns_InputData_TreatmentDesign_v14.csv"datafile.Experimentals <- "SWRuns_InputData_ExperimentalDesign_v04.csv"if ((any(actions == "external") || any(actions == "create") || any(actions == "execute") || any(actions == "aggregate")) ) {	#input datafiles in the folder ./datafiles	datafile.climatescenarios <- "SWRuns_InputData_ClimateScenarios_Change_v11.csv"	datafile.climatescenarios_values <- "SWRuns_InputData_ClimateScenarios_Values_v11.csv"	datafile.cloud <- "SWRuns_InputData_cloud_v10.csv"	datafile.prod <- "SWRuns_InputData_prod_v10.csv"	datafile.siteparam <- "SWRuns_InputData_siteparam_v13.csv"	datafile.soils <- "SWRuns_InputData_soils_v11.csv"	datafile.weathersetup <- "SWRuns_InputData_weathersetup_v10.csv"}if (( any(actions == "external") || any(actions == "create") || any(actions == "execute") || any(actions == "aggregate")) ) {	#input files in sub-folders ./treatments	trfile.LookupClimatePPTScenarios <- "climate.ppt.csv"	trfile.LookupClimateTempScenarios <- "climate.temp.csv"	trfile.LookupShiftedPPTScenarios <- "shifted.ppt.csv"	trfile.LookupEvapCoeffFromTable <- "BareSoilEvaporationCoefficientsPerSoilLayer.csv"	trfile.LookupTranspCoeffFromTable <- "TranspirationCoefficients_v2.csv"	trfile.LookupTranspRegionsFromTable <- "TranspirationRegionsPerSoilLayer.csv"	trfile.LookupSnowDensityFromTable <- "MeanMonthlySnowDensities_v2.csv"	trfile.LookupVegetationComposition <- "VegetationComposition_MeanMonthly_v5.csv"}datafile.SWRWinputs_preprocessed <- "SWRuns_InputAll_PreProcessed.RData" # Storage file of input data for repeated access (faster) instead of re-reading from (slower) csv files if flag 'usePreProcessedInput' is TRUE#------Northern/Southern Hemisphere adjustmentsaccountNSHemispheres_agg <- TRUE	#if TRUE and latitude < 0 (i.e., southern hemisphere) then the counting of timing variables is shifted by 6 months (e.g., July becomes 1st month, etc.)accountNSHemispheres_veg <- TRUE 	#if TRUE and latitude < 0 (i.e., southern hemisphere) then shift monthly production values in prod.in file by six months#------Output Header Columns------#Index_RunInformation <- NULL #indices of columns of 'SWRunInformation', e.g, c(3, 7:9), or NULL, used for outputting SoilWat-run information in addition to create_treatments and climate scenario#------Select aggregated output: time scale and variable groups#simulation_timescales is at least one of c("daily", "weekly", "monthly", "yearly")simulation_timescales <- c("daily", "monthly", "yearly")#turn aggregation for variable groups on (1) or off (0), don't delete any variable group labelsoutput_aggregates <- c(					#---Aggregation: SoilWat inputs						"input_SoilProfile", 1,            			"input_FractionVegetationComposition", 1,						"input_VegetationBiomassMonthly", 1,						"input_VegetationPeak", 1,						"input_Phenology", 1,						"input_TranspirationCoeff", 1,						"input_ClimatePerturbations", 1,					#---Aggregation: Climate and weather						"yearlyTemp", 1,						"yearlyPPT", 1,						"dailySnowpack", 1,						"dailyFrostInSnowfreePeriod", 1,						"dailyHotDays", 1,						"dailyPrecipitationEventSizeDistribution", 1,						"yearlyAET", 1,						"yearlyPET", 1,						"monthlySeasonalityIndices", 1,					#---Aggregation: Climatic dryness						"yearlymonthlyTemperateDrylandIndices", 1,						"yearlyDryWetPeriods", 1,						"dailyWeatherGeneratorCharacteristics", 1,	#Takes about .5120 seconds for 33 scenarios is about						"dailyPrecipitationFreeEventDistribution", 1,						"monthlySPEIEvents", 1,					#---Aggregation: Climatic control						"monthlyPlantGrowthControls", 1,						"dailyC4_TempVar", 1,						"dailyDegreeDays", 1,						"dailyNRCS_SoilMoistureTemperatureRegimes", 0, #Requires at least soil layers at 10, 20, 30, 50, 60, 90 cm						"dailyNRCS_Chambers2014_ResilienceResistance", 0, #Requires "dailyNRCS_SoilMoistureTemperatureRegimes"					#---Aggregation: Yearly water balance						"yearlyWaterBalanceFluxes", 1,						"dailySoilWaterPulseVsStorage", 1,					#---Aggregation: Daily extreme values						"dailyTranspirationExtremes", 1,						"dailyTotalEvaporationExtremes", 1,						"dailyDrainageExtremes", 1,						"dailyInfiltrationExtremes", 1,						"dailyAETExtremes", 1,						"dailySWPextremes", 1,						#Takes about .7630 seconds for 33 scenarios is about .419 minutes						"dailyRechargeExtremes", 1,					#---Aggregation: Ecological dryness						"dailyWetDegreeDays", 1,						"monthlySWPdryness", 1,						"dailySWPdrynessANDwetness", 1, 			#Takes about 3.200 seconds for 33 scenarios is about 1.76 minutes						"dailySuitablePeriodsDuration", 1,						"dailySuitablePeriodsAvailableWater", 1,						"dailySuitablePeriodsDrySpells", 1,						"dailySWPdrynessDurationDistribution", 1,	#Takes about .8132 seconds for 33 scenarios is about .447 minutes						"dailySWPdrynessEventSizeDistribution", 1,	#Takes about .5120 seconds for 33 scenarios is about .2819334						"dailySWPdrynessIntensity", 1,					#---Aggregation: Mean monthly values						"monthlyTemp", 1,						"monthlyPPT", 1,						"monthlySnowpack", 1,						"monthlySoilTemp", 1,						"monthlyRunoff", 1,						"monthlyHydraulicRedistribution", 1,						"monthlyInfiltration", 1,						"monthlyDeepDrainage", 1,						"monthlySWPmatric", 1,						"monthlyVWCbulk", 1,						"monthlyVWCmatric", 1,						"monthlySWCbulk", 1,						"monthlySWAbulk", 1,						"monthlySWAmatric", 1,						"monthlyTranspiration", 1,						"monthlySoilEvaporation", 1,						"monthlyAET", 1,						"monthlyPET", 1,						"monthlyAETratios", 1,						"monthlyPETratios", 1,					#---Aggregation: Potential regeneration						"dailyRegeneration_bySWPSnow", 0,						"dailyRegeneration_GISSM", 0)#select variables to aggregate daily mean and SD, if "daily" is in simulation_timescales#options: NULL or at least one of c("AET", "Transpiration", "EvaporationSoil", "EvaporationSurface", "EvaporationTotal", "VWCbulk", "VWCmatric", "SWCbulk", "SWPmatric", "Snowpack", "SWAbulk", "Rain", "Snowfall", "Snowmelt", "SnowLoss", "Runoff", "Infiltration", "DeepDrainage", "PET", "TotalPrecipitation", "TemperatureMin", "TemperatureMax", "SoilTemperature")#C output_aggregate_daily <- c("AET", "Transpiration", "EvaporationSoil", "EvaporationSurface", "EvaporationTotal", "VWCbulk", "VWCmatric", "SWCbulk", "SWPmatric", "Snowpack", "SWAbulk", "Rain", "Snowfall", "Snowmelt", "SnowLoss", "Runoff", "Infiltration", "DeepDrainage", "PET", "TotalPrecipitation", "TemperatureMin", "TemperatureMax", "SoilTemperature")output_aggregate_daily <- NULL#select variables to output as aggregated yearly time seriesouput_aggregated_ts <- NULL #c("Regeneration")#
#------Parameters used in output aggregation#critical soil water potentialSWPcrit_MPa <- c(-1.5, -3.0, -3.5, -3.9) #e.g., -1.5 or c(-3.0, -3.9, -4.9); critical soil water potential(s) to calculate 'dry' and 'wet' soils (aka wilting point) and available soil water#critical temperaturesTmin_crit_C <- c(-15, -9, 0)	#e.g., 0 or c(-15, -9, 0)Tmax_crit_C <- c(34, 40)	#e.g., 34 or c(34, 40)#degree-days and suitable temperatureDegreeDayBase <- 0 # (degree C) base temperature above which degree-days are accumulated#soil layersDepth_TopLayers  <- 20 				#cm, distinguishes between top and bottom soil layer for overall data aggregationAggLayer.daily <- TRUE				#if TRUE, then aggregate soil layers into 1-4 layers for mean/SD daily values; if FALSE, then use each soil layerDepth_FirstAggLayer.daily  <- 10 	#cm, distinguishes between first and second soil layer for average daily data aggregationDepth_SecondAggLayer.daily  <- 20 	#cm or NULL(=deepest soil layer), distinguishes between first and second soil layer for average daily data aggregationDepth_ThirdAggLayer.daily  <- 60 	#cm, NULL(=deepest soil layer), or NA(=only two aggregation layers), distinguishes between second and third soil layer for average daily data aggregationDepth_FourthAggLayer.daily  <- NULL	#cm, NULL(=deepest soil layer), or NA(=only three aggregation layers), distinguishes between third and fourth soil layer for average daily data aggregation#regeneration: germination and establishmentseason.start <- "LastSnow" # either doy or "LastSnow"season.end <- "FirstSnow" # either doy or "FirstSnow"germination.duration <- 7 # in daysgermination.swp.surface <- -0.2 # in MPa, duration must have at least x MPaestablishment.duration <- 14 # in daysestablishment.swp.surface <- -0.4 # in MPa, duration must have at least x MPaestablishment.delay <- 1 # start of establishment needs to occur latest x days after end of germination#daily weather frequency distributionsbin.prcpSizes <- 5	#bins of x mm precipitation event sizesbin.prcpfreeDurations <- 10	#bins of x consecutive days without precipitation#coefficients: potential natural vegetation based on climate data (Jose Paruelo et al. 1996, 1998)shrub.fraction.limit <- 0.2 	#page 1213: 0.2 in Paruelo JM, Lauenroth WK (1996) Relative abundance of plant functional types in grasslands and shrublands of North America. Ecological Applications, 6, 1212-1224.growing.season.threshold.tempC <- 10 # based on Trewartha's D temperateness definition (with >=4 & < 8 months with > 10C)growing.season.threshold.tempC <- 4 # based on standard input of mean monthly biomass values for vegetation composition#
#------SoilWat filessw <- "sw_v31"sw.inputs <- "Input"	#must be string of length > 0; i.e. not compatible with SoilWat versions < 21sw.outputs <- "Output"	#sw_v20+: "Output", earlier versions ""swFilesIn <- "files_v30.in"if(any(actions == "create") || any(actions == "execute") || any(actions == "aggregate") ) {	#sw input file names	swOutSetupIn <- "outsetup_v20.in"	swcsetupin <- "swcsetup.in"	soilsin <- "soils_v30.in"	yearsin <- "years.in"	estabin <- "estab.in"	weatherin <- "weathsetup_v20.in"	cloudin <- "cloud_v20.in"	prodin <- "sbe_prod_v31.in"	siteparamin <- "siteparam_v26.in"	filebasename.WeatherDataYear <- "weath"	#characteristics of sw input files	soilsin.firstDataLine <- 18	# 18, if soilsin >= v23; 17, if soilsin < v23	sw_aet			<- "AET"	sw_deepdrain	<- "DEEPSWC"	sw_estabs		<- "ESTABL"	sw_evsoil		<- "EVAPSOIL"	sw_evapsurface	<- "EVAPSURFACE"	sw_hd			<- "HYDRED"	sw_inf_soil		<- "SOILINFILT"	sw_interception	<- "INTERCEPTION"	sw_percolation	<- "LYRDRAIN"	sw_pet			<- "PET"	sw_precip		<- "PRECIP"	sw_runoff		<- "RUNOFF"	sw_snow			<- "SNOWPACK"	sw_soiltemp		<- "SOILTEMP"	sw_surfaceWater	<- "SURFACEWATER"	sw_swp			<- "SWPMATRIC"	sw_swabulk		<- "SWABULK"	sw_swamatric	<- "SWAMATRIC"	sw_swcbulk		<- "SWCBULK"	sw_temp			<- "TEMP"	sw_transp		<- "TRANSP"	sw_vwcbulk		<- "VWCBULK"	sw_vwcmatric	<- "VWCMATRIC"	sw_wetdays		<- "WETDAY"	sw_logfile		<- "LOG"}######################################################################################################Source of the code base###############################if (!interactive()) source(file.path(dir.code, "2_SWSF_p4of4_Code_v51.R"), verbose = FALSE, chdir = FALSE)
#--------------------------------------------------------------------------------------------------##------------------------PREPARE SOILWAT SIMULATIONSif(!be.quiet) print(paste("SWSF is executed for:", sQuote(basename(dir.prj)), "and started at", Sys.time())).Last <- function() { #Properly end mpi slaves before quitting R (e.g., at a crash)	if (is.loaded("mpi_initialize") && exists("mpi.comm.size")){		if (mpi.comm.size(1) > 0) mpi.close.Rslaves()		.Call("mpi_finalize")	}}#------actionWithSoilWat <- any(actions == "create") || any(actions == "execute") || any(actions == "aggregate")actionWithSWSFOutput <- any(actions == "concatenate") || any(actions == "ensemble")#--order output_aggregate_daily--#if(length(output_aggregate_daily) > 0) output_aggregate_daily <- output_aggregate_daily[order(output_aggregate_daily)]#------ow <- options("warn", "error")if(print.debug){	if(interactive()){		options(warn=1, error=quote({dump.frames(to.file=TRUE)}))	} else {		options(warn=2, error=quote({dump.frames(to.file=TRUE); q("no")}))	#turns all warnings into errors, dumps all to a file, and quits	}} else {	options(warn=0, error=traceback)	#catches all warnings and on error returns a traceback()}#custom list.dirs function because the ones in 2.13 and 2.15 are different... this function will behave like the one in 2.15 no matter which version you are using...#note: should work on any system where the directory seperator is .Platform$file.sep (ie Unix)list.dirs2 <- function(path, full.names=TRUE, recursive=TRUE) {	dir.list <- list.dirs(path, full.names)	if(is.null(dir.list))		return (dir.list)	if(length(dir.list) == 0)		return (dir.list)	if(recursive == TRUE)		return (dir.list)	nSlash = length(strsplit(dir.list[1], .Platform$file.sep)[[1]]) + 1	if(nSlash == 1)		return(dir.list[-1])	n = length(dir.list)	for(i in n:1)		if(length(strsplit(dir.list[i], .Platform$file.sep)[[1]]) != nSlash)			dir.list <- dir.list[-i]	return (dir.list)}#custom file.copy2 function, b/c it was giving errors on JANUS when run with MPIfile.copy2 <- function(from="", to="", overwrite=TRUE, copy.mode=TRUE, times=0) {	file.copy(from, to, overwrite, FALSE, copy.mode)	if(times < 24)		if(file.exists(from))			if(!file.exists(to)) {				print("trying to copy the file again")				file.copy2(from, to, overwrite, copy.mode, (times+1))	#recursively call the function again because when run with MPI the file copying doesn't seem to work everytime...			}	#else { #this commented out part copies the file via the system command cp	#	if(any(grepl("/", to, fixed=TRUE))) { #this part makes the to directory if it doesn't exist... so pretty much this can copy files to places that don't exist, which generally isn't what you want to do but in this case it might help solve an error I keep getting.	#		y <- to	#		while(substr(y, nchar(y), nchar(y)) != '/')	#			y <- substr(y, 1, nchar(y)-1)	#		y <- substr(y, 1, nchar(y)-1)	#		if(y != "")	#			system(paste("mkdir -p", y), ignore.stdout=FALSE, ignore.stderr=FALSE)	#	}	#	command <- "cp" #this just calls the system command cp...	#	if(overwrite == TRUE) command <- paste(command, "-f")	#	if(copy.mode == TRUE) command <- paste(command, "-p")	#	system(paste(command, from, to), ignore.stdout=FALSE, ignore.stderr=FALSE)	#}}#copy directory and content as in system(paste("cp -R", shQuote(from), shQuote(to)))dir.copy <- function(dir.from, dir.to, overwrite=FALSE){	dir.create2(dir.to, recursive=TRUE)	dir.list <- basename(list.dirs2(dir.from, full.names=FALSE, recursive=FALSE))	file.list <- list.files(dir.from)	if(length(dir.list) > 0) {		sapply(dir.list, function(x) {dir.copy(dir.from=file.path(dir.from, x), dir.to=file.path(dir.to, x), overwrite=overwrite)})		#file.list <- file.list[-match(dir.list, table=file.list)] #this line gives an error when run in R v. 2.13		file.list <- file.list[file.list != dir.list] #this line does the same as the other line, but does not throw the error	}	if(length(file.list) > 0) {		sapply(file.list, function(x) {file.copy2(from=file.path(dir.from, x), to=file.path(dir.to, x), overwrite=overwrite, copy.mode=TRUE)})	}	invisible(1)}#remove directory and contentdir.remove <- function(dir){	file.list <- try(list.files(dir, all.files=TRUE))	file.list <- file.list[-which(file.list %in% c(".", ".."))]	dir.list <- basename(list.dirs2(dir, full.names=FALSE, recursive=FALSE))	if(length(dir.list) > 0) {		sapply(dir.list, function(x) {dir.remove(dir=file.path(dir, x))})		file.list <- file.list[-match(dir.list, table=file.list)]	}	if(length(file.list) > 0) {		sapply(file.list, function(x) {file.remove(file.path(dir, x))})	}	return(file.remove(dir))}#made this function b/c dir.create wasn't always working correctly on JANUS for some reason... so if the simulations are being run on JANUS then it uses the system mkdir call to make the directories.dir.create2 <- function(path, showWarnings = TRUE, recursive = FALSE, mode = "0777", times = 0) {	dir.create(path, showWarnings, recursive, mode)	if(times < 24)		if(!file.exists(path)) {			print("trying to make directory again")			dir.create2(path, showWarnings, TRUE, mode, (times+1)) #recursively call the function b/c when run on JANUS with MPI it doesn't seem to make the directories everytime... quite aggravating.		}	#else if(recursive == TRUE) #this commented out part makes the directory via the system call mkdir	#	system(paste("mkdir -p", path), ignore.stdout=TRUE, ignore.stderr=FALSE)	#else	#	system(paste("mkdir", path), ignore.stdout=TRUE, ignore.stderr=FALSE)}#
#create simulation directory structuredir.sw.in <- normalizePath(dir.sw.in)if(makeInputForExperimentalDesign) dir.out.experimentalInput <- file.path(dir.out, "Experimentals_Input_Data")dir.out.temp <- file.path(dir.out, "temp")dir.create2(dir.out, showWarnings=FALSE, recursive=TRUE)dir.create2(dir.big, showWarnings=FALSE, recursive=TRUE)if(saveSoilWatInputOutput) dir.create2(dir.sw.runs, showWarnings=FALSE, recursive=TRUE)dir.create2(dir.out.temp, showWarnings=FALSE, recursive=TRUE)if(makeInputForExperimentalDesign) dir.create2(dir.out.experimentalInput, showWarnings=FALSE, recursive=TRUE)#timing: basis for estimated time of arrival, ETAtimerfile <- "temp_timer.csv"temp <- file.path(dir.out, timerfile)if (file.exists(temp) && (!continueAfterAbort || (actionWithSWSFOutput && !actionWithSoilWat))) {	try(file.remove(temp), silent=TRUE)}if (!file.exists(temp)) {	write.table(t(c(0,NA)), file=temp, append=TRUE, sep=",", dec=".", col.names=FALSE, row.names=FALSE)	runIDs_done <- NULL} else {	ttemp <- read.csv(file = temp, header = FALSE)	runIDs_done <- if (nrow(ttemp) > 1) sort(ttemp[-1, 1]) else NULL	rm(ttemp)}#timing: output for overall timing informationtimerfile2 <- "Timing_Simulation.csv"if(file.exists(temp <- file.path(dir.out, timerfile2))) try(file.remove(temp), silent=TRUE)write.table(t(c("", "Time_s", "Number")), file=temp, append=TRUE, sep=",", dec=".", col.names=FALSE, row.names=FALSE)#concatenate file keeps track of sql files inserted into dataconcatFile <- "sqlFilesInserted.csv"concatFileProblemLines <- "sqlFilesProblemLines.csv"#------load librariesdir.libraries <- .libPaths()[1]if (.Platform$OS.type == "windows") {	#test if user has write permission to standard library path	err <- try(write.table(1, file=ftemp <- file.path(dir.libraries, "testPermission.txt")))	if(inherits(err, "try-error")){		print(paste("User has no write permission for:", dir.libraries, ". A local path is attempted instead, but this is known to likely fail for the setup of 'snow' under Windows XP"))		dir.create2(path=dir.libraries <- file.path(dir.in, "RLibrary"),showWarnings=FALSE,recursive=FALSE)		if(!any(.libPaths() == dir.libraries)) .libPaths(dir.libraries)	} else {		file.remove(ftemp)	}}if(!require(Rsoilwat31,quietly = TRUE) || (require(Rsoilwat31,quietly = TRUE) && packageVersion("Rsoilwat31") < minVersionRsoilwat)) {	print("Going to try to install Rsoilwat library")	installed <- FALSE	if(.Platform$OS.type == "unix" && Sys.info()[1] == "Darwin" && sessionInfo()$R.version$major == 3){		#try to install mac binary for R version 3		installed<-tryCatch(install.packages(file.path(dir.in, "Rsoilwat", "Rsoilwat_osx_r3.zip"),repos=NULL, type="mac.binary",lib=dir.libraries), warning=function(w) { print(w); print("FAILED"); return(FALSE) })		installed<-is.null(installed)	} else if (.Platform$OS.type == "windows" && sessionInfo()$R.version$major == 3){		#try to install windows binary for R version 3		installed<-tryCatch(install.packages(file.path(dir.in, "Rsoilwat", "Rsoilwat_windows_r3.zip"),repos=NULL, type="win.binary",lib=dir.libraries), warning=function(w) { print(w); print("FAILED"); return(FALSE) })		installed<-is.null(installed)	}	if(!installed){#attempt to compile package from source because so far neither mac or windows binary attempted to install or successfully installed		installed <- tryCatch(install.packages(file.path(dir.in, "Rsoilwat", "SoilWat_v27_R.tar.gz"),repos=NULL, type="source",lib=dir.libraries), warning=function(w) { print(w); print("FAILED"); return(FALSE) })		installed <- is.null(installed)	}	if(!installed) stop("Could not install package Rsoilwat please contact admin.")	stopifnot(require(Rsoilwat31,quietly = TRUE) && packageVersion("Rsoilwat31") >= minVersionRsoilwat)}if(!require(circular, quietly=TRUE)) {	tryCatch(install.packages("circular",repos=url.Rrepos,lib=dir.libraries), warning=function(w) { print(w); print("circular failed to install"); stop("Stopping") })	stopifnot(require(circular, quietly=TRUE))}if(!require(SPEI, quietly=TRUE)) {	tryCatch(install.packages("SPEI",repos=url.Rrepos,lib=dir.libraries), warning=function(w) { print(w); print("circular failed to install"); stop("Stopping") })	stopifnot(require(SPEI, quietly=TRUE))}if(!require(RSQLite,quietly = TRUE)) {	tryCatch(install.packages("RSQLite",repos=url.Rrepos,lib=dir.libraries), warning=function(w) { print(w); print("RSQLite failed to install"); stop("Stopping") })	stopifnot(require(RSQLite, quietly = TRUE))}if(parallel_runs && identical(parallel_backend, "mpi")) {	if(!require(Rmpi,quietly = TRUE)) {		tryCatch(install.packages("Rmpi",repos=url.Rrepos,lib=dir.libraries), warning=function(w) { print(w); print("Rmpi failed to install"); stop("Stopping") })		stopifnot(require(Rmpi, quietly = TRUE))	}}if(parallel_runs && identical(parallel_backend, "snow")) {	if(!require(doSNOW,quietly = TRUE)) {#requires: foreach, iterators, snow		tryCatch(install.packages("doSNOW",repos=url.Rrepos,lib=dir.libraries), warning=function(w) { print(w); print("doSNOW failed to install"); stop("Stopping") })		stopifnot(require(doSNOW, quietly = TRUE))	}}if(parallel_runs && identical(parallel_backend, "multicore")) {	if(!require(doMC,quietly = TRUE)) {	#requires: foreach, iterators, codetools, and attaches: multicore		tryCatch(install.packages("doMC",repos=url.Rrepos,lib=dir.libraries), warning=function(w) { print(w); print("doMC failed to install"); stop("Stopping") })		stopifnot(require(doMC, quietly = TRUE))	}}if(!parallel_runs) {	if(!require(foreach,quietly = TRUE)) {		tryCatch(install.packages("foreach",repos=url.Rrepos,lib=dir.libraries), warning=function(w) { print(w); print("foreach failed to install"); stop("Stopping") })		stopifnot(require(foreach, quietly = TRUE))	}}#if(print.debug) trace(what=circular:::SdCircularRad, tracer=quote({print(x); print(sys.calls()[[6]]); print(paste(rbar, circsd))}), at=4)#------prepare outputaon.help <- matrix(data=output_aggregates, ncol=2, nrow=length(output_aggregates)/2, byrow=TRUE)aon <- data.frame(t(as.numeric(aon.help[,-1])))names(aon) <- aon.help[,1]#------constantsoutput_timescales_maxNo <- 4SoilLayer_MaxNo <- 20lmax <- 1:SoilLayer_MaxNodirname.sw.runs.weather <- "WeatherData"SoilWat.windspeedAtHeightAboveGround <- 2	#mst_mo <- 1:12isLeapYear <- function(y) y %% 4 == 0 & (y %% 100 != 0 | y %% 400 == 0)	#from package: tis#
#------import dataif(!be.quiet) print(paste("SWSF reads input data: started at", t1 <- Sys.time()))if (usePreProcessedInput && file.exists(file.path(dir.in, datafile.SWRWinputs_preprocessed))) {	load(file = file.path(dir.in, datafile.SWRWinputs_preprocessed),		envir = .GlobalEnv) # This however annihilates all objects in .GlobalEnv with the same names !} else {	# Read data from files	SWRunInformation <- tryCatch(read.csv(file.path(dir.in, datafile.SWRunInformation), as.is=TRUE),error=function(e) { print("datafile.SWRunInformation: Bad Path"); print(e)})	stopifnot(sapply(c("Label", "site_id", "WeatherFolder", "X_WGS84", "Y_WGS84", "ELEV_m", "Include_YN"),		function(x) x %in% colnames(SWRunInformation)),		# required columns		all(SWRunInformation$site_id == seq_len(nrow(SWRunInformation)))	# consecutive site_id	)		include_YN <- SWRunInformation$Include_YN	labels <- SWRunInformation$Label	sw_input_soillayers <- tryCatch(read.csv(file.path(dir.in, datafile.soillayers)),error=function(e) { print("datafile.soillayers: Bad Path"); print(e)})	sw_input_treatments_use <- tryCatch(read.csv(temp <- file.path(dir.in, datafile.treatments), nrows=1),error=function(e) { print("datafile.treatments: Bad Path"); print(e)})	sw_input_treatments <- read.csv(temp, skip=1, as.is=TRUE)	colnames(sw_input_treatments) <- colnames(sw_input_treatments_use)	sw_input_experimentals_use <- tryCatch(read.csv(temp <- file.path(dir.in, datafile.Experimentals), nrows=1),error=function(e) { print("datafile.Experimentals: Bad Path"); print(e)})	sw_input_experimentals <- read.csv(temp, skip=1, as.is=TRUE)	colnames(sw_input_experimentals) <- colnames(sw_input_experimentals_use)	create_experimentals <- names(sw_input_experimentals_use[-1][which(sw_input_experimentals_use[-1] > 0 & is.finite(as.numeric(sw_input_experimentals_use[-1])))])	#update treatment specifications based on experimental design	sw_input_treatments_use_combined <- ifelse(sw_input_treatments_use[-1] == 1 | names(sw_input_treatments_use[-1]) %in% create_experimentals, 1, 0)	temp<-which(!(create_experimentals %in% names(sw_input_treatments_use[-1])))	if(length(temp) != 0) sw_input_treatments_use_combined <- cbind(sw_input_treatments_use_combined, matrix(data=1,nrow=1,ncol=length(temp),dimnames=list(NA, c(create_experimentals[temp]))))	create_treatments <- names(sw_input_treatments_use_combined[,which(sw_input_treatments_use_combined > 0 & is.finite(as.numeric(sw_input_treatments_use_combined)))])	if(dim(SWRunInformation)[2] == 1) stop("SWRunInformation might be tab separated instead of comma.")	if(dim(sw_input_soillayers)[2] == 1) stop("SoilLayers might be tab separated instead of comma.")	if(dim(sw_input_treatments_use)[2] == 1) stop("Treatments might be tab separated instead of comma.")	if(dim(sw_input_experimentals_use)[2] == 1) stop("Experimentals might be tab separated instead of comma.")	sw_input_cloud_use <- sw_input_cloud <- list()	sw_input_prod_use <- sw_input_prod <- list()	sw_input_site_use <- sw_input_site <- list()	sw_input_soils_use <- sw_input_soils <- list()	sw_input_weather_use <- sw_input_weather <- list()	sw_input_climscen_use <- sw_input_climscen <- list()	sw_input_climscen_values_use <- sw_input_climscen_values <- list()	tr_files <- tr_prod <- tr_site <- tr_soil <- tr_weather <- tr_cloud <- list()	tr_input_climPPT <- tr_input_climTemp <- tr_input_shiftedPPT <- tr_input_EvapCoeff <- tr_input_TranspCoeff_Code <- tr_input_TranspCoeff <- tr_input_TranspRegions <- tr_input_SnowD <- tr_VegetationComposition <- list()	if (actionWithSoilWat || any(actions == "external") || any(actions == "map_input")) {		sw_input_cloud_use <- tryCatch(read.csv(temp <- file.path(dir.sw.dat, datafile.cloud), nrows=1),error=function(e) { print("datafile.cloud: Bad Path"); print(e)})		sw_input_cloud <- read.csv(temp, skip=1)		colnames(sw_input_cloud) <- colnames(sw_input_cloud_use)		sw_input_prod_use <- tryCatch(read.csv(temp <- file.path(dir.sw.dat, datafile.prod), nrows=1),error=function(e) { print("datafile.prod: Bad Path"); print(e)})		sw_input_prod <- read.csv(temp, skip=1)		colnames(sw_input_prod) <- colnames(sw_input_prod_use)		sw_input_prod_use[-1] <- ifelse(sw_input_prod_use[-1] == 1 | names(sw_input_prod_use[-1]) %in% create_experimentals, 1, 0)	#update specifications based on experimental design		sw_input_site_use <- tryCatch(read.csv(temp <- file.path(dir.sw.dat, datafile.siteparam), nrows=1),error=function(e) { print("datafile.siteparam: Bad Path"); print(e)})		sw_input_site <- read.csv(temp, skip=1)		colnames(sw_input_site) <- colnames(sw_input_site_use)		sw_input_site_use[-1] <- ifelse(sw_input_site_use[-1] == 1 | names(sw_input_site_use[-1]) %in% create_experimentals, 1, 0)	#update specifications based on experimental design		sw_input_soils_use <- tryCatch(read.csv(temp <- file.path(dir.sw.dat, datafile.soils), nrows=1),error=function(e) { print("datafile.soils: Bad Path"); print(e)})		sw_input_soils <- read.csv(temp, skip=1)		colnames(sw_input_soils) <- colnames(sw_input_soils_use)		sw_input_soils_use[-1] <- ifelse(sw_input_soils_use[-1] == 1 | names(sw_input_soils_use[-1]) %in% create_experimentals, 1, 0)	#update specifications based on experimental design		sw_input_weather_use <- tryCatch(read.csv(temp <- file.path(dir.sw.dat, datafile.weathersetup), nrows=1),error=function(e) { print("datafile.weathersetup: Bad Path"); print(e)})		sw_input_weather <- read.csv(temp, skip=1)		colnames(sw_input_weather) <- colnames(sw_input_weather_use)		sw_input_climscen_use <- tryCatch(read.csv(temp <- file.path(dir.sw.dat, datafile.climatescenarios), nrows=1),error=function(e) { print("datafile.climatescenarios: Bad Path"); print(e)})		sw_input_climscen <- read.csv(temp, skip=1)		colnames(sw_input_climscen) <- colnames(sw_input_climscen_use)		sw_input_climscen_values_use <- tryCatch(read.csv(temp <- file.path(dir.sw.dat, datafile.climatescenarios_values), nrows=1),error=function(e) { print("datafile.climatescenarios_values: Bad Path"); print(e)})		sw_input_climscen_values <- read.csv(temp, skip=1)		colnames(sw_input_climscen_values) <- colnames(sw_input_climscen_values_use)		if(dim(sw_input_cloud_use)[2] == 1) stop("Cloud datafile might be tab separated instead of comma.")		if(dim(sw_input_prod_use)[2] == 1) stop("Prod datafile might be tab separated instead of comma.")		if(dim(sw_input_site_use)[2] == 1) stop("Site datafile might be tab separated instead of comma.")		if(dim(sw_input_soils_use)[2] == 1) stop("Soils datafile might be tab separated instead of comma.")		if(dim(sw_input_weather_use)[2] == 1) stop("Weather datafile might be tab separated instead of comma.")		if(dim(sw_input_climscen_use)[2] == 1) stop("Climate Use datafile datafile might be tab separated instead of comma.")		if(dim(sw_input_climscen_values_use)[2] == 1) stop("Climate Values datafile datafile might be tab separated instead of comma.")		#Create a list of possible treatment files with data.		if(any(create_treatments=="sw"))			print("SW treatment is not used because library Rsoilwat only uses one version of soilwat. Sorry")		if(any(create_treatments=="filesin")) {			temp<-list.files(path=file.path(dir.sw.in.tr, "filesin"),pattern="in",include.dirs=FALSE,recursive=TRUE,full.names=TRUE)			tr_files[basename(temp)] <-unlist(lapply(temp,FUN=function(x) return(swReadLines(swClear(new("swFiles")),x))))		}		if(any(create_treatments=="prodin")) {			temp<-list.files(path=file.path(dir.sw.in.tr, "prodin"),pattern="in",include.dirs=FALSE,recursive=TRUE,full.names=TRUE)			tr_prod[basename(temp)] <-unlist(lapply(temp,FUN=function(x) return(swReadLines(swClear(new("swProd")),x))))		}		if(any(create_treatments=="siteparamin")) {			temp<-list.files(path=file.path(dir.sw.in.tr, "siteparamin"),pattern="in",include.dirs=FALSE,recursive=TRUE,full.names=TRUE)			tr_site[basename(temp)] <-unlist(lapply(temp,FUN=function(x) return(swReadLines(swClear(new("swSite")),x))))		}		if(any(create_treatments=="soilsin")) {			temp<-list.files(path=file.path(dir.sw.in.tr, "soilsin"),pattern="in",include.dirs=FALSE,recursive=TRUE,full.names=TRUE)			tr_soil[basename(temp)] <-unlist(lapply(temp,FUN=function(x) return(swReadLines(swClear(new("swSoils")),x))))		}		if(any(create_treatments=="weathersetupin")) {			temp<-list.files(path=file.path(dir.sw.in.tr, "weatherin"),pattern="in",include.dirs=FALSE,recursive=TRUE,full.names=TRUE)			tr_weather[basename(temp)] <-unlist(lapply(temp,FUN=function(x) return(swReadLines(swClear(new("swWeather")),x))))		}		if(any(create_treatments=="cloudin")) {			temp<-list.files(path=file.path(dir.sw.in.tr, "cloudin"),pattern="in",include.dirs=FALSE,recursive=TRUE,full.names=TRUE)			tr_cloud[basename(temp)] <-unlist(lapply(temp,FUN=function(x) return(swReadLines(swClear(new("swCloud")),x))))		}		if(any(create_treatments == "LookupClimatePPTScenarios")) tr_input_climPPT <- read.csv( file.path(dir.sw.in.tr, "LookupClimatePPTScenarios", trfile.LookupClimatePPTScenarios))		if(any(create_treatments == "LookupClimateTempScenarios")) tr_input_climTemp <- read.csv( file.path(dir.sw.in.tr, "LookupClimateTempScenarios", trfile.LookupClimateTempScenarios))		if(any(create_treatments == "LookupShiftedPPTScenarios")) tr_input_shiftedPPT <- read.csv( file.path(dir.sw.in.tr, "LookupShiftedPPTScenarios", trfile.LookupShiftedPPTScenarios), row.names=1)		if(any(create_treatments == "LookupEvapCoeffFromTable")) tr_input_EvapCoeff <- read.csv( file.path(dir.sw.in.tr, "LookupEvapCoeffFromTable", trfile.LookupEvapCoeffFromTable), row.names=1)		if(any(create_treatments == "LookupTranspCoeffFromTable_Grass", create_treatments == "LookupTranspCoeffFromTable_Shrub", create_treatments == "LookupTranspCoeffFromTable_Tree", create_treatments == "LookupTranspCoeffFromTable_Forb", create_treatments == "AdjRootProfile")){			tr_input_TranspCoeff_Code <- tryCatch(read.csv(temp <- file.path(dir.sw.in.tr, "LookupTranspCoeffFromTable", trfile.LookupTranspCoeffFromTable), nrows=2), error=function(e) { print("LookupTranspCoeffFromTable.csv: Bad Path"); print(e)})			tr_input_TranspCoeff_Code <- tr_input_TranspCoeff_Code[-2,]			tr_input_TranspCoeff <- read.csv(temp, skip=2)			colnames(tr_input_TranspCoeff) <- colnames(tr_input_TranspCoeff_Code)		}		if(any(create_treatments == "LookupTranspRegionsFromTable")) tr_input_TranspRegions <- read.csv( file.path(dir.sw.in.tr, "LookupTranspRegionsFromTable", trfile.LookupTranspRegionsFromTable), row.names=1)		if(any(create_treatments == "LookupSnowDensityFromTable")) tr_input_SnowD <- read.csv( file.path(dir.sw.in.tr, "LookupSnowDensityFromTable", trfile.LookupSnowDensityFromTable), row.names=1)		if(any(create_treatments == "AdjMonthlyBioMass_Temperature")) tr_VegetationComposition <- read.csv(file.path(dir.sw.in.tr, "LookupVegetationComposition", trfile.LookupVegetationComposition), skip=1, row.names=1)	}	#-import regeneration data	param.species_regeneration <- list()	if(any(simulation_timescales=="daily") & aon$dailyRegeneration_GISSM) {		list.species_regeneration <- list.files(dir.sw.in.reg, pattern=".csv")		no.species_regeneration <- length(list.species_regeneration)		if(no.species_regeneration > 0){			f.temp <- read.csv(file.path(dir.sw.in.reg, list.species_regeneration[1]))			param.species_regeneration <- matrix(NA, ncol=no.species_regeneration, nrow=nrow(f.temp))			colnames(param.species_regeneration) <- sub(".csv", "", list.species_regeneration)			rownames(param.species_regeneration) <- f.temp[, 1]			param.species_regeneration[, 1] <- f.temp[, 2]			if(no.species_regeneration > 1) for(f in 2:no.species_regeneration){					f.temp <- read.csv(file.path(dir.sw.in.reg, list.species_regeneration[f]))					param.species_regeneration[, f] <- f.temp[, 2]				}			rm(f.temp)		}	} else {		no.species_regeneration <- 0	}#
	save(SWRunInformation, include_YN, labels, sw_input_soillayers, sw_input_treatments_use, sw_input_treatments, sw_input_experimentals_use, sw_input_experimentals, create_experimentals, sw_input_treatments_use_combined, create_treatments, sw_input_cloud_use, sw_input_cloud, sw_input_prod_use, sw_input_prod, sw_input_site_use, sw_input_site, sw_input_soils_use, sw_input_soils, sw_input_weather_use, sw_input_weather, sw_input_climscen_use, sw_input_climscen, sw_input_climscen_values_use, sw_input_climscen_values, tr_files, tr_prod, tr_site, tr_soil, tr_weather, tr_cloud, tr_input_climPPT, tr_input_climTemp, tr_input_shiftedPPT, tr_input_EvapCoeff, tr_input_TranspCoeff_Code, tr_input_TranspCoeff, tr_input_TranspRegions, tr_input_SnowD, tr_VegetationComposition, param.species_regeneration, no.species_regeneration, 		file = file.path(dir.in, datafile.SWRWinputs_preprocessed),		compress = FALSE) # No compression for fast access; RDS may be slightly faster, but would require loop over assign(, envir = .GlobalEnv)}if(!be.quiet) print(paste("SWSF reads input data: ended after",  round(difftime(Sys.time(), t1, units="secs"), 2), "s"))#
#------create scenario namestemp <- climate.conditions[!grepl(climate.ambient, climate.conditions)] #make sure 'climate.ambient' is first entryif(length(temp) > 0){	temp <- paste0(rownames(future_yrs), ".", rep(temp, each = nrow(future_yrs)))	#add (multiple) future_yrs	temp <- paste0(downscaling.method, ".", rep(temp, each=length(downscaling.method))) #add (multiple) downscaling.method}climate.conditions <- c(climate.ambient, temp)scenario_No <- length(climate.conditions)scenario <- climate.conditions#------create ensemblesif(length(ensemble.levels) > 0) ensemble.levels <- sort(ensemble.levels)do.ensembles <- any(actions=="ensemble") && !is.null(ensemble.families) && length(ensemble.levels) > 0 && is.numeric(ensemble.levels) && scenario_No > 1if(do.ensembles){	ensemble.families <- paste0(rownames(future_yrs), ".", rep(ensemble.families, each = nrow(future_yrs)))	#add (multiple) future_yrs	scenarios.ineach.ensemble <- sapply(ensemble.families, function(x) grepl(pattern=x, climate.conditions, ignore.case=TRUE), simplify=TRUE)	ensemble.families <- ensemble.families[temp <- apply(scenarios.ineach.ensemble, MARGIN=2, FUN=any)]	scenarios.ineach.ensemble <- scenarios.ineach.ensemble[, temp]	families_N <- length(ensemble.families)	if(families_N > 1){		scenariosPERensemble_N <- max(temp <- apply(scenarios.ineach.ensemble, MARGIN=2, FUN=sum))		stopifnot(any(ensemble.levels <= min(temp)))	} else{		scenariosPERensemble_N <- sum(scenarios.ineach.ensemble)		stopifnot(any(ensemble.levels <= scenariosPERensemble_N))	}}#
#------Determine simulation runs#	- Simulations are run over three nested loops#		- loop1 (1...expN) nested in loop2b (1...runsN_sites) nested in loop3 (1...scenario_No)#			- Note: loop3 (along scenarios) occurs within the function 'do_OneSite'#			- Note: loop2b is a subset of loop2a (1...runsN_master)#		- column 'include_YN' reduces 'site_id' to 'runIDs_sites'#		- 'site_id' and 'P_id' are invariant to 'include_YN'##	- Master input file: column 'include_YN' selects rows which are included in the simulation#		Note: rows of the master input file correspond to rows of the treatment input file#		- column 'site_id'		== consecutive identification numbers of all rows in the master file; this is treated as a unique (and stable) identifier of a site#		- runsN_master			== number of rows in the master file #		- runsN_sites			== number of rows in the master file that are included (runsN_sites <= max(site_id))  [previously, 'runs']#		- runIDs_sites			== identification of rows in the master file that are included  [previously, 'seq.tr']##	- Experimental input file: each row defines a condition which is applied to every runIDs_sites#		- expN	== number of experimental treatments	[previously, 'trow']##	- The function 'do_OneSite' will be called n-times with n = runsN_total#		- runsN_total		== (number of included sites) x (number of experimental treatments)	[previously, 'runsN.total']#		- runIDs_total		== consecutive identification numbers along runsN_total [previously, 'seq.todo']#		- runIDs_done		== values of runIDs_total that have already been processed by 'do_OneSite' [previously, 'seq.done']#		- runIDs_todo		== values of runIDs_total that await simulation by 'do_OneSite' [previously, 'seq.todo']#		- runsN_todo		== number of runIDs_total that await simulation by 'do_OneSite' [previously, 'runsN.todo']##	- The function 'do_OneSite' could be called n-times with n = runsN_incl if all 'include_YN' were on#		- runsN_incl		== (number of sites) x (number of experimental treatments)##	- The variable 'climate.conditions' defines climate conditions that are applied to each 'runIDs_total'#		- scenario_No		== number of climate conditions##	- A grand total of n = runsN_Pid SoilWat runs could be carried out (n == number of rows in the output database)#		- runsN_Pid			== max(P_id) == runsN_incl x scenario_No#		- P_id				== a consecutive identification number for each possible SoilWat simulation; used as the ID for the output database ##	- Iterators:#		- i_sim					== A value out of the set of 'runIDs_todo' (as subset of 'runIDs_total') to be simulated#								== a consecutive index across loops 1+2b#		- i_site <- it_site()	== calculates the current value of 'runIDs_sites' based on 'i_sim'	[previously, 'i_tr']#								== position in loop 2 based on position across loops 1+2b#		- i_exp <- it_exp()		== position in loop 1 based on position across loops 1+2b#		- sc					== the iterator variable across 'scenario_No'#		- P_id <- it_Pid_old()	== a variable consecutive iterator across all loops 1+2b+3#		- P_id <- it_Pid()		== an invariant consecutive iterator across all loops 1+2a+3runsN_master <- nrow(SWRunInformation)runIDs_sites <- which(include_YN > 0)runsN_sites <- length(runIDs_sites)if (!(runsN_sites > 0))	stop(paste("at least 1 SoilWat-run needed for simulation, but", runsN_sites, "found"))# identify how many SoilWat-runs = rows are to be carried outexpN <- NROW(sw_input_experimentals)runsN_total <- runsN_sites * max(expN, 1L)runsN_incl <- runsN_master * max(expN, 1L)runsN_Pid <- runsN_incl * scenario_NorunIDs_total <- seq_len(runsN_total) # consecutive number of all (tr x exp) simulations to be executedcounter.digitsN <- 1 + ceiling(log10(runsN_master * max(expN, 1L)))	#max index digitsrunIDs_todo <- runIDs_total[!(runIDs_total %in% runIDs_done)] # remove already completed runs from todo listrunsN_todo <- length(runIDs_todo)# iterator functions#' @param isim An integer value. A value of \code{runIDs_todo} as subset of \code{runIDs_total}.#' @details NOTE: Do not change the iterators without adjusting the design of the output databases!it_Pid_old <- function(isim, sc) (isim - 1L) * scenario_No + scit_Pid <- function(isim, sc) ((it_exp(isim) - 1L) * runsN_master + it_site(isim) - 1L) * scenario_No + scit_exp <- function(isim) (isim - 1L) %/% runsN_sites + 1Lit_site <- function(isim) runIDs_sites[(isim - 1L) %% runsN_sites + 1L]## Tests#include_YN <- c(0, 0, 1, 0, 0, 1, 1, 0)#include_YN <- rep(1, 8)#t(sapply(runIDs_todo, function(isim) c(isim, it_site(isim), it_exp(isim), it_Pid(isim, 1), it_Pid_old(isim, 1))))#t(sapply(runIDs_total, function(isim) c(isim, it_site(isim), it_exp(isim), it_Pid(isim, 1), it_Pid_old(isim, 1))))#
#------outputing dataif(makeInputForExperimentalDesign) ExpInput_Seperator <- "X!X"#append treatment information to the aggregated output in addition to selected Index_RunInformationIndex_RunInformation_Treatments <- NULLif(length(create_treatments) > 0) {	Index_RunInformation_Treatments <- match(create_treatments, names(sw_input_treatments))}daily_no <- length(output_aggregate_daily)if(any(simulation_timescales=="daily")){	if(any(output_aggregate_daily == "SWAbulk") & length(SWPcrit_MPa) > 0){		output_aggregate_daily <- output_aggregate_daily[-which(output_aggregate_daily == "SWAbulk")]		for(icrit in seq(along=SWPcrit_MPa)){			output_aggregate_daily <- c(output_aggregate_daily, paste("SWAbulkatSWPcrit", abs(round(-1000*SWPcrit_MPa[icrit], 0)), "kPa", sep=""))		}		daily_no <- length(output_aggregate_daily)	}#	if(AggLayer.daily){#		aggLs_no <- 2 + ifelse(is.null(Depth_ThirdAggLayer.daily), 1, ifelse(!is.na(Depth_ThirdAggLayer.daily), 1, 0)) + ifelse(is.null(Depth_FourthAggLayer.daily), 1, ifelse(!is.na(Depth_FourthAggLayer.daily), 1, 0))#	} else {#at this stage we don't know how many soil layers we will have among the SoilWat runs; so just prepare for the maximum#		if(!any(create_treatments == "soilsin") & !is.null(sw_input_soillayers)){#			aggLs_no <- max(apply(sw_input_soillayers[, -1], MARGIN=1, FUN=function(x) ifelse(is.na(x[1]), NA, findInterval(x[1] - sqrt(.Machine$double.neg.eps), c(0, na.exclude(unlist(x[-1]))))) ), na.rm=TRUE)#		} else {#			aggLs_no <- SoilLayer_MaxNo#		}#	}}#
#------------------------FLAGS FOR EXTERNAL DATAtemp <- matrix(data=do.ExtractExternalDatasets, ncol=2, nrow=length(do.ExtractExternalDatasets)/2, byrow=TRUE)exinfo <- data.frame(t(as.numeric(temp[,-1])))names(exinfo) <- temp[,1]exinfo$use_sim_spatial <- 	exinfo$ExtractSoilDataFromCONUSSOILFromSTATSGO_USA	||	exinfo$ExtractSoilDataFromISRICWISEv12_Global		||	exinfo$ExtractElevation_NED_USA						||	exinfo$ExtractElevation_HWSD_Global					||	exinfo$ExtractSkyDataFromNOAAClimateAtlas_USA		||	exinfo$ExtractSkyDataFromNCEPCFSR_Global#
#------------------------SPATIAL SETUP OF SIMULATIONSif (exinfo$use_sim_spatial || any(actions == "map_input")) {	if (any(!requireNamespace("rgdal"), !requireNamespace("sp"), !requireNamespace("raster"))) {		stop("The packages 'rgdal', 'sp', and 'raster' are required, but one or multiple of them are not installed.")	}#
	# make sure that flag 'sim_cells_or_points' has a valid option	sim_cells_or_points <- match.arg(sim_cells_or_points, c("point", "cell"))	# make sure sim_raster agrees with sim_res and sim_crs; sim_raster takes priority	if (sim_cells_or_points == "cell") {		if (file.exists(fname_sim_raster)) {			sim_raster <- raster::raster(fname_sim_raster)			sim_res <- raster::res(sim_raster)			sim_crs <- raster::crs(sim_raster)		}		# make sure that sim_res is valid		stopifnot(is.finite(sim_res), length(sim_res) == 2L, sim_res > 0)	}	# make sure that sim_crs is valid	stopifnot((temp <- rgdal::checkCRSArgs(as.character(sim_crs)))[[1]])	sim_crs <- sp::CRS(temp[[2]])	# SpatialPoints of simulation cell centers/sites in WGS84	crs_sites <- sp::CRS("+init=epsg:4326")	# sp::CRS("+proj=longlat +datum=WGS84 +no_defs")	run_sites <- sp::SpatialPoints(coords = with(SWRunInformation[runIDs_sites,], data.frame(X_WGS84, Y_WGS84)), proj4string = crs_sites)	}#
#--------------------------------------------------------------------------------------------------##------------------------SET UP PARALLELIZATION#used in: GriddedDailyWeatherFromNCEPCFSR_Global, external dataset extractions, loop calling do_OneSite, and ensemblesworkersN <- 1parallel_init <- FALSEif(any(actions == "external") || (actionWithSoilWat && runsN_todo > 0) || do.ensembles){	if(parallel_runs){		if(!be.quiet) print(paste("SWSF prepares parallelization: started at", t1 <- Sys.time()))		if(identical(parallel_backend, "mpi")) {			mpi.spawn.Rslaves(nslaves=num_cores)			exportObjects <- function(allObjects) {				print("exporting objects from master node to slave nodes")				t.bcast <- Sys.time()				for(obj in 1:length(allObjects)) {					bcast.tempString <- allObjects[obj]					bcast.tempValue <- try(eval(as.name(allObjects[obj])))					if(!inherits(bcast.tempValue, "try-error")){						mpi.bcast.Robj2slave(bcast.tempString)						mpi.bcast.Robj2slave(bcast.tempValue)						mpi.bcast.cmd(cmd=try(assign(bcast.tempString, bcast.tempValue)))					} else {						print(paste(obj, bcast.tempString, "not successful"))					}				}				print(paste("object export took", round(difftime(Sys.time(), t.bcast, units="secs"), 2), "secs"))			}		}		if(identical(parallel_backend, "snow")){			if(!be.quiet) setDefaultClusterOptions(outfile="")			#cl <-  makeCluster(num_cores, type="MPI", outfile="")			cl <- snow::makeSOCKcluster(num_cores)			clusterApply(cl, 1:num_cores, function(x) nodeNumber<<-x)			#snow::clusterSetupRNG(cl) #random numbers setup			doSNOW::registerDoSNOW(cl) 	# register foreach backend		}		if(identical(parallel_backend, "multicore")) {			#stop("Only use snow on JANUS, because multicore cannot access cores outside master node")			registerDoMC(num_cores)		}		if(identical(parallel_backend, "mpi")){			workersN <- (mpi.comm.size() - 1)		} else {			workersN <- foreach::getDoParWorkers()		}		parallel_init <- TRUE		if(!be.quiet) print(paste("SWSF prepares parallelization: initialization of", workersN, "workers ended after",  round(difftime(Sys.time(), t1, units="secs"), 2), "s"))	}}#--------------------------------------------------------------------------------------------------##
#------------------------FUNCTIONS FOR NCEP/CFSR DATAif(exinfo$GriddedDailyWeatherFromNCEPCFSR_Global || exinfo$ExtractSkyDataFromNCEPCFSR_Global){	writeLines(c("'NCEPCFSR' extractions: make sure the following conditions are met:", 		" 	1) C code for 'cfsr_convert' is located in directory 'dir.cfsr.code'",		"	2) Compiled 'wgrib2' executable is located in directory 'dir.cfsr.code' or '/opt/local/bin/' & have it located in the same directory as cfsr_convert.  Instructions for how to compile 'wgrib2' can be found in the 'cfsr_convert.c'. The code of wgrib2 is available from http://www.cpc.ncep.noaa.gov/products/wesley/wgrib2/",		"	3) Appropriate grib files (the data) are located in directory 'dir.cfsr.data'.  Info about the gribfiles is in 'cfsr_convert.c'"))	#daily data (http://rda.ucar.edu/datasets/ds093.1/): ds093.1 NCEP Climate Forecast System Reanalysis (CFSR) Selected Hourly Time-Series Products, January 1979 to December 2010, 0.313-deg: 6-hourly	#- maximum temperature: 2m above ground (Kelvin): 6-hour period	#	-> tmax.gdas.yyyymm.grb2 --> max of 4 values per day	#- minimum temperature: 2m above ground (Kelvin): 6-hour period	#	-> tmin.gdas.yyyymm.grb2 --> max of 4 values per day	#- precipitation rate: ground or water surface (kg m-2 s-1): 6-hour average	#	-> prate.gdas.yyyymm.grb2 --> sum of 4 values per day which are converted to cm/6-hour#
	#monthly data (http://rda.ucar.edu/datasets/ds093.2/): ds093.2 - NCEP Climate Forecast System Reanalysis (CFSR) Monthly Products, January 1979 to December 2010, 0.313-deg: monthly mean (4 per day) of forecasts of 6-hour average	#- relative humidity (%): entire atmosphere --> 2m above ground	#	-> [0.5-deg] pgbh06.gdas.R_H.2m.grb2 --> means for Jan-Dec	#- wind (m s-1): u- and v-component at 10m above ground	#	-> flxf06.gdas.WND.10m.grb2 (u- and v-component) --> means for Jan-Dec	#- total cloud cover (%): entire atmosphere as a single layer	#	-> flxf06.gdas.T_CDC.EATM.grb2 --> means for Jan-Dec	load_NCEPCFSR_shlib <- function(cfsr_so){		if(!is.loaded("writeMonthlyClimate_R")) dyn.load(cfsr_so) # load because .so is available		invisible(0)	}	prepare_NCEPCFSR_extraction <- function(dir.cfsr.data, dir.cfsr.code = dir.cfsr.data) {		dir.create(dir.in.cfsr <- file.path(dir.big, "ncepcfsr"), showWarnings=FALSE)		fname_cfsr <- file.path(dir.in.cfsr, "cfsr_convert.so")		.local <- function(){			#Check for the shared object 'cfsr_convert.so' that contains the C functions accessible to R			if(!file.exists(fname_cfsr)){ # compile				dtemp <- getwd()				setwd(dir.cfsr.code)				stopifnot(file.exists("cfsr_convert.c", "generic2.c", "generic2.h", "filefuncs2.c", "filefuncs2.h", "mymemory2.c", "mymemory2.h"))				unlink(c("cfsr_convert.o", "generic2.o", "filefuncs2.o", "mymemory2.o"))				stopifnot(system2(command=file.path(Sys.getenv()[["R_HOME"]], "R"), args=paste("CMD SHLIB -o", fname_cfsr, "cfsr_convert.c generic2.c filefuncs2.c mymemory2.c"), wait=TRUE) == 0)				setwd(dtemp)			}			load_NCEPCFSR_shlib(fname_cfsr)			#Check for wgrib2 (http://www.cpc.ncep.noaa.gov/products/wesley/wgrib2/)			if(!file.exists(wgrib2 <- file.path(dir.in.cfsr, "wgrib2"))){				temp2 <- if(nchar(temp <- Sys.which("wgrib2")) > 0) temp else if(file.exists(temp <- "/opt/local/bin/wgrib2")) temp else ""				stopifnot(nchar(temp2) > 0)				file.copy(from=temp2, to=wgrib2)			}			#Soft link to gribbed data			fname_gribDir <- "griblargeC2"			if(!file.exists(dir.grib <- file.path(dir.in.cfsr, fname_gribDir))){ # value of gribDir defined in cfsr_convert.c				stopifnot(system2(command="ln", args=paste("-s", file.path(dir.cfsr.data, fname_gribDir), dir.grib)) == 0)			}			#Set up temporary directory for C code to store objects			if(file.exists(ftemp <- file.path(dir.in.cfsr, "temporary_dy"))) unlink(ftemp, recursive=TRUE)			temp <- lapply(lapply(c("tmax", "tmin", "ppt"), FUN=function(x) file.path(ftemp, x)), FUN=function(x) dir.create(x, recursive=TRUE, showWarnings=FALSE))			return(0)		}		temp <- .local()		res <- if(!inherits(temp, "try-error")) list(dir.in.cfsr=dir.in.cfsr, cfsr_so=fname_cfsr)  else temp		return(res)	}	# Wrapper functions for C code to access NCEP/CFSR data and write out to temporary files	gribDailyWeatherData <- function(id, do_daily, nSites, latitudes, longitudes) {		if(id %% 36 == 1) print(paste(Sys.time(), ": NCEP/CFSR extraction: year=", do_daily[id, "years"]))		gribData <- .C("dailyWeather2_R",							nSites = as.integer(nSites),							latitudes = as.double(latitudes),							longitudes = as.double(longitudes),							year = as.integer(do_daily[id, "years"]),							month = as.integer(do_daily[id, "months"]),							type = as.integer(do_daily[id, "types"]))		return(1)	}	writeDailyWeatherData <- function(year, nSites, siteNames, siteDirsC) {		dataWrite <- .C("dailyWeather2Write_R",							nSites = as.integer(nSites),							siteNames = as.character(siteNames),							siteDirs = as.character(siteDirsC),							year = as.integer(year))		return(1)	}	gribMonthlyClimate <- function(type, nSites, latitudes, longitudes, siteDirsC, yearLow, yearHigh) {		gribData <- .C("monthlyClimate2_R",							nSites = as.integer(nSites),							latitudes = as.double(latitudes),							longitudes = as.double(longitudes),							siteDirs = as.character(siteDirsC),							yearLow = as.integer(yearLow),							yearHigh = as.integer(yearHigh),							type = as.integer(type))		return(1)	}	writeMonthlyClimate <- function(id, siteDirsC) {		dataWrite <- .C("writeMonthlyClimate2_R", siteDir = as.character(siteDirsC[id]))		return(1)	}	get_NCEPCFSR_data <- function(dat_sites, daily=FALSE, monthly=FALSE, yearLow, yearHigh, n_site_per_core=100, cfsr_so, dir.in.cfsr, dir.temp, rm_mc_files=FALSE){	#str(dat_sites): 'data.frame':	n_sites obs. of  3 variables:	# $ WeatherFolder: chr  ...	# $ X_WGS84      : num  -117 -117 -117 -117 -120 ...	# $ Y_WGS84      : num  32.8 32.8 32.8 32.8 38.9 ...		# directory paths		dir.create(dir.temp.cfsr <- file.path(dir.temp, "temp_NCEFCFSR"), showWarnings=FALSE)		dir.temp.sites <- file.path(dir.temp.cfsr, dat_sites[, "WeatherFolder"])		temp <- lapply(dir.temp.sites, FUN=function(x) dir.create(x, showWarnings=FALSE))		dir.temp.sitesC <- gsub("/", "//", normalizePath(dir.temp.sites)) # C-style paths; they cannot be relative to ~		# prepare tasks		n_years <- (yearHigh - yearLow + 1)		n_sites <- nrow(dat_sites)		do_sites <- parallel::splitIndices(n_sites, ceiling(n_sites / n_site_per_core))#
		n_climvars <- n_dailyvars <- 3		do_daily <- expand.grid(types = seq_len(n_dailyvars) - 1, months = st_mo, years = yearLow:yearHigh)		# do the extractions, loop over chunks of sites		if (n_sites > 0) {			dtemp <- getwd()			setwd(dir.in.cfsr)			# set up parallel			if (parallel_runs && parallel_init) {				list.export <- c("load_NCEPCFSR_shlib", "cfsr_so", "dir.in.cfsr") #objects that need exporting to slaves				if (identical(parallel_backend, "mpi")) {					exportObjects(list.export)					mpi.bcast.cmd(load_NCEPCFSR_shlib(cfsr_so))					mpi.bcast.cmd(setwd(dir.in.cfsr))				}				if (identical(parallel_backend, "snow")) {					export_obj_local <- list.export[list.export %in% ls(name=environment())]					export_obj_in_parent <- list.export[list.export %in% ls(name=parent.frame())]					export_obj_in_parent <- export_obj_in_parent[!(export_obj_in_parent %in% export_obj_local)]					export_obj_in_globenv <- list.export[list.export %in% ls(name=.GlobalEnv)]					export_obj_in_globenv <- export_obj_in_globenv[!(export_obj_in_globenv %in% c(export_obj_local, export_obj_in_parent))]					stopifnot(c(export_obj_local, export_obj_in_parent, export_obj_in_globenv) %in% list.export)					if (length(export_obj_local) > 0) snow::clusterExport(cl, export_obj_local, envir=environment())					if (length(export_obj_in_parent) > 0) snow::clusterExport(cl, export_obj_in_parent, envir=parent.frame())					if (length(export_obj_in_globenv) > 0) snow::clusterExport(cl, export_obj_in_globenv, envir=.GlobalEnv)					snow::clusterEvalQ(cl, load_NCEPCFSR_shlib(cfsr_so))					snow::clusterEvalQ(cl, setwd(dir.in.cfsr))				}			}			for (k in seq_along(do_sites)) {				if(!be.quiet) print(paste(Sys.time(), ": NCEP/CFSR extraction of", if(daily) "daily", if(daily && monthly) "and", if(monthly) "monthly", "data: chunk", k, "of", length(do_sites)))				nDailyReads <- nDailyWrites <- nMonthlyReads <- nMonthlyWrites <- 0				ntemp <- length(do_sites[[k]])				irows <- do_sites[[k]]				longs <- dat_sites[irows, "X_WGS84"]				lats <- dat_sites[irows, "Y_WGS84"]				dtemp <- dir.temp.sitesC[irows]				if (print.debug) print(paste(Sys.time(), "cfsr chunk", k, ": # open R files", system2(command="lsof", args="-c R | wc -l", stdout=TRUE)))				if (parallel_runs && parallel_init) {					if (identical(parallel_backend, "mpi")) {						if (daily) {							nDailyReads <- mpi.applyLB(x=1:nrow(do_daily), fun=gribDailyWeatherData, do_daily=do_daily, nSites=ntemp, latitudes=lats, longitudes=longs)							nDailyReads <- do.call(sum, nDailyReads)							nDailyWrites <- mpi.applyLB(x=yearLow:yearHigh, fun=writeDailyWeatherData, nSites=ntemp, siteNames=dat_sites[irows, "WeatherFolder"], siteDirsC=dtemp)							nDailyWrites <- do.call(sum, nDailyWrites)						}						if (monthly) {							nMonthlyReads <- mpi.applyLB(x=0:(n_climvars-1), fun=gribMonthlyClimate, nSites=ntemp, latitudes=lats, longitudes=longs, siteDirsC=dtemp, yearLow=yearLow, yearHigh=yearHigh)							nMonthlyReads <- do.call(sum, nMonthlyReads)						}						if (monthly && k == length(do_sites)) { # only do at the end							nMonthlyWrites <- mpi.applyLB(x=1:n_sites, fun=writeMonthlyClimate, siteDirsC=dir.temp.sitesC)							nMonthlyWrites <- do.call(sum, nMonthlyWrites)						}					} else if (identical(parallel_backend, "snow")) {						if (daily) {							nDailyReads <- snow::clusterApplyLB(cl, x=1:nrow(do_daily), fun=gribDailyWeatherData, do_daily=do_daily, nSites=ntemp, latitudes=lats, longitudes=longs)							nDailyReads <- do.call(sum, nDailyReads)							nDailyWrites <- snow::clusterApplyLB(cl, x=yearLow:yearHigh, fun=writeDailyWeatherData, nSites=ntemp, siteNames=dat_sites[irows, "WeatherFolder"], siteDirsC=dtemp)							nDailyWrites <- do.call(sum, nDailyWrites)						}						if (monthly) {							nMonthlyReads <- snow::clusterApplyLB(cl, x=0:(n_climvars-1), fun=gribMonthlyClimate, nSites=ntemp, latitudes=lats, longitudes=longs, siteDirsC=dtemp, yearLow=yearLow, yearHigh=yearHigh)							nMonthlyReads <- do.call(sum, nMonthlyReads)						}						if (monthly && k == length(do_sites)) { # only do at the end							nMonthlyWrites <- snow::clusterApplyLB(cl, x=1:n_sites, fun=writeMonthlyClimate, siteDirsC=dir.temp.sitesC)							nMonthlyWrites <- do.call(sum, nMonthlyWrites)						}					} else if (identical(parallel_backend, "multicore")) {						if (daily) {							nDailyReads <- foreach(id = 1:nrow(do_daily), .combine="sum", .errorhandling="remove", .inorder=FALSE, .export=list.export) %dopar%								gribDailyWeatherData(id, do_daily=do_daily, nSites=ntemp, latitudes=lats, longitudes=longs)							nDailyWrites <- foreach(y = yearLow:yearHigh, .combine="sum", .errorhandling="remove", .inorder=FALSE, .export=list.export) %dopar%								writeDailyWeatherData(y, nSites=ntemp, siteNames=dat_sites[irows, "WeatherFolder"], siteDirsC=dtemp)						}						if (monthly) {							nMonthlyReads <- foreach(iv = 0:(n_climvars-1), .combine="sum", .errorhandling="remove", .inorder=FALSE, .export=list.export) %dopar%								gribMonthlyClimate(iv, nSites=ntemp, latitudes=lats, longitudes=longs, siteDirsC=dtemp, yearLow=yearLow, yearHigh=yearHigh)						}						if (monthly && k == length(do_sites)) { # only do at the end							nMonthlyWrites <- foreach(ic = 1:n_sites, .combine="sum", .errorhandling="remove", .inorder=FALSE, .export=list.export) %dopar%								writeMonthlyClimate(ic, siteDirsC=dir.temp.sitesC)						}					}				} else {					if (daily) {						nDailyReads <- foreach(id = 1:nrow(do_daily), .combine="sum", .errorhandling="remove", .inorder=FALSE) %do%							gribDailyWeatherData(id, do_daily=do_daily, nSites=ntemp, latitudes=lats, longitudes=longs)						nDailyWrites <- foreach(y = yearLow:yearHigh, .combine="sum", .errorhandling="remove", .inorder=FALSE) %do%							writeDailyWeatherData(y, nSites=ntemp, siteNames=dat_sites[irows, "WeatherFolder"], siteDirsC=dtemp)					}					if (monthly) {						nMonthlyReads <- foreach(iv = 0:(n_climvars-1), .combine="sum", .errorhandling="remove", .inorder=FALSE) %do%							gribMonthlyClimate(iv, nSites=ntemp, latitudes=lats, longitudes=longs, siteDirsC=dtemp, yearLow=yearLow, yearHigh=yearHigh)					}					if (monthly && k == length(do_sites)) { # only do at the end						nMonthlyWrites <- foreach(ic = 1:n_sites, .combine="sum", .errorhandling="remove", .inorder=FALSE) %do%							writeMonthlyClimate(ic, siteDirsC=dir.temp.sitesC)					}				}				# check that all was done				if (daily) stopifnot(nDailyReads == nrow(do_daily), nDailyWrites == n_years)				if (monthly) stopifnot(nMonthlyReads == n_climvars)			}			# check that all was done			if (monthly) stopifnot(nMonthlyWrites == n_sites)			# clean up parallel			if (parallel_runs && parallel_init){				if (identical(parallel_backend, "mpi")) {					mpi.bcast.cmd(rm(list=ls()))					mpi.bcast.cmd(gc())				}				if (identical(parallel_backend, "snow")) {					snow::clusterEvalQ(cl, rm(list=ls()))					snow::clusterEvalQ(cl, gc())				}			}			setwd(dtemp)		}#
		# concatenating the monthlyClimate csv files		if (monthly) {			res_clim <- data.frame(matrix(NA, nrow=n_sites, ncol=1 + n_climvars * 12))			colnames(res_clim) <- c("WeatherFolder", paste0("Cloud_m", st_mo), paste0("Wind_m", st_mo), paste0("RH_m", st_mo))			res_clim[, "WeatherFolder"] <- dat_sites[, "WeatherFolder"]			for (i in seq_len(n_sites)) {				ftemp <- file.path(dir.temp.sites[i], "mc.csv")				if (file.exists(ftemp)) {					table.mc <- read.csv(file=ftemp, comment="", stringsAsFactors=FALSE)					res_clim[i, 1 + st_mo] <- table.mc[, "Cloud_Cover"]					res_clim[i, 1 + 12 + st_mo] <- table.mc[, "Surface_Wind"]					res_clim[i, 1 + 24 + st_mo] <- table.mc[, "Rel_Humidity"]					if (rm_mc_files == TRUE) unlink(ftemp)				}			}		} else {			res_clim <- NULL		}		list(dir.temp.cfsr = dir.temp.cfsr, res_clim = res_clim)	}}#
#------------------------DAILY WEATHERif (extract_determine_database == "SWRunInformation" && "dailyweather_source" %in% colnames(SWRunInformation)) {	sites_dailyweather_source <- factor(SWRunInformation$dailyweather_source[runIDs_sites], levels=dailyweather_options)	do_weather_source <- anyNA(sites_dailyweather_source)} else {	sites_dailyweather_source <- factor(rep(NA, runsN_sites), levels=dailyweather_options)	do_weather_source <- TRUE}weather.digits <- 2lwf_cond1 <- sw_input_treatments_use$LookupWeatherFolder && sum(is.na(sw_input_treatments$LookupWeatherFolder[runIDs_sites])) == 0lwf_cond2 <- (sum(is.na(SWRunInformation$WeatherFolder[runIDs_sites])) == 0) && !any(as.logical(c(exinfo$GriddedDailyWeatherFromMaurer2002_NorthAmerica, exinfo$GriddedDailyWeatherFromDayMet_USA, exinfo$GriddedDailyWeatherFromNRCan_10km_Canada, exinfo$GriddedDailyWeatherFromNCEPCFSR_Global)))lwf_cond3 <- sw_input_experimentals_use$LookupWeatherFolder && sum(is.na(sw_input_experimentals$LookupWeatherFolder)) == 0lwf_cond4 <- any(create_treatments == "LookupWeatherFolder")if(any(lwf_cond1, lwf_cond2, lwf_cond3, lwf_cond4)){	#function to be executed for each SoilWat-run	#TODO replace with Rsoilwat31::getWeatherData_folders	ExtractLookupWeatherFolder <- function(dir.weather, weatherfoldername){		WeatherFolder <- file.path(dir.weather, weatherfoldername)		weath <- list.files(WeatherFolder, pattern="weath.")		stopifnot(!anyNA(years <- as.numeric(sub(pattern="weath.", replacement="", weath))))		weatherData <- list()		for(j in seq_along(weath)) {			data_sw <- as.matrix(read.table(file.path(WeatherFolder, weath[j]), header=FALSE, comment.char = "#", blank.lines.skip=TRUE, sep="\t"))			data_sw[, -1] <- round(data_sw[, -1], 2) #weather.digits			colnames(data_sw) <- c("DOY", "Tmax_C", "Tmin_C", "PPT_cm")			weatherData[[j]] <- new("swWeatherData", year=years[j], data = data.matrix(data_sw, rownames.force = FALSE))		}		names(weatherData) <- years		return(weatherData)	}}if(exinfo$GriddedDailyWeatherFromMaurer2002_NorthAmerica){	#extract daily weather information for the grid cell coded by latitude/longitude for each simulation run	#Citation: Maurer, E. P., A. W. Wood, J. C. Adam, D. P. Lettenmaier, and B. Nijssen. 2002. A long-term hydrologically based dataset of land surface fluxes and states for the conterminous United States. Journal of Climate 15:3237-3251.	dir.ex.maurer2002 <- file.path(dir.ex.weather,"Maurer+_2002updated","DAILY_FORCINGS")	stopifnot(file.exists(dir.ex.maurer2002))	create_filename_for_Maurer2002_NorthAmerica <- function(X_WGS84, Y_WGS84){		paste("data", formatC(28.8125+round((Y_WGS84-28.8125)/0.125,0)*0.125, digits=4, format="f"), formatC(28.8125+round((X_WGS84-28.8125)/0.125,0)*0.125, digits=4, format="f"), sep="_")	}#
	#function to be executed for each SoilWat-run	#' @return A list of which each element represents one year of daily weather data of class \linkS4class{swWeatherData}.	#' Units are [degree Celsius] for temperature and [cm / day] and for precipitation.	ExtractGriddedDailyWeatherFromMaurer2002_NorthAmerica <- function(cellname, startYear=simstartyr, endYear=endyr){		#read data from Maurer et al. 2002		weath.data <- try(read.table(file=file.path(dir.ex.maurer2002, cellname), comment.char=""), silent=TRUE)#
		if(!inherits(weath.data, "try-error")){			colnames(weath.data) <- c("year", "month", "day", "prcp_mm", "Tmax_C", "Tmin_C", "Wind_mPERs")			#times			date <- seq(from=as.Date(with(weath.data[1, ], paste(year, month, day, sep="-")), format="%Y-%m-%d"),					to=as.Date(with(weath.data[nrow(weath.data), ], paste(year, month, day, sep="-")), format="%Y-%m-%d"),					by="1 day")#
			# conversion precipitation: mm/day -> cm/day			data_all <- with(weath.data, data.frame(doy=1 + as.POSIXlt(date)$yday, Tmax_C, Tmin_C, prcp_mm/10))			colnames(data_all) <- c("DOY", "Tmax_C", "Tmin_C", "PPT_cm")			years <- startYear:endYear			n_years <- length(years)			if(!all(years %in% unique(weath.data$year)))				stop("simstartyr or endyr out of weather data range")			weathDataList <- list()			for(y in seq_along(years)) {				data_sw <- data_all[weath.data$year == years[y], ]				data_sw[, -1] <- round(data_sw[, -1], 2) #weather.digits				weathDataList[[y]]<-new("swWeatherData", data = data.matrix(data_sw, rownames.force = FALSE), year = years[y]) #strip row.names, otherwise they consume about 60% of file size			}			names(weathDataList) <- as.character(years)			weath.data <- weathDataList		}#
		weathDataList	}}if(exinfo$GriddedDailyWeatherFromDayMet_NorthAmerica){	# https://daymet.ornl.gov/	#extract daily weather information for the grid cell coded by latitude/longitude for each simulation run	#Citation	#	- article: Thornton, P.E., Running, S.W., White, M.A. 1997. Generating surfaces of daily meteorological variables over large regions of complex terrain. Journal of Hydrology 190: 214 - 251. http://dx.doi.org/10.1016/S0022-1694(96)03128-9	#	- dataset: Thornton, P.E., M.M. Thornton, B.W. Mayer, N. Wilhelmi, Y. Wei, R. Devarakonda, and R.B. Cook. 2014. Daymet: Daily Surface Weather Data on a 1-km Grid for North America, Version 2. ORNL DAAC, Oak Ridge, Tennessee, USA. Accessed Month DD, YYYY. Time period: YYYY-MM-DD to YYYY-MM-DD. Spatial range: N=DD.DD, S=DD.DD, E=DDD.DD, W=DDD.DD. http://dx.doi.org/10.3334/ORNLDAAC/1219	stopifnot(file.exists(dir.ex.daymet <- file.path(dir.ex.weather, "DayMet_NorthAmerica", "DownloadedSingleCells_FromDayMet_NorthAmerica")))	stopifnot(require(DaymetR)) #https://bitbucket.org/khufkens/daymetr	stopifnot(require(raster))	stopifnot(require(rgdal))	get_DayMet_cellID <- function(coords_WGS84) {		# Determine 1-km cell that contains requested location		res_DayMet <- 1000L		proj_LCC <- CRS("+proj=lcc +lat_1=25 +lat_2=60 +lat_0=42.5 +lon_0=-100 +x_0=0 +y_0=0 +datum=WGS84 +units=m +no_defs +ellps=WGS84 +towgs84=0,0,0")		proj_WGS84 <- CRS("+init=epsg:4326 +proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs +towgs84=0,0,0")		xy_LCC <- coordinates(spTransform(SpatialPoints(coords = coords_WGS84, proj4string = proj_WGS84), proj_LCC))		dm_LCC <- floor(xy_LCC / res_DayMet) # Origin at lower-lef corner (-2015000, -3037000)			## ==> (0, 0)- cell includes xlim = [0, 1000[ and ylim = [0, 1000[			## ==> at 100-m and 1-m scale: ok; but some deviations at 0.5-m scale		cellID <- apply(dm_LCC, 1, FUN = function(chr) paste0("daymet_pixel_",													if(chr[1] < 0) "-" else "+", formatC(abs(chr[1]), width=6, flag="0", format="d"), "_",													if(chr[2] < 0) "-" else "+", formatC(abs(chr[2]), width=6, flag="0", format="d")))		dm_LCC <- res_DayMet * dm_LCC + 500 # center of 1-km cells to avoid projection errors at cell margins		dm_WGS84 <- coordinates(spTransform(SpatialPoints(coords = dm_LCC, proj4string = proj_LCC), proj_WGS84))		return(list(cellID = cellID, dm_LCC = dm_LCC, dm_WGS84 = dm_WGS84))	}	#' @return A list of which each element represents one year of daily weather data of class \linkS4class{swWeatherData}.	#' Units are [degree Celsius] for temperature and [cm / day] and for precipitation.	get_DayMet_NorthAmerica <- function(cellID, Xdm_WGS84, Ydm_WGS84, start_year=simstartyr, end_year=endyr){		# Filename for data of this 1-km cell		ftemp <- file.path(dir.ex.daymet, paste0(cellID, "_", start_year, "_", end_year, ".csv"))		# Get data		pwd <- getwd()		get_from_ornl <- TRUE		if(file.exists(ftemp)){			dm_temp <- try(read.table(ftemp, sep = ",", skip = 6, header = TRUE), silent=TRUE)			if(!inherits(dm_temp, "try-error")) get_from_ornl <- FALSE		}		if(get_from_ornl){			setwd(dir.ex.daymet)			dm_temp <- try(DaymetR::download.daymet(site=cellID, lat=Ydm_WGS84, lon=Xdm_WGS84, start_yr=start_year, end_yr=end_year, internal=TRUE, quiet=TRUE), silent=TRUE)		}		# Convert to Rsoilwat format		if(!inherits(dm_temp, "try-error")){			if(exists(cellID, envir=.GlobalEnv)){				temp <- get(cellID, envir=.GlobalEnv)$data			} else if(!get_from_ornl && inherits(dm_temp, "data.frame")){				temp <- dm_temp			} else stop(paste("Daymet data not successful", cellID))			data_all <- with(temp, data.frame(year, yday, tmax..deg.c., tmin..deg.c., prcp..mm.day./10))			stopifnot(!anyNA(data_all), sum(data_all == -9999L) == 0)			template_sw <- data.frame(matrix(NA, nrow=366, ncol=4, dimnames=list(NULL, c("DOY", "Tmax_C", "Tmin_C", "PPT_cm"))))			years <- start_year:end_year			weathDataList <- list()			for(y in seq_along(years)){				data_sw <- template_sw				# All Daymet years, including leap years, have 1 - 365 days. For leap years, the Daymet database includes leap day. Values for December 31 are discarded from leap years to maintain a 365-day year.				data_sw[1:365, ] <- data_all[data_all$year == years[y], -1]				if(isLeapYear(years[y])){					data_sw[366, ] <- c(366, data_sw[365, -1])				}				data_sw[, -1] <- round(data_sw[, -1], 2) #weather.digits				weathDataList[[y]] <- new("swWeatherData", data=data.matrix(data_sw[if(isLeapYear(years[y])) 1:366 else 1:365, ], rownames.force=FALSE), year=years[y]) #strip row.names, otherwise they consume about 60% of file size			}			names(weathDataList) <- as.character(years)		} else {			weathDataList <- dm_temp		}		# Clean up		if(exists(cellID, envir=.GlobalEnv)) rm(list=cellID, envir=.GlobalEnv)		setwd(pwd)		weathDataList	}#
	if(getCurrentWeatherDataFromDatabase && createAndPopulateWeatherDatabase){		# Function to be executed for all SoilWat-sites together		#' @return An invisible zero. A list of which each element represents one year of daily weather data of class \linkS4class{swWeatherData}. The list is copied to the weather database.		#' Units are [degree Celsius] for temperature and [cm / day] and for precipitation.		ExtractGriddedDailyWeatherFromDayMet_NorthAmerica <- function(site_ids, coords_WGS84, start_year, end_year) {			if (!be.quiet) print(paste("Started 'ExtractGriddedDailyWeatherFromDayMet_NorthAmerica' at", Sys.time()))			# Check if weather data was previously partially extracted			wtemp_file <- file.path(dir.out.temp, "DayMet_weather_temp.rds")			site_ids_done <- if (file.exists(wtemp_file)) readRDS(wtemp_file) else NULL			iuse <- !(site_ids %in% site_ids_done)			if (sum(iuse) > 0) {				site_ids_todo <- site_ids[iuse]				xy_WGS84 <- coords_WGS84[iuse, , drop=FALSE]				dm <- get_DayMet_cellID(xy_WGS84)				#TODO: re-write for parallel processing (does it make sense to download in parallel?)				# Extract weather data sequentially for requested locations				for (idm in seq_along(site_ids_todo)) {					if (!be.quiet) print(paste(Sys.time(), "DayMet data extraction of site", site_ids_todo[idm], "at", paste(round(coords_WGS84[idm, ], 4), collapse="/")))					weatherData <- get_DayMet_NorthAmerica(cellID=dm$cellID[idm], Xdm_WGS84=dm$dm_WGS84[idm, 1], Ydm_WGS84=dm$dm_WGS84[idm, 2], start_year, end_year)#
					if (!inherits(weatherData, "try-error")) {						# Store site weather data in weather database						data_blob <- dbW_weatherData_to_blob(weatherData, type = dbW_compression_type)						Rsoilwat31:::dbW_addWeatherDataNoCheck(Site_id = site_ids_todo[idm],							Scenario_id = 1,							StartYear = start_year,							EndYear = end_year,							weatherData = data_blob)						site_ids_done <- c(site_ids_done, site_ids_todo[idm])						saveRDS(site_ids_done, file = wtemp_file)					} else {						warning(paste(Sys.time(), "DayMet data extraction NOT successful for site", site_ids_todo[idm]))					}				}			}			if (!be.quiet) print(paste("Finished 'ExtractGriddedDailyWeatherFromDayMet_NorthAmerica' at", Sys.time()))			invisible(0)		}#
	} else {		# Function to be executed for each SoilWat-run		ExtractGriddedDailyWeatherFromDayMet_NorthAmerica <- function(site_ids, coords_WGS84, start_year, end_year) {			xy_WGS84 <- matrix(unlist(coords_WGS84), ncol = 2)[1, , drop = FALSE]			dm <- get_DayMet_cellID(xy_WGS84)			get_DayMet_NorthAmerica(cellID=dm$cellID[1], Xdm_WGS84=dm$dm_WGS84[1, 1], Ydm_WGS84=dm$dm_WGS84[1, 2], start_year, end_year)		}	}}if(exinfo$GriddedDailyWeatherFromNRCan_10km_Canada && createAndPopulateWeatherDatabase){	#Citations:	#	- Hopkinson, R. F., D. W. McKenney, E. J. Milewska, M. F. Hutchinson, P. Papadopol, and L. A. Vincent. 2011. Impact of Aligning Climatological Day on Gridding Daily Maximum–Minimum Temperature and Precipitation over Canada. Journal of Applied Meteorology and Climatology 50:1654-1665.	#	- Hutchinson, M. F., D. W. McKenney, K. Lawrence, J. H. Pedlar, R. F. Hopkinson, E. Milewska, and P. Papadopol. 2009. Development and Testing of Canada-Wide Interpolated Spatial Models of Daily Minimum–Maximum Temperature and Precipitation for 1961–2003. Journal of Applied Meteorology and Climatology 48:725-741.	#	- McKenney, D. W., M. F. Hutchinson, P. Papadopol, K. Lawrence, J. Pedlar, K. Campbell, E. Milewska, R. F. Hopkinson, D. Price, and T. Owen. 2011. Customized Spatial Climate Models for North America. Bulletin of the American Meteorological Society 92:1611-1622.	dir.ex.NRCan <- file.path(dir.ex.weather, "NRCan_10km_Canada", "DAILY_GRIDS")	stopifnot(file.exists(dir.ex.NRCan), require(raster), require(sp), require(rgdal))	# Function to be executed for all SoilWat-sites together	#' @return An invisible zero. A list of which each element represents one year of daily weather data of class \linkS4class{swWeatherData}. The list is copied to the weather database.	#' Units are [degree Celsius] for temperature and [cm / day] and for precipitation.	ExtractGriddedDailyWeatherFromNRCan_10km_Canada <- function(site_ids, coords_WGS84, start_year, end_year) {		if(!be.quiet) print(paste("Started 'ExtractGriddedDailyWeatherFromNRCan_10km_Canada' at", Sys.time()))		NRC_years <- as.integer(list.dirs(path=dir.ex.NRCan, recursive=FALSE, full.names=FALSE))		NRC_target_years <- NRC_years[NRC_years %in% start_year:end_year]		stopifnot(start_year:end_year %in% NRC_target_years)		vars <- c("max", "min", "pcp") # units = C, C, mm/day		prj_geographicWGS84 <- CRS("+init=epsg:4326 +proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs +towgs84=0,0,0")		prj_geographicNAD83 <- CRS("+init=epsg:4269 +proj=longlat +ellps=GRS80 +datum=NAD83 +no_defs +towgs84=0,0,0")		sp_locs <- SpatialPoints(coords=coords_WGS84, proj4string=prj_geographicWGS84)		sp_locs <- spTransform(sp_locs, CRSobj=prj_geographicNAD83)		#TODO: re-write for parallel processing with other backends		if(parallel_runs && identical(parallel_backend, "snow")) beginCluster(n=num_cores, type="SOCK")		#TODO: re-write for a more memory friendly approach		# Check if weather data was partially extracted already		wtemp_file <- file.path(dir.out.temp, "NRCan_weather_temp.RData")		if(file.exists(wtemp_file)){			load(wtemp_file) # NRC_weather, iy			yr_offset <- iy			NRC_use_years <- NRC_target_years[-(1:iy)]		} else {			NRC_weather <- array(NA, dim=c(length(sp_locs), 366, length(NRC_target_years), 3), dimnames=list(NULL, NULL, NRC_target_years, c("Tmax(C)", "Tmin(C)", "PPT(mm)")))			NRC_use_years <- NRC_target_years			yr_offset <- 0		}		# Extract weather data for all locations together for each day of each year		pwd <- getwd()		for(iy in seq_along(NRC_use_years)){ # Loop through years			if(!be.quiet) print(paste(Sys.time(), "NRC data extraction of year", NRC_use_years[iy]))			setwd(file.path(dir.ex.NRCan, NRC_use_years[iy]))			NRC_days <- list.files() #find all days for this year			ndays <- length(NRC_days) / length(vars)			stopifnot(ndays == if(isLeapYear(NRC_use_years[iy])) 366 else 365)			# Stack rasters for each day and extract data			NRC_stack <- stack(NRC_days, RAT=FALSE, quick=TRUE)			projection(NRC_stack) <- prj_geographicNAD83			temp <- round(extract(NRC_stack, sp_locs), 2) #weather.digits; [sp_locs, NRC_days x vars]			# Convert extraction information to array			ivars <- substr(NRC_days, 1, 3) # sapply(vars, nchar) == 3			for(iv in seq_along(vars)){				idays <- as.integer(sapply(strsplit(NRC_days[vars[iv] == ivars], split="[_.]"), FUN=function(x) x[2]))				NRC_weather[, 1:ndays, yr_offset + iy, iv] <- temp[, which(vars[iv] == ivars)[order(idays)][1:ndays]]			}			save(NRC_weather, iy, file=wtemp_file)		}		setwd(pwd)		if(parallel_runs && identical(parallel_backend, "snow")) endCluster()#
		# Convert weather array to SoilWat weather objects for each sites		NRC_weather[, , , "PPT(mm)"] <- NRC_weather[, , , "PPT(mm)"] / 10	# convert from mm/day to cm/day#
		for (i in seq_along(site_ids)) {			if (!be.quiet && i %% 100 == 1)				print(paste(Sys.time(), "storing NRC weather data of site_id", site_ids[i], i, "of", length(site_ids), "sites in database"))#
			weatherData <- list()			for (iy in seq_along(NRC_target_years)) {				doys <- if (isLeapYear(NRC_use_years[iy])) 1:366 else 1:365				data_sw <- cbind(doys, NRC_weather[i, doys, iy, ]) #DOY Tmax(C) Tmin(C) PPT(cm) [ppt was converted from mm to cm]				colnames(data_sw) <- c("DOY", "Tmax_C", "Tmin_C", "PPT_cm")				weatherData[[iy]] <- new("swWeatherData", data = data.matrix(data_sw, rownames.force = FALSE), year = NRC_target_years[iy])			}			names(weatherData) <- as.character(NRC_target_years)			# Store site weather data in weather database			data_blob <- dbW_weatherData_to_blob(weatherData, dbW_weatherData_to_blob)			Rsoilwat31:::dbW_addWeatherDataNoCheck(Site_id = site_ids[i],				Scenario_id = 1,				StartYear = start_year,				EndYear = end_year,				weatherData = data_blob)		}		#unlink(file=wtemp_file)		if (!be.quiet) print(paste("Finished 'ExtractGriddedDailyWeatherFromNRCan_10km_Canada' at", Sys.time()))		rm(NRC_weather, weatherData, data_blob)		gc()		invisible(0)	}}if(exinfo$GriddedDailyWeatherFromNCEPCFSR_Global && createAndPopulateWeatherDatabase){	#Citations: Saha, S., et al. 2010. NCEP Climate Forecast System Reanalysis (CFSR) Selected Hourly Time-Series Products, January 1979 to December 2010. Research Data Archive at the National Center for Atmospheric Research, Computational and Information Systems Laboratory. http://dx.doi.org/10.5065/D6513W89.	# http://rda.ucar.edu/datasets/ds093.1/. Accessed 8 March 2012.	dir.ex.CFSR <- file.path(dir.ex.weather, "NCEPCFSR_Global", "CFSR_weather_prog08032012")	stopifnot(file.exists(dir.ex.CFSR))	prepd_CFSR <- prepare_NCEPCFSR_extraction(dir.cfsr.data=dir.ex.CFSR)	stopifnot(!inherits(prepd_CFSR, "try-error"))	# Function to be executed for all SoilWat-sites together	GriddedDailyWeatherFromNCEPCFSR_Global <- function(site_ids, dat_sites, start_year, end_year, rm_temp = TRUE) {		# do the extractions		etemp <- get_NCEPCFSR_data(dat_sites = dat_sites, daily=TRUE, monthly=FALSE, yearLow=start_year, yearHigh=end_year, n_site_per_core=100, cfsr_so=prepd_CFSR$cfsr_so, dir.in.cfsr=prepd_CFSR$dir.in.cfsr, dir.temp=dir.out.temp, rm_mc_files=TRUE)		# move the weather data into the database		for (i in seq_along(site_ids)) {			weatherData <- getWeatherData_folders(LookupWeatherFolder = etemp$dir.temp.cfsr,				weatherDirName = dat_sites[i, "WeatherFolder"],				filebasename = "weath",				startYear = start_year,				endYear = end_year)			# Store site weather data in weather database			data_blob <- dbW_weatherData_to_blob(weatherData, dbW_weatherData_to_blob)			Rsoilwat31:::dbW_addWeatherDataNoCheck(Site_id = site_ids[i],				Scenario_id = 1,				StartYear = start_year,				EndYear = end_year,				weatherData = data_blob)		}		if (rm_temp) {			dir.remove(etemp$dir.temp.cfsr)			temp <- lapply(c("ppt", "tmax", "tmin"), FUN=function(x) dir.remove(file.path(prepd_CFSR$dir.in.cfsr, "temporary_dy", x)))		}		if (!be.quiet) print(paste("Finished 'ExtractGriddedDailyWeatherFromNCEPCFSR_Global' at", Sys.time()))		invisible(0)	}}#
if(do_weather_source){	#Functions to determine sources of daily weather; they write to global 'sites_dailyweather_source' and 'sites_dailyweather_names', i.e., the last entry is the one that will be used	dw_LookupWeatherFolder <- function(){		if(any(lwf_cond1, lwf_cond2, lwf_cond3, lwf_cond4)){			# Check which requested lookup weather folders are available			pwd <- getwd()			setwd(file.path(dir.sw.in.tr, "LookupWeatherFolder"))			there <- rep(FALSE, times = runsN_sites)			if(lwf_cond1)				there <- there | sapply(runIDs_sites, FUN=function(ix) if(!is.na(sw_input_treatments$LookupWeatherFolder[ix])) file.exists(sw_input_treatments$LookupWeatherFolder[ix]) else FALSE)			if(lwf_cond2)				there <- there | sapply(runIDs_sites, FUN=function(ix) if(!is.na(SWRunInformation$WeatherFolder[ix])) file.exists(SWRunInformation$WeatherFolder[ix]) else FALSE)			if(lwf_cond3)				there <- there | rep(any(sapply(sw_input_experimentals$LookupWeatherFolder, FUN=function(ix) file.exists(sw_input_experimentals$LookupWeatherFolder))), times = runsN_sites)			setwd(pwd)			if(sum(there) > 0)				sites_dailyweather_source[there] <<- "LookupWeatherFolder"			if(!be.quiet) print(paste("Data for", sum(there), "sites will come from 'LookupWeatherFolder'"))		}		invisible(0)	}	dw_Maurer2002_NorthAmerica <- function(){		if(exinfo$GriddedDailyWeatherFromMaurer2002_NorthAmerica && (simstartyr >= 1949 && endyr <= 2010)){			# Check which requested Maurer weather data are available			Maurer <- with(SWRunInformation[runIDs_sites, ], create_filename_for_Maurer2002_NorthAmerica(X_WGS84, Y_WGS84))			there <- sapply(Maurer, FUN=function(im) file.exists(file.path(dir.ex.maurer2002, im)))			if(sum(there) > 0){				sites_dailyweather_source[there] <<- "Maurer2002_NorthAmerica"				sites_dailyweather_names[there] <<- paste0(SWRunInformation$Label[runIDs_sites][there], "_", Maurer[there])			}			if(!be.quiet) print(paste("Data for", sum(there), "sites will come from 'Maurer2002_NorthAmerica'"))		}		invisible(0)	}	dw_DayMet_NorthAmerica <- function(){		if(exinfo$GriddedDailyWeatherFromDayMet_NorthAmerica && (simstartyr >= 1980 && endyr <= as.POSIXlt(Sys.time())$year+1900 - 1)){			# Check which of the DayMet weather data are available			#	- Temperature: 2-meter air temperature in Celsius degrees			#	- Precipitation: mm/day; Daily total precipitation in millimeters per day, sum of all forms converted to water-equivalent. Precipitation occurrence on any given day may be ascertained.			#	- Grids domain: -131.104 	-52.95 	52.000 	14.53			#	- Grids: Geographic Coordinate Reference: WGS_1984; Projection: Lambert Conformal Conic			#	- Cells size: 1000 x 1000 m			#	- All Daymet years, including leap years, have 1 - 365 days. For leap years, the Daymet database includes leap day. Values for December 31 are discarded from leap years to maintain a 365-day year.			there <- (SWRunInformation[runIDs_sites, "X_WGS84"] >= -131.104 & SWRunInformation[runIDs_sites, "X_WGS84"] <= -52.95) & (SWRunInformation[runIDs_sites, "Y_WGS84"] >= 14.53 & SWRunInformation[runIDs_sites, "Y_WGS84"] <= 52)			if(sum(there) > 0){				sites_dailyweather_source[there] <<- "DayMet_NorthAmerica"				sites_dailyweather_names[there] <<- with(SWRunInformation[runIDs_sites[there], ], paste0(Label, "_DayMet", formatC(X_WGS84, digits=4, format="f"), "_", format(Y_WGS84, digits=4, format="f")))			}			if(!be.quiet) print(paste("Data for", sum(there), "sites will come from 'DayMet_NorthAmerica'"))		}		invisible(0)	}	dw_NRCan_10km_Canada <- function(){		if(exinfo$GriddedDailyWeatherFromNRCan_10km_Canada && (simstartyr >= 1950 && endyr <= 2013)){			# Check which of the NRCan weather data are available			#	- Temperature: Celsius degrees			#	- Precipitation: mm			#	- Grids domain: 141.00 to 52.00 W, 41.00 to 83.00 N			#	- Grids datum: geographic NAD83			#	- Columns: 1068, Rows: 510, Cells size: 0.083333333			nrc_test <- raster(file.path(dir.ex.NRCan, "1950", "max1950_1.asc"))			projection(nrc_test) <- CRS("+init=epsg:4269 +proj=longlat +ellps=GRS80 +datum=NAD83 +no_defs +towgs84=0,0,0") #	see http://spatialreference.org/ref/epsg/4269/			sp_locs <- SpatialPoints(coords=SWRunInformation[runIDs_sites, c("X_WGS84", "Y_WGS84")], proj4string=CRS("+init=epsg:4326 +proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs +towgs84=0,0,0"))			there <- !is.na(extract(nrc_test, y=spTransform(sp_locs, CRSobj=CRS(projection(nrc_test)))))			if(sum(there) > 0){				sites_dailyweather_source[there] <<- "NRCan_10km_Canada"				sites_dailyweather_names[there] <<- with(SWRunInformation[runIDs_sites[there], ], paste0(Label, "_NRCan", formatC(X_WGS84, digits=4, format="f"), "_", format(Y_WGS84, digits=4, format="f")))			}			if(!be.quiet) print(paste("Data for", sum(there), "sites will come from 'NRCan_10km_Canada'"))		}		invisible(0)	}	dw_NCEPCFSR_Global <- function(){		if(exinfo$GriddedDailyWeatherFromNCEPCFSR_Global && (simstartyr >= 1979 && endyr <= 2010)){			# Check which of the NCEPCFSR_Global weather data are available			#	- Grids domain: 0E to 359.688E and 89.761N to 89.761S			there <- (SWRunInformation[runIDs_sites, "X_WGS84"] >= 0 - 180 & SWRunInformation[runIDs_sites, "X_WGS84"] <= 360 - 180) & (SWRunInformation[runIDs_sites, "Y_WGS84"] >= -89.761 & SWRunInformation[runIDs_sites, "Y_WGS84"] <= 89.761)			if(sum(there) > 0){				sites_dailyweather_source[there] <<- "NCEPCFSR_Global"				sites_dailyweather_names[there] <<- with(SWRunInformation[runIDs_sites[there], ], paste0(Label, "_CFSR", formatC(X_WGS84, digits=4, format="f"), "_", format(Y_WGS84, digits=4, format="f")))			}			if(!be.quiet) print(paste("Data for", sum(there), "sites will come from 'NCEPCFSR_Global'"))		}		invisible(0)	}	#Determine order of priorities (highest priority comes last)	sites_dailyweather_names <- rep(NA, times=length(sites_dailyweather_source))	dailyweather_priorities <- rev(paste("dw", dailyweather_options, sep="_"))	for(idw in dailyweather_priorities) get(idw)()#
	if(anyNA(sites_dailyweather_source)){		if(FALSE){# remove sites with no weather; code to run by hand			xy <- SpatialPoints(coords=t(sapply(strsplit(list.files(dir.ex.maurer2002), "_"), FUN=function(x) as.numeric(x[3:2]))), proj4string=CRS("+init=epsg:4326 +proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs +towgs84=0,0,0"))			sp_locs2 <- spTransform(sp_locs, CRSobj=CRS(projection(nrc_test)))			plot(sp_locs2, pch=19, cex=0.5, col=c("blue", "red", "green", "purple", "black")[ifelse(is.na(sites_dailyweather_source),5,sites_dailyweather_source)])			plot(nrc_test, col=adjustcolor("orange", alpha.f=0.5), add=TRUE)			if(require(maps)) map("state", add=TRUE)			plot(xy, col=adjustcolor("darkgray", alpha.f=0.5), lwd=1, add=TRUE)			id_remove <- which(is.na(sites_dailyweather_source))			if(!be.quiet) print(paste("There are no daily weather data for", length(id_remove), "sites"))			SWRunInformation$Include_YN[runIDs_sites][id_remove] <- 0			write.csv(SWRunInformation, file=file.path(dir.in, datafile.SWRunInformation), row.names=FALSE)			unlink(file.path(dir.in, datafile.SWRWinputs_preprocessed))#
			stop(paste("Restart code because master file", datafile.SWRunInformation, "has changed"))		}	}	# Save information about weather source to disk file	SWRunInformation$WeatherFolder[runIDs_sites][!is.na(sites_dailyweather_names)] <- na.exclude(sites_dailyweather_names)	SWRunInformation$dailyweather_source[runIDs_sites] <- as.character(sites_dailyweather_source)	write.csv(SWRunInformation, file=file.path(dir.in, datafile.SWRunInformation), row.names=FALSE)	unlink(file.path(dir.in, datafile.SWRWinputs_preprocessed))}#
#------------------------CHECK THAT DAILY WEATHER DATA IS AVAILABLEif(anyNA(sites_dailyweather_source)){	stop("There are sites without daily weather. Provide data for all runs")}if(exinfo$ExtractClimateChangeScenarios_CMIP3_BCSD_GDODCPUCLLNL_USA || exinfo$ExtractClimateChangeScenarios_CMIP3_BCSD_GDODCPUCLLNL_Global || exinfo$ExtractClimateChangeScenarios_CMIP5_BCSD_GDODCPUCLLNL_USA || exinfo$ExtractClimateChangeScenarios_CMIP5_BCSD_GDODCPUCLLNL_Global || exinfo$ExtractClimateChangeScenarios_CMIP5_BCSD_NEX_USA) {	getScenarioWeatherDataFromDatabase <- TRUE	getCurrentWeatherDataFromDatabase <- TRUE}if(getScenarioWeatherDataFromDatabase)	getCurrentWeatherDataFromDatabase <- TRUEif(getCurrentWeatherDataFromDatabase){	if(!(createAndPopulateWeatherDatabase || file.exists(dbWeatherDataFile)))		stop("Create or use existing Weather database with Scenario data inside.")} else {	if(!any(create_treatments == "LookupWeatherFolder", as.logical(exinfo$GriddedDailyWeatherFromMaurer2002_NorthAmerica), as.logical(exinfo$GriddedDailyWeatherFromDayMet_NorthAmerica)))		stop("Daily weather data must be provided through 'LookupWeatherFolder', 'Maurer2002_NorthAmerica', or 'DayMet_NorthAmerica' since no weather database is used")}#
#------ Create the Database and Tables withinif(!be.quiet) print(paste("SWSF sets up the database: started at", t1 <- Sys.time()))name.OutputDB <- file.path(dir.out, "dbTables.sqlite3")if(copyCurrentConditionsFromDatabase | copyCurrentConditionsFromTempSQL) name.OutputDBCurrent <- file.path(dir.out, "dbTables_current.sqlite3")setwd(dir.prj)source(file.path(dir.code, "2_SWSF_p2of4_CreateDB_Tables_v51.R"), verbose = FALSE, chdir = FALSE)con <- DBI::dbConnect(RSQLite::SQLite(), dbname=name.OutputDB)if (getCurrentWeatherDataFromDatabase || getScenarioWeatherDataFromDatabase) {	# Check that version of dbWeather suffices	dbW_setConnection(dbWeatherDataFile)	v_dbW <- dbW_version()#
	if (v_dbW < minVersion_dbWeather) {		print(paste0("The version (", v_dbW, ") of the daily weather database is outdated; min. version required: ", minVersion_dbWeather))		if (v_dbW >= "1") print("Use function 'Rsoilwat31:::dbW_upgrade_v1to2' to upgrade your version 1.y.z weather database to version 2.0.0")		stop("Outdated weather database")	}#
}if(!be.quiet) print(paste("SWSF sets up the database: ended after",  round(difftime(Sys.time(), t1, units="secs"), 2), "s"))#------simulation timingoutput_timescales_shortest <- ifelse(any(simulation_timescales=="daily"), 1, ifelse(any(simulation_timescales=="weekly"), 2, ifelse(any(simulation_timescales=="monthly"), 3, 4)))simTiming <- function(startyr, simstartyr, endyr){	#simyrs <- simstartyr:endyr	#no.simyr <- endyr - simstartyr + 1	useyrs <- startyr:endyr	no.useyr <- endyr - startyr + 1	no.usemo <- no.useyr * 12	no.usedy <- as.numeric(as.POSIXlt(paste(endyr, "-12-31", sep="")) - as.POSIXlt(paste(startyr, "-01-01", sep=""))) + 1	discardyr <- startyr - simstartyr	discardmo <- discardyr * 12	discarddy <- as.numeric(as.POSIXlt(paste(startyr, "-01-01", sep="")) - as.POSIXlt(paste(simstartyr, "-01-01", sep="")))	index.useyr <- (discardyr+1):(discardyr+no.useyr)	index.usemo <- (discardmo+1):(discardmo+no.usemo)	index.usedy <- (discarddy+1):(discarddy+no.usedy)	return(list(useyrs=useyrs, no.useyr=no.useyr, index.useyr=index.useyr, index.usemo=index.usemo, index.usedy=index.usedy))}simTiming_ForEachUsedTimeUnit <- function(simTime, latitude=90){	#positive latitudes -> northern hemisphere; negative latitudes -> southern hemisphere	res <- NULL	if(any(simulation_timescales=="daily")){		temp <- as.POSIXlt(seq(from=as.POSIXlt(paste(min(simTime$useyrs), "-01-01", sep="")), to=as.POSIXlt(paste(max(simTime$useyrs), "-12-31", sep="")), by="1 day"))		res$doy_ForEachUsedDay <- res$doy_ForEachUsedDay_NSadj <- temp$yday + 1		res$month_ForEachUsedDay <- res$month_ForEachUsedDay_NSadj <- temp$mon + 1		res$year_ForEachUsedDay <- res$year_ForEachUsedDay_NSadj <- temp$year + 1900		if(latitude < 0 && accountNSHemispheres_agg){			dshift <- as.POSIXlt(paste(simTime$useyrs, 6, 30, sep="-"))$yday+1	#new month either at end of year or in the middle because the two halfs (6+6 months) of a year are of unequal length (182 (183 if leap year) and 183 days): I chose to have a new month at end of year (i.e., 1 July -> 1 Jan & 30 June -> 31 Dec; but, 1 Jan -> July 3/4): and instead of a day with doy=366, there are two with doy=182			res$doy_ForEachUsedDay_NSadj <- unlist(lapply(seq(along=simTime$useyrs), FUN=function(x) c((temp <- res$doy_ForEachUsedDay[simTime$useyrs[x] == res$year_ForEachUsedDay])[-(1:dshift[x])], temp[1:dshift[x]])))			res$month_ForEachUsedDay_NSadj <- strptime(paste(res$year_ForEachUsedDay, res$doy_ForEachUsedDay_NSadj, sep="-"), format="%Y-%j")$mon + 1			res$year_ForEachUsedDay_NSadj <- c(rep(simTime$useyrs[1]-1, times=dshift[1] + ifelse(dshift[1] == 182, 2, 3)), res$year_ForEachUsedDay[-(((temp <- length(res$year_ForEachUsedDay)) - dshift[1] - ifelse(dshift[1] == 182, 1, 2)):temp)])		}	}	if(any(simulation_timescales=="weekly")){	}	if(any(simulation_timescales=="monthly")){		res$yearno_ForEachUsedMonth <- res$yearno_ForEachUsedMonth_NSadj <- rep(1:simTime$no.useyr, each=12)		res$month_ForEachUsedMonth <- res$month_ForEachUsedMonth_NSadj <- rep(st_mo, times=simTime$no.useyr)		if(latitude < 0 && accountNSHemispheres_agg){			res$month_ForEachUsedMonth_NSadj <- (res$month_ForEachUsedMonth + 5) %% 12 + 1		}	}	if(any(simulation_timescales=="yearly")){	}	return(res)}simTime <- simTiming(startyr, simstartyr, endyr)simTime_ForEachUsedTimeUnit_North <- simTiming_ForEachUsedTimeUnit(simTime, latitude=90)if(accountNSHemispheres_agg){	simTime_ForEachUsedTimeUnit_South <- simTiming_ForEachUsedTimeUnit(simTime, latitude=-90)} else {	simTime_ForEachUsedTimeUnit_South <- simTime_ForEachUsedTimeUnit_North}#
#------auxiliary functionsadjustLayersDepth <- function(layers_depth, d) return(round(layers_depth[1:d])) #The wrapper only handles 1-cm resolution of soil depths (maily because of the trco)getLayersWidth <- function(layers_depth) return(diff(c(0, layers_depth)))setLayerSequence <- function(d) return(1:d)sw_dailyC4_TempVar <- function(dailyTempMin, dailyTempMean, simTime2){	#Variables to estimate percent C4 species in North America: Teeri JA, Stowe LG (1976) Climatic patterns and the distribution of C4 grasses in North America. Oecologia, 23, 1-12.	Month7th_MinTemp_C <- aggregate(dailyTempMin[simTime2$month_ForEachUsedDay_NSadj == 7], by=list(simTime2$year_ForEachUsedDay_NSadj[simTime2$month_ForEachUsedDay_NSadj == 7]), FUN=min)[, 2]	LengthFreezeFreeGrowingPeriod_Days <- aggregate(dailyTempMin, by=list(simTime2$year_ForEachUsedDay_NSadj), FUN=function(x) {temp <- rle(x > 0); if(any(temp$values)) max(temp$lengths[temp$values], na.rm=TRUE) else 0})[, 2]	DegreeDaysAbove65F_DaysC <- aggregate(dailyTempMean, by=list(simTime2$year_ForEachUsedDay_NSadj), FUN=function(x) sum(ifelse((temp <- x - ((65-32) * 5/9)) > 0, temp, 0)))[, 2]	nyrs <- seq_along(Month7th_MinTemp_C) #if southern Hemisphere, then 7th month of last year is not included	res <- c(apply(temp <- cbind(Month7th_MinTemp_C[nyrs], LengthFreezeFreeGrowingPeriod_Days[nyrs], DegreeDaysAbove65F_DaysC[nyrs]), MARGIN=2, FUN=mean), apply(temp, MARGIN=2, FUN=sd))	names(res) <- c(temp <- c("Month7th_NSadj_MinTemp_C", "LengthFreezeFreeGrowingPeriod_NSadj_Days", "DegreeDaysAbove65F_NSadj_DaysC"), paste(temp, ".sd", sep=""))	return(res)}sw_SiteClimate_Ambient <- function(weatherList, year.start, year.end, do.C4vars=FALSE, simTime2=NULL) {	sw.weather.suffices <- as.numeric(names(weatherList))	itemp <- year.start <= sw.weather.suffices & year.end >= sw.weather.suffices	years <- sw.weather.suffices[itemp]	tempMean <- tempMin <- tempMax <- ppt <- rep(0, times=12)	mat <- NULL	if(do.C4vars){		dailyTempMin <- NULL		dailyTempMean <- NULL	}	if((no.yrs <- length(years)) > 0) for(y in 1:no.yrs){			temp.dailyTempMean <- apply(get_swWeatherData(weatherList, years[y])@data[, 2:3], 1, mean)			temp.dailyTempMin <- get_swWeatherData(weatherList, years[y])@data[, 3]			temp.dailyTempMax <- get_swWeatherData(weatherList, years[y])@data[, 2]			mat <- c(mat, mean(temp.dailyTempMean))			if(do.C4vars){				dailyTempMin <- c(dailyTempMin, get_swWeatherData(weatherList, years[y])@data[, 3])				dailyTempMean <- c(dailyTempMean, temp.dailyTempMean)			}			month_forEachDoy <- as.POSIXlt(seq(from=as.POSIXlt(paste(years[y], "-01-01", sep="")), to=as.POSIXlt(paste(years[y], "-12-31", sep="")), by="1 day"))$mon + 1			if (years[y] == 1942 ){			  month_forEachDoy<-c(month_forEachDoy,12)			}			tempMean <- tempMean + aggregate(temp.dailyTempMean, by=list(month_forEachDoy), FUN=mean)[, 2]			tempMin <- tempMin + aggregate(temp.dailyTempMin, by=list(month_forEachDoy), FUN=mean)[, 2]			tempMax <- tempMax + aggregate(temp.dailyTempMax, by=list(month_forEachDoy), FUN=mean)[, 2]			ppt <- ppt + aggregate(get_swWeatherData(weatherList, years[y])@data[, 4], by=list(month_forEachDoy), FUN=sum)[, 2]		}	tempMean <- tempMean / no.yrs	tempMin <- tempMin / no.yrs	tempMax <- tempMax / no.yrs	ppt <- ppt / no.yrs	res <- list(meanMonthlyTempC=tempMean, minMonthlyTempC=tempMin, maxMonthlyTempC=tempMax,				meanMonthlyPPTcm=ppt, MAP_cm=sum(ppt), MAT_C=mean(mat))	if(do.C4vars){		res$dailyTempMin <- dailyTempMin		res$dailyTempMean <- dailyTempMean		res$dailyC4vars <- sw_dailyC4_TempVar(dailyTempMin, dailyTempMean, simTime2)	}	return(res)}PotentialNaturalVegetation_CompositionShrubsC3C4_Paruelo1996 <- function(MAP_mm,MAT_C,monthly.ppt,monthly.temp,dailyC4vars,isNorth,shrub.fraction.limit,		use_Annuals_Fraction,Annuals_Fraction,		use_C4_Fraction,C4_Fraction,		use_C3_Fraction,C3_Fraction,		use_Shrubs_Fraction,Shrubs_Fraction,		use_Forbs_Fraction, Forbs_Fraction,		use_BareGround_Fraction, BareGround_Fraction) {	cut0Inf <- function(x) {x[x < 0] <- NA; return(x)}	NAto0 <- function(x) {x[is.na(x)] <- 0; return(x)}	finite01 <- function(x) {x[x < 0 | is.na(x)] <- 0; x[x > 1] <- 1; return(x)}	f.digits <- 3	tolerance <- 1.1*10^-f.digits	#Get the user specified fractions, if column is false set to NA	tree.fraction <- 0 #option 'PotentialNaturalVegetation_CompositionShrubsC3C4_Paruelo1996' doesn't estimate tree cover, i.e., assumed to be == 0	forb.fraction <- 0	bareGround.fraction <- 0	AnnC4C3ShrubForbBareGroundFraction <- rep(NA, 6)	if(use_Annuals_Fraction){		AnnC4C3ShrubForbBareGroundFraction[1] <- finite01(Annuals_Fraction)	} else {		AnnC4C3ShrubForbBareGroundFraction[1] <- 0 #Annuals can not be NA	}	if(use_C4_Fraction)		AnnC4C3ShrubForbBareGroundFraction[2] <- C4_Fraction	if(use_C3_Fraction)		AnnC4C3ShrubForbBareGroundFraction[3] <- C3_Fraction	if(use_Shrubs_Fraction)		AnnC4C3ShrubForbBareGroundFraction[4] <- Shrubs_Fraction	if(use_Forbs_Fraction) {		AnnC4C3ShrubForbBareGroundFraction[5] <- finite01(Forbs_Fraction)	} else {		AnnC4C3ShrubForbBareGroundFraction[5] <- forb.fraction	}	if(use_BareGround_Fraction) {		AnnC4C3ShrubForbBareGroundFraction[6] <- finite01(BareGround_Fraction)	} else {		AnnC4C3ShrubForbBareGroundFraction[6] <- bareGround.fraction	}	AnnC4C3ShrubForbBareGroundFraction <- cut0Inf(AnnC4C3ShrubForbBareGroundFraction) #treat negatives as if NA	TotalFraction <- sum(AnnC4C3ShrubForbBareGroundFraction, na.rm=TRUE)	#Decide if all fractions are sufficiently defined or if they need to be calculated based on climate variables	if(!isTRUE(all.equal(TotalFraction, 1, tolerance=tolerance)) && TotalFraction < 1 && sum(is.na(AnnC4C3ShrubForbBareGroundFraction)) == 0) {		stop(print(paste(i, " run: User defined fractions of Shrub, C3, C4, Annuals are all set, but less than 1", sep=""))) #throw an error	}	if(isTRUE(all.equal(TotalFraction, 1, tolerance=tolerance)) || TotalFraction > 1 || sum(is.na(AnnC4C3ShrubForbBareGroundFraction)) == 1){		if(sum(is.na(AnnC4C3ShrubForbBareGroundFraction)) == 1){ #if only one is NA, then this can be calculated			AnnC4C3ShrubForbBareGroundFraction[which(is.na(AnnC4C3ShrubForbBareGroundFraction))] <- cut0Inf(1 - TotalFraction)		} else {			AnnC4C3ShrubForbBareGroundFraction <- finite01(AnnC4C3ShrubForbBareGroundFraction) #the composition is >= 1, so set eventually remaining NA to 0		}		TotalFraction <- sum(AnnC4C3ShrubForbBareGroundFraction, na.rm=TRUE)		AnnC4C3ShrubForbBareGroundFraction <- AnnC4C3ShrubForbBareGroundFraction / TotalFraction #Rescale, in case it is needed	} else { #i.e., (TotalFraction < 1 && sum(is.na(AnnC4C3ShrubForbBareGroundFraction)) > 1) is TRUE; thus, calculate some fractions based on climate variables		if(isNorth){ #Northern hemisphere			Months_WinterTF <- c(12, 1:2)			Months_SummerTF <- c(6:8)		} else {			Months_WinterTF <- c(6:8)			Months_SummerTF <- c(12, 1:2)		}		ppt.SummerToMAP <- sum(monthly.ppt[Months_SummerTF]) / MAP_mm		ppt.WinterToMAP <- sum(monthly.ppt[Months_WinterTF]) / MAP_mm		#---Potential natural vegetation		#1. step: Paruelo JM, Lauenroth WK (1996) Relative abundance of plant functional types in grasslands and shrublands of North America. Ecological Applications, 6, 1212-1224.		if(MAP_mm < 1){			shrubs.fractionNA <- NA		} else {			shrubs.fractionNA <- cut0Inf(1.7105 - 0.2918 * log(MAP_mm) + 1.5451 * ppt.WinterToMAP) 								#if NA, then not enough winter precipitation above a given MAP		}		if(MAT_C <= 0){			grass.c4.fractionNA <- 0		} else {			grass.c4.fractionNA <- cut0Inf(-0.9837 + 0.000594 * MAP_mm + 1.3528 * ppt.SummerToMAP + 0.2710 * log(MAT_C))			#if NA, then either MAT < 0 or not enough summer precipitation or too cold below a given MAP		}		if(ppt.WinterToMAP <= 0){			grass.c3ingrasslands.fractionNA <- grass.c3inshrublands.fractionNA <- NA		} else {			grass.c3ingrasslands.fractionNA <- cut0Inf(1.1905 - 0.02909 * MAT_C + 0.1781 * log(ppt.WinterToMAP) - 0.2383 * 1)		#if NA, then not enough winter precipitation or too warm below a given MAP			grass.c3inshrublands.fractionNA <- cut0Inf(1.1905 - 0.02909 * MAT_C + 0.1781 * log(ppt.WinterToMAP) - 0.2383 * 2)		}		grass.c3.fractionNA <- ifelse(shrubs.fractionNA >= shrub.fraction.limit && !is.na(shrubs.fractionNA), grass.c3inshrublands.fractionNA, grass.c3ingrasslands.fractionNA)		grass.Annual.fraction <- AnnC4C3ShrubForbBareGroundFraction[1] #Ann will be 0 or something <= 1		#2. step: Teeri JA, Stowe LG (1976) Climatic patterns and the distribution of C4 grasses in North America. Oecologia, 23, 1-12.		#This equations give percent species/vegetation -> use to limit Paruelo's C4 equation, i.e., where no C4 species => there are no C4 abundance > 0		if(dailyC4vars["LengthFreezeFreeGrowingPeriod_NSadj_Days"] <= 0){			grass.c4.species <- 0		} else {			x10 <- dailyC4vars["Month7th_NSadj_MinTemp_C"] * 9/5 + 32			x13 <- dailyC4vars["DegreeDaysAbove65F_NSadj_DaysC"] * 9/5			x18 <- log(dailyC4vars["LengthFreezeFreeGrowingPeriod_NSadj_Days"])			grass.c4.species <- as.numeric((1.60 * x10 + 0.0086 * x13 - 8.98 * x18 - 22.44) / 100)		}		grass.c4.fractionNA <- ifelse(grass.c4.species >= 0, grass.c4.fractionNA, NA)		#3. step: Replacing missing values: If no or only one successful equation, then add 100% C3 if MAT < 10 C, 100% shrubs if MAP < 600 mm, and 100% C4 if MAT >= 10C & MAP >= 600 mm	[these rules are made up arbitrarily by drs, Nov 2012]		if(sum(!is.na(shrubs.fractionNA), !is.na(grass.c4.fractionNA), !is.na(grass.c3.fractionNA)) <= 1){			if(MAP_mm < 600) shrubs.fractionNA <- 1 + ifelse(is.na(shrubs.fractionNA), 0, shrubs.fractionNA)			if(MAT_C < 10)  grass.c3.fractionNA <- 1 + ifelse(is.na(grass.c3.fractionNA), 0, grass.c3.fractionNA)			if(MAT_C >= 10  & MAP_mm >= 600)  grass.c4.fractionNA <- 1 + ifelse(is.na(grass.c4.fractionNA), 0, grass.c4.fractionNA)		}		#4. step: Scale fractions to 0-1 with a sum of 1 including grass.Annual.fraction, but don't scale grass.Annual.fraction		#if na then use calc fraction else use the user defined fraction		shrubs.fraction <- NAto0(shrubs.fractionNA)		grass.c4.fraction <- NAto0(grass.c4.fractionNA)		grass.c3.fraction <- NAto0(grass.c3.fractionNA)		sumVegWithoutAnnuals <- shrubs.fraction + grass.c4.fraction + grass.c3.fraction		shrubs.fraction <- (shrubs.fraction / sumVegWithoutAnnuals) * (1 - grass.Annual.fraction) #scale these down to 1-annual fraction		grass.c4.fraction <- (grass.c4.fraction / sumVegWithoutAnnuals) * (1 - grass.Annual.fraction)		grass.c3.fraction <- (grass.c3.fraction / sumVegWithoutAnnuals) * (1 - grass.Annual.fraction)		calcAnnC4C3ShrubForbBareGroundFraction <- c(grass.Annual.fraction, grass.c4.fraction, grass.c3.fraction, shrubs.fraction)		naIndex <- which(is.na(AnnC4C3ShrubForbBareGroundFraction))		#replace missing values		if(isTRUE(all.equal(sum(calcAnnC4C3ShrubForbBareGroundFraction[naIndex]), 0)) && isTRUE(all.equal(temp <- sum(AnnC4C3ShrubForbBareGroundFraction[!naIndex]), 0))){ #there would be no vegetation, so force vegetation > 0			AnnC4C3ShrubForbBareGroundFraction[naIndex] <- (1 - temp) / length(naIndex)		} else {			AnnC4C3ShrubForbBareGroundFraction[naIndex] <- calcAnnC4C3ShrubForbBareGroundFraction[naIndex]		}		#now we need to get the sum and scale the naIndex values accordingly		AnnC4C3ShrubForbBareGroundFraction[naIndex] <- sapply(AnnC4C3ShrubForbBareGroundFraction[naIndex], function(x) (x/sum(AnnC4C3ShrubForbBareGroundFraction[naIndex])) * (1-sum(AnnC4C3ShrubForbBareGroundFraction[-naIndex])))	}	#Scale Grass components to one (or set to 0)	if(!isTRUE(all.equal(sum(AnnC4C3ShrubForbBareGroundFraction[4:6]), 1))){		grass.c4.fractionG <- AnnC4C3ShrubForbBareGroundFraction[2] / (1-sum(AnnC4C3ShrubForbBareGroundFraction[4:6]))		grass.c3.fractionG <- AnnC4C3ShrubForbBareGroundFraction[3] / (1-sum(AnnC4C3ShrubForbBareGroundFraction[4:6]))		grass.Annual.fractionG <- AnnC4C3ShrubForbBareGroundFraction[1] / (1-sum(AnnC4C3ShrubForbBareGroundFraction[4:6]))	} else {		grass.c4.fractionG <- grass.c3.fractionG <- grass.Annual.fractionG <- 0	}	grass.fraction <- sum(AnnC4C3ShrubForbBareGroundFraction[c(1:3)])	return(list("Composition"=c("Grasses"=grass.fraction, "Shrubs"=AnnC4C3ShrubForbBareGroundFraction[4], "Trees"=tree.fraction, "Forbs"=AnnC4C3ShrubForbBareGroundFraction[5], "BareGround"=AnnC4C3ShrubForbBareGroundFraction[6]),"grasses.c3c4ann.fractions"=c(grass.c3.fractionG,grass.c4.fractionG,grass.Annual.fractionG)))}AdjMonthlyBioMass <- function(tr_VegetationComposition,AdjMonthlyBioMass_Temperature,AdjMonthlyBioMass_Precipitation,grasses.c3c4ann.fractions,growing.season.threshold.tempC,isNorth,MAP_mm,monthly.temp) {	tr_VegComp_Adj <- tr_VegetationComposition	#Default shrub biomass input is at MAP = 450 mm/yr, and default grass biomass input is at MAP = 340 mm/yr	#Describe conditions for which the default vegetation biomass values are valid	std.winter <- c(11:12, 1:2) #Assumes that the "growing season" (valid for growing.season.threshold.tempC == 4) in 'tr_VegetationComposition' starts in March and ends after October, for all functional groups.	std.growing <- st_mo[-std.winter] #Assumes that the "growing season" in 'tr_VegetationComposition' starts in March and ends after October, for all functional groups.	#Default site for the grass description is SGS LTER	StandardGrasses_MAP_mm <- 340	StandardGrasses_VegComposition <- c(0.12, 0.22, 0.66) #Fraction of shrubs, C3, and C4	#Default site for the shrub description is Reynolds Creek, ID	StandardShrub_MAP_mm <- 250	StandardShrub_VegComposition <- c(0.7, 0.3, 0) #Fraction of shrubs, C3, and C4	#Calculate 'live biomass amount'	tr_VegComp_Adj$Sh.Amount.Live <- tr_VegComp_Adj$Sh.Biomass * tr_VegComp_Adj$Sh.Perc.Live	tr_VegComp_Adj$C3.Amount.Live <- tr_VegComp_Adj$C3.Biomass * tr_VegComp_Adj$C3.Perc.Live	tr_VegComp_Adj$C4.Amount.Live <- tr_VegComp_Adj$C4.Biomass * tr_VegComp_Adj$C4.Perc.Live	tr_VegComp_Adj$Annual.Amount.Live <- tr_VegComp_Adj$Annual.Biomass * tr_VegComp_Adj$Annual.Perc.Live	#Scale monthly values of litter and live biomass amount by column-max; total biomass will be back calculated from 'live biomass amount' / 'percent live'	colmax <- apply(tr_VegComp_Adj[, itemp <- grepl("Litter", names(tr_VegComp_Adj)) | grepl("Amount.Live", names(tr_VegComp_Adj))], MARGIN=2, FUN=max)	colmin <- apply(tr_VegComp_Adj[, itemp], MARGIN=2, FUN=min)	tr_VegComp_Adj[, itemp] <- sweep(tr_VegComp_Adj[, itemp], MARGIN=2, STATS=colmax, FUN="/")	#Pull different composition types	shrubs_Composition <- shrubs_Standard <- tr_VegComp_Adj[, grepl("Sh", names(tr_VegComp_Adj))]	C3_Composition <- C3_Standard <- tr_VegComp_Adj[, grepl("C3", names(tr_VegComp_Adj))]	C4_Composition <- C4_Standard <- tr_VegComp_Adj[, grepl("C4", names(tr_VegComp_Adj))]	AnnGrass_Composition <- AnnGrass_Standard <- tr_VegComp_Adj[, grepl("Annual", names(tr_VegComp_Adj))]	adjCompPPT <- function(shrubs_Composition, C3_Composition, C4_Composition, AnnGrass_Composition, ShrubsMAP_mm, GrassMAP_mm) {		#Equations: Milchunas & Lauenroth 1993 (Fig. 2): Y [g/m2/yr] = c1 * MAP [mm/yr] + c2		Shrub_ANPP <- function(MAP_mm) 0.393 * MAP_mm - 10.2		Grass_ANPP <- function(MAP_mm) 0.646 * MAP_mm - 102.5		#Intercepts to match outcomes of M & L 1993 equations under 'default' MAP with our previous default inputs for shrubs and sgs-grasslands		#Whereas these intercepts were introduced artificially, they could also be interpreted as perennial storage, e.g., Lauenroth & Whitman (1977) found "Accumulation in the standing dead was 63% of inputs, in the litter 8%, and belowground 37%.". Lauenroth, W.K. & Whitman, W.C. (1977) Dynamics of dry matter production in a mixed-grass prairie in western North Dakota. Oecologia, 27, 339-351.		Shrub_ANPPintercept <- (StandardShrub_VegComposition[1]*colmax["Sh.Amount.Live"] + StandardShrub_VegComposition[2]*colmax["C3.Amount.Live"] + StandardShrub_VegComposition[3]*colmax["C4.Amount.Live"]) - Shrub_ANPP(StandardShrub_MAP_mm)	#Default input for shrubs (IM_USC00107648_Reynolds; 70% shrubs, 30% C3): biomass was estimated at MAP = 450 mm/yr		Grasses_ANPPintercept <- (StandardGrasses_VegComposition[1]*colmax["Sh.Amount.Live"] + StandardGrasses_VegComposition[2]*colmax["C3.Amount.Live"] + StandardGrasses_VegComposition[3]*colmax["C4.Amount.Live"]) - Grass_ANPP(StandardGrasses_MAP_mm)		#Default input for sgs-grassland (GP_SGSLTER; 12% shrubs, 22% C3, and 66% C4): biomass was estimated at MAP = 340 mm/yr		#Get scaling values for scaled biomass; guarantee that > minimum.totalBiomass		minimum.totalBiomass <- 0 #This is a SoilWat parameter		Shrub_BiomassScaler <- max(minimum.totalBiomass, Shrub_ANPP(ShrubsMAP_mm) + Shrub_ANPPintercept)		Grass_BiomassScaler <- max(minimum.totalBiomass, Grass_ANPP(GrassMAP_mm) + Grasses_ANPPintercept)		#Scale live biomass amount by productivity; assumption: ANPP = peak standing live biomass		shrubs_Composition$Sh.Amount.Live <- shrubs_Composition$Sh.Amount.Live * Shrub_BiomassScaler		C3_Composition$C3.Amount.Live <- C3_Composition$C3.Amount.Live * Grass_BiomassScaler		C4_Composition$C4.Amount.Live <- C4_Composition$C4.Amount.Live * Grass_BiomassScaler		AnnGrass_Composition$Annual.Amount.Live <- AnnGrass_Composition$Annual.Amount.Live * Grass_BiomassScaler		#Scale litter amount by productivity and adjust for ratio of litter/live		shrubs_Composition$Sh.Litter <- shrubs_Composition$Sh.Litter * Shrub_BiomassScaler * colmax["Sh.Litter"] / colmax["Sh.Amount.Live"]		C3_Composition$C3.Litter <- C3_Composition$C3.Litter * Grass_BiomassScaler * colmax["C3.Litter"] / colmax["C3.Amount.Live"]		C4_Composition$C4.Litter <- C4_Composition$C4.Litter * Grass_BiomassScaler * colmax["C4.Litter"] / colmax["C4.Amount.Live"]		AnnGrass_Composition$Annual.Litter <- AnnGrass_Composition$Annual.Litter * Grass_BiomassScaler * colmax["Annual.Litter"] / colmax["Annual.Amount.Live"]		#Guarantee that live fraction = ]0, 1]		shrubs_Composition$Sh.Perc.Live <- pmin(1, pmax(sqrt(.Machine$double.eps), shrubs_Composition$Sh.Perc.Live))		C3_Composition$C3.Perc.Live <- pmin(1, pmax(sqrt(.Machine$double.eps), C3_Composition$C3.Perc.Live))		C4_Composition$C4.Perc.Live <- pmin(1, pmax(sqrt(.Machine$double.eps), C4_Composition$C4.Perc.Live))		AnnGrass_Composition$Annual.Perc.Live <- pmin(1, pmax(sqrt(.Machine$double.eps), AnnGrass_Composition$Annual.Perc.Live))		#Calculate total biomass based on scaled live biomass amount		shrubs_Composition$Sh.Biomass <- shrubs_Composition$Sh.Amount.Live / shrubs_Composition$Sh.Perc.Live		C3_Composition$C3.Biomass <- C3_Composition$C3.Amount.Live / C3_Composition$C3.Perc.Live		C4_Composition$C4.Biomass <- C4_Composition$C4.Amount.Live / C4_Composition$C4.Perc.Live		AnnGrass_Composition$Annual.Biomass <- AnnGrass_Composition$Annual.Amount.Live / AnnGrass_Composition$Annual.Perc.Live		return(list("shrubs_Composition"=shrubs_Composition,"C3_Composition"=C3_Composition,"C4_Composition"=C4_Composition,"AnnGrass_Composition"=AnnGrass_Composition))	}	#adjust phenology for mean monthly temperatures	if(AdjMonthlyBioMass_Temperature) {		growing.season <- monthly.temp >= growing.season.threshold.tempC		if(!isNorth) growing.season <- c(growing.season[7:12], growing.season[1:6]) #Standard growing season needs to be adjusted for southern Hemi		predict.season <- function(biomass_Standard, std.season.padded, std.season.seq, site.season.seq){			#length(std.season.seq) >= 3 because of padding and test that season duration > 0			calc.loess_coeff <- function(N, span){				#prevent call to loessc.c:ehg182(104): "span too small.   fewer data values than degrees of freedom"				lcoef <- list(span=min(1, span), degree=2)				if(span > 1) return(lcoef)				nf <- floor(lcoef$span * N) - 1 #see R/trunk/src/library/stats/src/loessf.f:ehg136()				if(nf > 2){					lcoef$degree <- 2				} else if(nf > 1){					lcoef$degree <- 1				} else {					lcoef <- calc.loess_coeff(N, lcoef$span+0.1)				}				return(lcoef)			}			lcoef <- calc.loess_coeff(N=length(std.season.seq), span=0.4)			op <- options(c("warn", "error"))			options(warn=-1, error=traceback) #loess throws many warnings: 'pseudoinverse used', see calc.loess_coeff(), etc.			res <- sapply(apply(biomass_Standard, MARGIN=2, function(x) {lf<-loess(x[std.season.padded] ~ std.season.seq, span=lcoef$span, degree=lcoef$degree); predict(lf, newdata=data.frame(std.season.seq=site.season.seq) ) }), FUN=function(x) max(0, x)) # guarantee that > 0			options(op)			return(res)		}		#Adjust for timing and duration of non-growing season		if(sum(!growing.season) > 0) {			if(sum(!growing.season) < 12) {				std.winter.padded <- (c(std.winter[1] - 1, std.winter, std.winter[length(std.winter)] + 1) - 1) %% 12 + 1				std.winter.seq <- 0:(length(std.winter.padded) - 1)				site.winter.seq <- seq(from=1, to=length(std.winter), length=sum(!growing.season))				site.winter.start <- (temp3 <- (temp2 <- cumsum(c(0, (rtemp <- rle(!growing.season))$lengths))+1)[-length(temp2)][rtemp$values])[length(temp3)] #Calculate first month of winter				site.winter.months <- (site.winter.start + 1:sum(!growing.season) - 2) %% 12 + 1				shrubs_Composition[site.winter.months,] <- predict.season(shrubs_Standard, std.winter.padded, std.winter.seq, site.winter.seq)				C3_Composition[site.winter.months,] <- predict.season(C3_Standard, std.winter.padded, std.winter.seq, site.winter.seq)				C4_Composition[site.winter.months,] <- predict.season(C4_Standard, std.winter.padded, std.winter.seq, site.winter.seq)				AnnGrass_Composition[site.winter.months,] <- predict.season(AnnGrass_Standard, std.winter.padded, std.winter.seq, site.winter.seq)			} else { #if winter lasts 12 months				#Take the mean of the winter months				shrubs_Composition[] <- matrix(apply(shrubs_Standard[std.winter,], 2, mean), nrow=12, ncol=ncol(shrubs_Composition), byrow=TRUE)				C3_Composition[] <- matrix(apply(C3_Standard[std.winter,], 2, mean), nrow=12, ncol=ncol(C3_Composition), byrow=TRUE)				C4_Composition[] <- matrix(apply(C4_Standard[std.winter,], 2, mean), nrow=12, ncol=ncol(C4_Composition), byrow=TRUE)				AnnGrass_Composition[] <- matrix(apply(AnnGrass_Standard[std.winter,], 2, mean), nrow=12, ncol=ncol(AnnGrass_Composition), byrow=TRUE)			}		}		#Adjust for timing and duration of growing season		if(sum(growing.season)>0) {			if(sum(growing.season) < 12) {				std.growing.padded <- (c(std.growing[1] - 1, std.growing, std.growing[length(std.growing)] + 1) - 1) %% 12 + 1				std.growing.seq <- 0:(length(std.growing.padded) - 1)				site.growing.seq <- seq(from=1, to=length(std.growing), length=sum(growing.season))				site.growing.start <- (temp3 <- (temp2 <- cumsum(c(0, (rtemp <- rle(growing.season))$lengths))+1)[-length(temp2)][rtemp$values])[1] #Calculate first month of growing season				site.growing.months <- (site.growing.start + 1:sum(growing.season) - 2) %% 12 + 1				shrubs_Composition[site.growing.months,] <- predict.season(shrubs_Standard, std.growing.padded, std.growing.seq, site.growing.seq)				C3_Composition[site.growing.months,] <- predict.season(C3_Standard, std.growing.padded, std.growing.seq, site.growing.seq)				C4_Composition[site.growing.months,] <- predict.season(C4_Standard, std.growing.padded, std.growing.seq, site.growing.seq)				AnnGrass_Composition[site.growing.months,] <- predict.season(AnnGrass_Standard, std.growing.padded, std.growing.seq, site.growing.seq)			} else { #if growing season lasts 12 months				shrubs_Composition[] <- matrix(apply(shrubs_Standard[std.growing,], MARGIN=2, FUN=max), nrow=12, ncol=ncol(shrubs_Composition), byrow=TRUE)				C3_Composition[] <- matrix(apply(C3_Standard[std.growing,], MARGIN=2, FUN=max), nrow=12, ncol=ncol(C3_Composition), byrow=TRUE)				C4_Composition[] <- matrix(apply(C4_Standard[std.growing,], MARGIN=2, FUN=max), nrow=12, ncol=ncol(C4_Composition), byrow=TRUE)				AnnGrass_Composition[] <- matrix(apply(AnnGrass_Standard[std.growing,], MARGIN=2, FUN=max), nrow=12, ncol=ncol(AnnGrass_Composition), byrow=TRUE)			}		}		if(!isNorth) { #Adjustements were done as if on nothern hemisphere			shrubs_Composition <- rbind(shrubs_Composition[7:12,], shrubs_Composition[1:6,])			C3_Composition <- rbind(C3_Composition[7:12,], C3_Composition[1:6,])			C4_Composition <- rbind(C4_Composition[7:12,], C4_Composition[1:6,])			AnnGrass_Composition <- rbind(AnnGrass_Composition[7:12,], AnnGrass_Composition[1:6,])		}		if(!AdjMonthlyBioMass_Precipitation){			temp<-adjCompPPT(shrubs_Composition,C3_Composition,C4_Composition,AnnGrass_Composition,ShrubsMAP_mm=StandardShrub_MAP_mm, GrassMAP_mm=StandardGrasses_MAP_mm)			shrubs_Composition <- temp$shrubs_Composition			C3_Composition <- temp$C3_Composition			C4_Composition <- temp$C4_Composition			AnnGrass_Composition <- temp$AnnGrass_Composition		}	}	#Adjust biomass amounts by productivity relationship with MAP	if(AdjMonthlyBioMass_Precipitation) {		temp<-adjCompPPT(shrubs_Composition,C3_Composition,C4_Composition,AnnGrass_Composition,ShrubsMAP_mm=MAP_mm, GrassMAP_mm=MAP_mm)		shrubs_Composition <- temp$shrubs_Composition		C3_Composition <- temp$C3_Composition		C4_Composition <- temp$C4_Composition		AnnGrass_Composition <- temp$AnnGrass_Composition	}	Grass_Composition <- C3_Composition*grasses.c3c4ann.fractions[1] + C4_Composition*grasses.c3c4ann.fractions[2] + AnnGrass_Composition*grasses.c3c4ann.fractions[3]	return(list("grass"=as.matrix(Grass_Composition),"shrub"=as.matrix(shrubs_Composition)))}#
#Circular functions: int=number of units in circle, e.g., for days: int=365; for months: int=12circ.mean <- function(x, int, na.rm=FALSE){	if(length(x) == sum(is.na(x))){		return(NA)	} else {		require(circular)		circ <- 2 * pi / int		x.circ <- circular(x * circ, type="angles", units="radians", rotation="clock", modulo="2pi")		x.int <- mean.circular(x.circ, na.rm=na.rm) / circ		rm(circ, x.circ)		return(round(as.numeric(x.int) - 1, 13) %% int + 1)	# map 0 -> int; rounding to 13 digits: 13 was empirically derived for int={12, 365} and x=c((-1):2, seq(x-5, x+5, by=1), seq(2*x-5, 2*x+5, by=1)) assuming that this function will never need to calculate for x > t*int with t>2	}}circ.range <- function(x, int, na.rm=FALSE) {	if(length(x) == sum(is.na(x))){		return(NA)	} else {		require(circular)		circ <- 2 * pi / int		x.circ <- circular(x * circ, type="angles", units="radians", rotation="clock", modulo="2pi")		x.int <- range(x.circ, na.rm=na.rm) / circ		rm(circ, x.circ)		return(as.numeric(x.int))	}}circ.sd <- function(x, int, na.rm=FALSE){	if(length(x) == sum(is.na(x)) || sum(!is.na(x)) == 1){		return(NA)	} else if(sd(x, na.rm=TRUE) == 0){		return(0)	} else {		require(circular)		circ <- 2 * pi / int		x.circ <- circular(x * circ, type="angles", units="radians", rotation="clock", modulo="2pi")		x.int <- sd.circular(x.circ, na.rm=na.rm) / circ		rm(circ, x.circ)		return(as.numeric(x.int))	}}#
#functions wet and dry periodsmax.duration <- function(x) {	r <- rle(x)	if(length(temp <- which(r$values==1)) > 0){		rmax <- max(r$lengths[temp])	} else {		rmax <- 0	}	return(rmax)}startDoyOfDuration <- function(x, duration=10) {	r <- rle(x)	if(length(r$lengths)==1 | sum(r$values==1 & r$lengths>=duration)==0 ){		return (ifelse((length(r$lengths)==1 & (r$values==0 | r$lengths<duration)) | sum(r$values==1 & r$lengths>=10)==0, NA, 1)[1])	} else {		first10dry <- r$lengths[which(r$values==1 & r$lengths>=duration)][1] #pick first period		if( !is.na(first10dry) ){			ind <- which(r$lengths==first10dry & r$values==1)[1] #always pick start of first suitable period		} else {			ind <- -1		}		if(ind==1) {#start of period at beginning of year			return(1)		} else if(ind==-1) {#no period this year			return(NA)		} else {			return(cumsum(r$lengths)[ind-1]+1)		}	}}endDoyAfterDuration <- function(x, duration=10) {	r <- rle(x)	if(length(r$lengths)==1 | sum(r$values==1 & r$lengths>=duration)==0 ){		return (ifelse((length(r$lengths)==1 & (r$values==0 | r$lengths<duration)) | sum(r$values==1 & r$lengths>=duration)==0, 365, NA)[1])	} else {		last10dry <- (rl <- r$lengths[which(r$values==1 & r$lengths>=duration)])[length(rl)] #pick last period		if( length(last10dry) > 0 ){			ind <- (temp <- which(r$lengths==last10dry & r$values==1))[length(temp)]	#always pick end of last suitable period		} else {			ind <- -1		}		if(ind==-1) {#no period this year			return(NA)		} else {			return(cumsum(r$lengths)[ind])		}	}}#convert SWP(matric) to VWC(matric), e.g., to calculate field capacity and wilting pointSWPtoVWC <- function(swp, sand, clay) {#Cosby, B. J., G. M. Hornberger, R. B. Clapp, and T. R. Ginn. 1984. A statistical exploration of the relationships of soil moisture characteristics to the physical properties of soils. Water Resources Research 20:682-690.	#1. SWP in MPa [single value] + sand and clay in fraction [single values] --> VWC in fraction [single value]	#2. SWP in MPa [single value] + sand and clay in fraction [vectors of length d] --> VWC in fraction [vector of length d]	#3. SWP in MPa [vector of length l] + sand and clay in fraction [single values] --> VWC in fraction [vector of length l]	#4. SWP in MPa [vector of length l] + sand and clay in fraction [vectors of length d] --> VWC in fraction [matrix with nrow=l and ncol=d, SWP vector repeated for each column]: probably not used	#5. SWP in MPa [matrix with nrow=l and ncol=d] + sand and clay in fraction [single values] --> VWC in fraction [matrix with nrow=l and ncol=d]	#6. SWP in MPa [matrix with nrow=l and ncol=d] + sand and clay in fraction [vectors of length d] --> VWC in fraction [matrix with nrow=l and ncol=d, sand/clay vector repeated for each row]#input: sand and clay as fraction of matric volume, i.e, they don't need to be scaled with gravel	stopifnot(length(sand) && length(sand) == length(clay))	na.act <- na.action(na.exclude(apply(data.frame(sand, clay), MARGIN=1, FUN=sum)))	if(length(sand) > length(na.act)){		na.index <- as.vector(na.act)		if(length(na.index) > 0){			sand <- sand[-na.index]			clay <- clay[-na.index]		}		thetas <- -14.2 * sand - 3.7 * clay + 50.5		psis <- 10 ^ (-1.58 * sand - 0.63 * clay + 2.17)		b <- -0.3 * sand + 15.7 * clay + 3.10		if(any(b <= 0)) stop("b <= 0")		bar_conversion <- 1024		MPa_toBar <- -10		get_vector <- function(swp, sand, clay, thetas=thetas, psis=psis, b=b, do.na=TRUE){#either swp or sand/clay needs be a single value			vwc <- ifelse(!is.na(swp) & swp <= 0 & sand <= 1 & sand >= 0 & clay <= 1 & clay >= 0, thetas * (psis / (swp * MPa_toBar * bar_conversion))^(1/b) / 100, NA)			if(do.na & length(na.index) > 0){				vwc <- napredict(na.act, vwc)			}			return(vwc)		}		if(is.null(dim(swp))){			if(length(swp) == 1 & length(sand) >= 1 | length(swp) >= 1 & length(sand) == 1){ #cases 1-3				vwc <- get_vector(swp, sand, clay, thetas=thetas, psis=psis, b=b)			} else if(length(swp) > 1 & length(sand) > 1){ #case 4				vwc <- t(sapply(1:length(swp), FUN=function(d) get_vector(swp[d], sand, clay, thetas=thetas, psis=psis, b=b)))			}		} else {			if(length(sand) == 1){ #case 5				vwc <- sapply(1:ncol(swp), FUN=function(d) get_vector(swp[, d], sand, clay, thetas=thetas, psis=psis, b=b))			} else { #case 6				sand <- napredict(na.act, sand)				clay <- napredict(na.act, clay)				stopifnot(ncol(swp) == length(sand))				psis <- napredict(na.act, psis)				thetas <- napredict(na.act, thetas)				b <- napredict(na.act, b)				vwc <- sapply(1:ncol(swp), FUN=function(d) get_vector(swp[, d], sand[d], clay[d], thetas=thetas[d], psis=psis[d], b=b[d], do.na=FALSE))			}		}	} else {		vwc <- swp		vwc[!is.na(vwc)] <- NA	}	return(vwc) #fraction m3/m3 [0, 1]}#convert VWC(matric) to SWP(matric)VWCtoSWP <- function(vwc, sand, clay) {#Cosby, B. J., G. M. Hornberger, R. B. Clapp, and T. R. Ginn. 1984. A statistical exploration of the relationships of soil moisture characteristics to the physical properties of soils. Water Resources Research 20:682-690.	#1. VWC in fraction [single value] + sand and clay in fraction [single values] --> SWP in MPa [single value]	#2. VWC in fraction [single value] + sand and clay in fraction [vectors of length d] --> SWP in MPa [vector of length d]	#3. VWC in fraction [vector of length l] + sand and clay in fraction [single values] --> SWP in MPa [vector of length l]	#4. VWC in fraction [vector of length l] + sand and clay in fraction [vectors of length d] --> SWP in MPa [matrix with nrow=l and ncol=d, VWC vector repeated for each column]: probably not used	#5. VWC in fraction [matrix with nrow=l and ncol=d] + sand and clay in fraction [single values] --> SWP in MPa [matrix with nrow=l and ncol=d]	#6. VWC in fraction [matrix with nrow=l and ncol=d] + sand and clay in fraction [vectors of length d] --> SWP in MPa [matrix with nrow=l and ncol=d, sand/clay vector repeated for each row]#input: sand and clay as fraction of matric volume, i.e, they don't need to be scaled with gravel	stopifnot(length(sand) && length(sand) == length(clay))	na.act <- na.action(na.exclude(apply(data.frame(sand, clay), MARGIN=1, FUN=sum)))	if(length(sand) > length(na.act)){		na.index <- as.vector(na.act)		if(length(na.index) > 0){			sand <- sand[-na.index]			clay <- clay[-na.index]		}		thetas <- -14.2 * sand - 3.7 * clay + 50.5		psis <- 10 ^ (-1.58 * sand - 0.63 * clay + 2.17)		b <- -0.3 * sand + 15.7 * clay + 3.10		if(any(b <= 0)) stop("b <= 0")		bar_conversion <- 1024		bar_toMPa <- -1/10		get_vector <- function(vwc, sand, clay, thetas=thetas, psis=psis, b=b, do.na=TRUE){#either vwc or sand/clay needs be a single value			swp <- ifelse(!is.na(vwc) & vwc <= 1 & vwc >= 0 & sand <= 1 & sand >= 0 & clay <= 1 & clay >= 0, psis / ((vwc*100/thetas) ^ b * bar_conversion) * bar_toMPa, NA)			if(do.na & length(na.index) > 0){				swp <- napredict(na.act, swp)			}			return(swp)		}		if(is.null(dim(vwc))){			if(length(vwc) == 1 & length(sand) >= 1 | length(vwc) >= 1 & length(sand) == 1){ #cases 1-3				swp <- get_vector(vwc, sand, clay, thetas=thetas, psis=psis, b=b)			} else if(length(vwc) > 1 & length(sand) > 1){ #case 4				swp <- t(sapply(1:length(vwc), FUN=function(d) get_vector(vwc[d], sand, clay, thetas=thetas, psis=psis, b=b)))			}		} else {			if(length(sand) == 1){ #case 5				swp <- sapply(1:ncol(vwc), FUN=function(d) get_vector(vwc[, d], sand, clay, thetas=thetas, psis=psis, b=b))			} else { #case 6				sand <- napredict(na.act, sand)				clay <- napredict(na.act, clay)				stopifnot(ncol(vwc) == length(sand))				psis <- napredict(na.act, psis)				thetas <- napredict(na.act, thetas)				b <- napredict(na.act, b)				swp <- sapply(1:ncol(vwc), FUN=function(d) get_vector(vwc[, d], sand[d], clay[d], thetas=thetas[d], psis=psis[d], b=b[d], do.na=FALSE))			}		}	} else {		swp <- vwc		swp[!is.na(swp)] <- NA	}	return(swp) #MPa [-Inf, 0]}#two, three, or four layer aggregation for average daily aggregation outputsetAggSoilLayerForAggDailyResponses <- function(layers_depth){	d <- length(layers_depth)	vals <- list()	#first layer	DeepestFirstDailyAggLayer <- findInterval(Depth_FirstAggLayer.daily, c(0, layers_depth) + sqrt(.Machine$double.eps), all.inside=TRUE)	vals[[1]] <- 1:DeepestFirstDailyAggLayer	#second layer	if(!is.null(Depth_SecondAggLayer.daily)){		DeepestSecondDailyAggLayer <- findInterval(Depth_SecondAggLayer.daily, c(0, layers_depth) + sqrt(.Machine$double.eps), all.inside=TRUE)	} else {		DeepestSecondDailyAggLayer <- d	}	if(is.numeric(DeepestSecondDailyAggLayer) && is.numeric(DeepestFirstDailyAggLayer) && d > DeepestFirstDailyAggLayer){		vals[[2]] <- (DeepestFirstDailyAggLayer+1):DeepestSecondDailyAggLayer	}	#third layer	if(!is.null(Depth_ThirdAggLayer.daily)){		if(!is.na(Depth_ThirdAggLayer.daily)){			DeepestThirdDailyAggLayer <- findInterval(Depth_ThirdAggLayer.daily, c(0, layers_depth) + sqrt(.Machine$double.eps), all.inside=TRUE)		} else {			DeepestThirdDailyAggLayer <- NULL		}	} else {		DeepestThirdDailyAggLayer <- d	}	if(is.numeric(DeepestThirdDailyAggLayer) && is.numeric(DeepestSecondDailyAggLayer) && d > DeepestSecondDailyAggLayer){		vals[[3]] <- (DeepestSecondDailyAggLayer+1):DeepestThirdDailyAggLayer	}	#fourth layer	if(!is.null(Depth_FourthAggLayer.daily)){		if(!is.na(Depth_FourthAggLayer.daily)){			DeepestFourthDailyAggLayer <- findInterval(Depth_FourthAggLayer.daily, c(0, layers_depth) + sqrt(.Machine$double.eps), all.inside=TRUE)		} else {			DeepestFourthDailyAggLayer <- NULL		}	} else {		DeepestFourthDailyAggLayer <- d	}	if(is.numeric(DeepestFourthDailyAggLayer) && is.numeric(DeepestThirdDailyAggLayer) && d > DeepestThirdDailyAggLayer){		vals[[4]] <- ((DeepestThirdDailyAggLayer+1):DeepestFourthDailyAggLayer)	}	return(vals)}#
#function to extrapolate windspeeds measured at heights different than SoilWat required 2-m above groundadjust.WindspeedHeight <- function(uz, height){	# Allen RG, Walter IA, Elliott R, Howell T, Itenfisu D, Jensen M (2005) In The ASCE standardized reference evapotranspiration equation, pp. 59. ASCE-EWRI Task Committee Report.	# input: windspeed [m/s] at height x	# output: windspeed [m/s] at height 2 m	stopifnot(all(uz >= 0) && height >= 2 )	return( uz * 4.87 / log(67.8 * height - 5.42) )	# eqn. 33 in Allen et al. (2005)}#
#--------------------------------------------------------------------------------------------------##------------------------OBTAIN INFORMATION FROM EXTERNAL DATASETS PRIOR TO SIMULATION RUNS TO CREATE THEMif(any(actions == "external") && any(exinfo[!grepl("GriddedDailyWeather", names(exinfo))] > 0)){	setwd(dir.prj)	if(!be.quiet) print(paste("SWSF extracts information from external datasets prior to simulation runs: started at", t1 <- Sys.time()))	stopifnot(file.exists(dir.external))	source(file.path(dir.code, "2_SWSF_p3of4_ExternalDataExtractions_v51.R"), verbose = FALSE, chdir = FALSE)	if(!be.quiet) print(paste("SWSF extracts information from external datasets prior to simulation runs: ended after",  round(difftime(Sys.time(), t1, units="secs"), 2), "s"))}#
#--------------------------------------------------------------------------------------------------##------------------------OBTAIN INFORMATION FROM TABLES PRIOR TO SIMULATION RUNS TO CREATE THEM#------obtain information prior to simulation runsif(any(actions == "create")){	if(!be.quiet) print(paste("SWSF obtains information prior to simulation runs: started at", t1 <- Sys.time()))	if(any(create_treatments == "LookupEvapCoeffFromTable")){		#lookup bare soil evaporation coefficients per soil layer per distribution type for each simulation run and copy values to 'datafile.soils'		get.LookupEvapCoeffFromTable <- function(evco_type, sw_input_soils_use, sw_input_soils){			#extract data from table by category			table.EvapCoeff <- matrix(data=unlist(sapply(evco_type, FUN=function(i) {tr_input_EvapCoeff[which(rownames(tr_input_EvapCoeff) == as.character(i)), 1:SoilLayer_MaxNo]})), ncol=SoilLayer_MaxNo, byrow=TRUE)			#add data to sw_input_soils and set the use flags			i.temp <- grepl(pattern="EvapCoeff", x=names(sw_input_soils_use))			tr.col.max <- max(rowSums(!is.na(table.EvapCoeff)))			sw_input_soils[, i.temp][1:tr.col.max] <- ifelse(!is.na(table.EvapCoeff[, 1:tr.col.max]), table.EvapCoeff[, 1:tr.col.max], 0)			sw_input_soils[, i.temp][(tr.col.max+1):SoilLayer_MaxNo] <- NA			sw_input_soils_use[i.temp][1:tr.col.max] <- 1			sw_input_soils_use[i.temp][(tr.col.max+1):SoilLayer_MaxNo] <- 0			return(list(sw_input_soils_use=sw_input_soils_use, sw_input_soils=sw_input_soils))		}		if( !(any(names(sw_input_experimentals)[sw_input_experimentals_use == 1] == "LookupEvapCoeffFromTable")) ){#Use only if option is off in sw_input_experimentals and on in treatments			if(any(is.na(sw_input_treatments$LookupEvapCoeffFromTable))) stop("ERROR: LookupEvapCoeffFromTable column in treatments cannot have any NAs.")			if(!all(unique(sw_input_treatments$LookupEvapCoeffFromTable) %in% rownames(tr_input_EvapCoeff))) stop("ERROR: LookupEvapCoeffFromTable column values in treatments do not match up with trfile.LookupEvapCoeffFromTable row names.")			tempdat <- get.LookupEvapCoeffFromTable(evco_type=sw_input_treatments$LookupEvapCoeffFromTable, sw_input_soils_use=sw_input_soils_use, sw_input_soils=sw_input_soils)			sw_input_soils_use <- tempdat$sw_input_soils_use			sw_input_soils <- tempdat$sw_input_soils			#write data to datafile.soils			write.csv(rbind(sw_input_soils_use, sw_input_soils), file=file.path(dir.sw.dat, datafile.soils), row.names=FALSE)			unlink(file.path(dir.in, datafile.SWRWinputs_preprocessed))		}	}	if(any(create_treatments == "LookupTranspRegionsFromTable")){		#lookup transpiration region per soil layer per distribution type for each simulation run and copy values to 'datafile.soils'		get.LookupTranspRegionsFromTable <- function(trtype, sw_input_soils_use, sw_input_soils){			#extract data from table by type			table.TranspReg <- matrix(data=unlist(sapply(trtype, FUN=function(i) {tr_input_TranspRegions[which(rownames(tr_input_TranspRegions) == as.character(i)), 1:SoilLayer_MaxNo]})), ncol=SoilLayer_MaxNo, byrow=TRUE)			#add data to sw_input_soils and set the use flags			i.temp <- grepl(pattern="TranspRegion", x=names(sw_input_soils_use))			tr.col.max <- max(rowSums(!is.na(table.TranspReg)))			sw_input_soils[, i.temp][1:tr.col.max] <- table.TranspReg[, 1:tr.col.max]			sw_input_soils[, i.temp][(tr.col.max+1):SoilLayer_MaxNo] <- NA			sw_input_soils_use[i.temp][1:tr.col.max] <- 1			sw_input_soils_use[i.temp][(tr.col.max+1):SoilLayer_MaxNo] <- 0			return(list(sw_input_soils_use=sw_input_soils_use, sw_input_soils=sw_input_soils))		}		if( !(any(names(sw_input_experimentals)[sw_input_experimentals_use == 1] == "LookupTranspRegionsFromTable")) ){#Use only if option is off in sw_input_experimentals			if(any(is.na(sw_input_treatments$LookupTranspRegionsFromTable))) stop("ERROR: LookupTranspRegionsFromTable column in treatments cannot have any NAs.")			if(!all(unique(sw_input_treatments$LookupTranspRegionsFromTable) %in% rownames(tr_input_TranspRegions))) stop("ERROR: LookupTranspRegionsFromTable column values in treatments do not match up with trfile.LookupTranspRegionsFromTable row names.")			tempdat <- get.LookupTranspRegionsFromTable(trtype=sw_input_treatments$LookupTranspRegionsFromTable, sw_input_soils_use=sw_input_soils_use, sw_input_soils=sw_input_soils)			sw_input_soils_use <- tempdat$sw_input_soils_use			sw_input_soils <- tempdat$sw_input_soils			#write data to datafile.soils			write.csv(rbind(sw_input_soils_use, sw_input_soils), file=file.path(dir.sw.dat, datafile.soils), row.names=FALSE)			unlink(file.path(dir.in, datafile.SWRWinputs_preprocessed))		}	}	if(any(create_treatments == "LookupSnowDensityFromTable")){		#lookup monthly snow density values per category for each simulation run and copy values to 'datafile.cloud'		get.LookupSnowDensityFromTable <- function(sdcategories, sw_input_cloud_use, sw_input_cloud){			#extract data from table by category			snowd <- matrix(data=unlist(sapply(sdcategories, FUN=function(i) {tr_input_SnowD[which(rownames(tr_input_SnowD) == as.character(i)), st_mo]})), ncol=12, byrow=TRUE)			notes <- data.frame(matrix(data=unlist(sapply(sdcategories, FUN=function(i) {tr_input_SnowD[which(rownames(tr_input_SnowD) == as.character(i)), 13:14]})), ncol=2, byrow=TRUE), stringsAsFactors=FALSE)			#add fresh snow density during month of no or zero data			if(sum(itemp <- (is.na(snowd) | snowd == 0)) > 0) snowd[itemp] <- 76 #76 kg/m3 = median of medians over 6 sites in Colorado and Wyoming: Judson, A. & Doesken, N. (2000) Density of Freshly Fallen Snow in the Central Rocky Mountains. Bulletin of the American Meteorological Society, 81, 1577-1587.			#add data to sw_input_cloud and set the use flags			sw_input_cloud_use[i.temp <- grepl(pattern="snowd", x=names(sw_input_cloud_use))] <- 1			sw_input_cloud[, i.temp][st_mo] <- snowd			sw_input_cloud[, grepl(pattern="(SnowD_Hemisphere)|(SnowD_Source)", x=names(sw_input_cloud))] <- cbind(notes[1], apply(notes[2], MARGIN=2, FUN=function(x) paste("Type", sdcategories, "from", x)))			return(list(sw_input_cloud_use=sw_input_cloud_use, sw_input_cloud=sw_input_cloud))		}		if( !(any(names(sw_input_experimentals)[sw_input_experimentals_use == 1] == "LookupSnowDensityFromTable")) ){#Use only if option is off in sw_input_experimentals			if(any(is.na(sw_input_treatments$LookupSnowDensityFromTable))) stop("ERROR: LookupSnowDensityFromTable column in treatments cannot have any NAs.")			if(!all(unique(sw_input_treatments$LookupSnowDensityFromTable) %in% rownames(tr_input_SnowD))) stop("ERROR: LookupSnowDensityFromTable column values in treatments do not match up with trfile.LookupSnowDensityFromTable row names.")			tempdat <- get.LookupSnowDensityFromTable(sdcategories=sw_input_treatments$LookupSnowDensityFromTable, sw_input_cloud_use=sw_input_cloud_use, sw_input_cloud=sw_input_cloud)			sw_input_cloud_use <- tempdat$sw_input_cloud_use			sw_input_cloud <- tempdat$sw_input_cloud			#write data to datafile.cloud			write.csv(rbind(sw_input_cloud_use, sw_input_cloud), file=file.path(dir.sw.dat, datafile.cloud), row.names=FALSE)			unlink(file.path(dir.in, datafile.SWRWinputs_preprocessed))		}	}	if(any(create_treatments == "LookupTranspCoeffFromTable_Grass", create_treatments == "LookupTranspCoeffFromTable_Shrub", create_treatments == "LookupTranspCoeffFromTable_Tree", create_treatments == "LookupTranspCoeffFromTable_Forb", create_treatments == "AdjRootProfile"))	{		#lookup transpiration coefficients for grasses, shrubs, and trees per soil layer or per soil depth increment of 1 cm per distribution type for each simulation run and copy values to 'datafile.soils'		#first row of datafile is label for per soil layer 'Layer' or per soil depth increment of 1 cm 'DepthCM'		#second row of datafile is source of data		#the other rows contain the data for each distribution type = columns		TranspCoeffByVegType <- function(soillayer_no, trco_type, layers_depth, adjustType=c("positive", "inverse", "allToLast"))		{			#extract data from table by category			trco.code <- as.character(tr_input_TranspCoeff_Code[, which(colnames(tr_input_TranspCoeff_Code) == trco_type)])			trco <- rep(0, times=soillayer_no)			trco.raw <- na.omit(tr_input_TranspCoeff[, which(colnames(tr_input_TranspCoeff) == trco_type)])			if(trco.code == "DepthCM"){				trco_sum <- ifelse((temp <- sum(trco.raw, na.rm=TRUE)) == 0 & is.na(temp), 1, temp)				lup <- 1				for(l in 1:soillayer_no){					llow <- as.numeric(layers_depth[l])					if(is.na(llow) | lup > length(trco.raw))					{						l <- l - 1						break					}					trco[l] <- sum(trco.raw[lup:llow], na.rm=TRUE) / trco_sum					lup <- llow + 1				}				usel <- l			} else if(trco.code == "Layer"){				usel <- ifelse(length(trco.raw) < soillayer_no, length(trco.raw), soillayer_no)				trco[1:usel] <- trco.raw[1:usel] / ifelse((temp <- sum(trco.raw[1:usel], na.rm=TRUE)) == 0 & is.na(temp), 1, temp)			}			if(identical(adjustType, "positive")){				trco <- trco / sum(trco)	#equivalent to: trco + (1 - sum(trco)) * trco / sum(trco)			} else if(identical(adjustType, "inverse")){				irows <- 1:max(which(trco > 0))				trco[irows] <- trco[irows] + rev(trco[irows]) * (1 / sum(trco[irows]) - 1)	#equivalent to: trco + (1 - sum(trco)) * rev(trco) / sum(trco)			} else if(identical(adjustType, "allToLast")){				irow <- max(which(trco > 0))				if(irow > 1){					trco[irow] <- 1 - sum(trco[1:(irow - 1)]) 	#adding all the missing roots because soil is too shallow to the deepest available layer				} else {					trco[1] <- 1				}			}			return(trco)		}		#cannot write data from sw_input_soils to datafile.soils	}	if(!be.quiet) print(paste("SWSF obtains information prior to simulation runs: ended after",  round(difftime(Sys.time(), t1, units="secs"), 2), "s"))}#
#--------------------------------------------------------------------------------------------------##------------------------CALCULATIONS PRIOR TO SIMULATION RUNS TO CREATE THEM#------flagstemp <- matrix(data=do.PriorCalculations, ncol=2, nrow=length(do.PriorCalculations)/2, byrow=TRUE)pcalcs <- data.frame(t(as.numeric(temp[,-1])))names(pcalcs) <- temp[,1]if(actionWithSoilWat) {	do.GetClimateMeans <- 	(sum(sw_input_climscen_values_use[-1]) > 0) |			pcalcs$EstimateConstantSoilTemperatureAtUpperAndLowerBoundaryAsMeanAnnualAirTemperature |			sw_input_site_use$SoilTempC_atLowerBoundary |			sw_input_site_use$SoilTempC_atUpperBoundary |			pcalcs$EstimateInitialSoilTemperatureForEachSoilLayer |			any(create_treatments == "PotentialNaturalVegetation_CompositionShrubsC3C4_Paruelo1996") |			any(create_treatments == "AdjMonthlyBioMass_Temperature") |			any(create_treatments == "AdjMonthlyBioMass_Precipitation") |			any(create_treatments == "Vegetation_Biomass_ScalingSeason_AllGrowingORNongrowing")}if(any(actions == "create") && any(pcalcs > 0)){	if(!be.quiet) print(paste("SWSF makes calculations prior to simulation runs: started at", t1 <- Sys.time()))	if(pcalcs$CalculateBareSoilEvaporationCoefficientsFromSoilTexture){		#calculate bare soil evaporation coefficients per soil layer for each simulation run and copy values to 'datafile.soils'		bsEvap.depth.max <- 15	# max = 15 cm: Torres EA, Calera A (2010) Bare soil evaporation under high evaporation demand: a proposed modification to the FAO-56 model. Hydrological Sciences Journal-Journal Des Sciences Hydrologiques, 55, 303-315.		ld <- 1:SoilLayer_MaxNo		use.layers <- which(sw_input_soils_use[match(paste("Sand_L", ld, sep=""), colnames(sw_input_soils_use))] == 1)		stopifnot(length(use.layers) > 0)		layers.depth <- as.matrix(sw_input_soillayers[, match(paste("depth_L", use.layers, sep=""), colnames(sw_input_soillayers))])		if(length(dim(layers.depth)) > 0){			layers.width <- t(apply(layers.depth, MARGIN=1, FUN=function(x) diff(c(0, x))))		} else {			layers.width <- diff(c(0, layers.depth))		}		bsEvap.ld <- t(lapply(1:nrow(layers.depth), FUN=function(l) 1:(1+findInterval(bsEvap.depth.max - sqrt(.Machine$double.neg.eps), na.exclude(as.numeric(layers.depth[l, ]))))))#TODO: add influence of gravel		sand <- sw_input_soils[, match(paste("Sand_L", ld, sep=""), colnames(sw_input_soils_use))]		clay <- sw_input_soils[, match(paste("Clay_L", ld, sep=""), colnames(sw_input_soils_use))]		sand.mean <- sapply(1:nrow(layers.depth), FUN=function(l) weighted.mean(as.numeric(sand[l, bsEvap.ld[[l]]]), w=layers.width[bsEvap.ld[[l]]], na.rm=TRUE))		clay.mean <- sapply(1:nrow(layers.depth), FUN=function(l) weighted.mean(as.numeric(clay[l, bsEvap.ld[[l]]]), w=layers.width[bsEvap.ld[[l]]], na.rm=TRUE))		temp <- 4.1984+0.6695*sand.mean^2+168.7603*clay.mean^2	# soil texture influence: Wythers KR, Lauenroth WK, Paruelo JM (1999) Bare-Soil Evaporation Under Semiarid Field Conditions. Soil Science Society of America Journal, 63, 1341-1349.		bsEvap.depth.min <- ifelse(length(dim(layers.depth)) > 0, min(layers.width[, 1]), min(layers.width[1]))		stopifnot(bsEvap.depth.min < bsEvap.depth.max)		temp <- matrix(data=c(temp, rep(bsEvap.depth.min, times=nrow(layers.depth)), rep(bsEvap.depth.max, times=nrow(layers.depth))), ncol=3, byrow=FALSE)		bsEvap.depth <- apply(temp, MARGIN=1, FUN=function(x) min(c(x[3], max(x[1:2], na.rm=TRUE)), na.rm=TRUE))		bsEvap.ld <- t(lapply(1:nrow(layers.depth), FUN=function(l) 1:(1+findInterval(bsEvap.depth[l] - sqrt(.Machine$double.neg.eps), na.exclude(as.numeric(layers.depth[l, ]))))))		bsEvap.coeff <-  t(sapply(1:nrow(layers.depth), FUN=function(i) {							temp <- rep(NA, times=SoilLayer_MaxNo);							temp[bsEvap.ld[[i]]] <- 1 - exp(1 - layers.depth[i, bsEvap.ld[[i]]] * 5 / bsEvap.depth[i]) / exp(1);	#function made up to match previous cummulative distributions							return( (temp <- (c(temp <- as.numeric(temp), 1)-c(0, temp))[ld])/sum(temp, na.rm=TRUE) )	#garuantee that sum is 1						} ))		i.bsE <- grepl(pattern="EvapCoeff", x=names(sw_input_soils_use))		#add data to sw_input_soils and set the use flags		sw_input_soils_use[i.bsE] <- 0		sw_input_soils_use[i.bsE][1:max(unlist(bsEvap.ld))] <- 1		sw_input_soils[, i.bsE] <- 0		sw_input_soils[, i.bsE] <- bsEvap.coeff		#write data to datafile.soils		tempdat <- rbind(sw_input_soils_use, sw_input_soils)		write.csv(tempdat, file=file.path(dir.sw.dat, datafile.soils), row.names=FALSE)		unlink(file.path(dir.in, datafile.SWRWinputs_preprocessed))		rm(tempdat, i.bsE, bsEvap.coeff, bsEvap.depth, clay.mean, sand.mean, sand, clay, use.layers, layers.depth, layers.width)	}# SoilWat >=v31 calculates field capacity and wilting point internally; they are no longer required as inputs and this option has become obsolete#	if(pcalcs$CalculateFieldCapacityANDWiltingPointFromSoilTexture){#		#lookup soil texture data from 'datafile.soils' for those that the use flag of sand and clay is set, and calculate field capacity and wilting point#		ld <- 1:SoilLayer_MaxNo#		use.layers <- which(sw_input_soils_use[match(paste("Sand_L", ld, sep=""), colnames(sw_input_soils_use))] == 1)#		sand <- sw_input_soils[, match(paste("Sand_L", use.layers, sep=""), colnames(sw_input_soils_use))]#		clay <- sw_input_soils[, match(paste("Clay_L", use.layers, sep=""), colnames(sw_input_soils_use))]##		fieldc <- sapply(1:ncol(sand), FUN=function(i) SWPtoVWC(-0.033, sand[, i], clay[, i]))#		wiltp <- sapply(1:ncol(sand), FUN=function(i) SWPtoVWC(-1.5, sand[, i], clay[, i]))##		#add data to sw_input_cloud and set the use flags#		sw_input_soils_use[i.fieldc <- match(paste("FieldC_L", use.layers, sep=""), colnames(sw_input_soils_use))] <- 1#		sw_input_soils_use[i.wiltp <- match(paste("WiltP_L", use.layers, sep=""), colnames(sw_input_soils_use))] <- 1#		sw_input_soils[, i.fieldc] <- fieldc#		sw_input_soils[, i.wiltp] <- wiltp##		#write data to datafile.soils#		tempdat <- rbind(sw_input_soils_use, sw_input_soils)#		write.csv(tempdat, file=file.path(dir.sw.dat, datafile.soils), row.names=FALSE)#		unlink(file.path(dir.in, datafile.SWRWinputs_preprocessed))##		rm(use.layers, sand, clay, fieldc, wiltp, tempdat, i.fieldc, i.wiltp)#	}	#------used during each simulation run: define functions here	if(pcalcs$EstimateConstantSoilTemperatureAtUpperAndLowerBoundaryAsMeanAnnualAirTemperature){		sw_input_site_use$SoilTempC_atLowerBoundary <- 1 #set use flag		sw_input_site_use$SoilTempC_atUpperBoundary <- 1		#call function 'SiteClimate' in each SoilWat-run	}	if(pcalcs$EstimateInitialSoilTemperatureForEachSoilLayer){		#set use flags		ld <- 1:SoilLayer_MaxNo		use.layers <- which(sw_input_soils_use[match(paste("Sand_L", ld, sep=""), colnames(sw_input_soils_use))] == 1)		soilTemp <- sw_input_soils[, index.soilTemp <- match(paste("SoilTemp_L", ld, sep=""), colnames(sw_input_soils_use))[use.layers]]		sw_input_soils_use[index.soilTemp] <- 1		#function to be executed for each SoilWat-run		EstimateInitialSoilTemperatureForEachSoilLayer <- function(layers_depth, lower.Tdepth, soilTupper, soilTlower){			sl <- c(0, lower.Tdepth)			st <- c(soilTupper, soilTlower)			return( predict(lm(st ~ sl), data.frame(sl=layers_depth)) )		}	}	if(!be.quiet) print(paste("SWSF makes calculations prior to simulation runs: ended after",  round(difftime(Sys.time(), t1, units="secs"), 2), "s"))}#--------------------------------------------------------------------------------------------------##------------------------MAP INPUT VARIABLES (FOR QUALITY CONTROL)if (any(actions == "map_input") && length(map_vars) > 0) {	if (!be.quiet) print(paste("SWSF generates maps of input variables for quality control: started at", t1 <- Sys.time()))	dir.create(dir.inmap <- file.path(dir.out, "Input_maps"), showWarnings = FALSE)	input_avail <- list(SWRunInformation = list(cols = colnames(SWRunInformation), use = rep(TRUE, ncol(SWRunInformation))),						sw_input_soillayers = list(cols = colnames(sw_input_soillayers), use = rep(TRUE, ncol(sw_input_soillayers))),						sw_input_cloud = list(cols = colnames(sw_input_cloud), use = as.logical(sw_input_cloud_use)),						sw_input_prod = list(cols = colnames(sw_input_prod), use = as.logical(sw_input_prod_use)),						sw_input_site = list(cols = colnames(sw_input_site), use = as.logical(sw_input_site_use)),						sw_input_soils = list(cols = colnames(sw_input_soils), use = as.logical(sw_input_soils_use)),						sw_input_weather = list(cols = colnames(sw_input_weather), use = as.logical(sw_input_weather_use)),						sw_input_climscen = list(cols = colnames(sw_input_climscen), use = as.logical(sw_input_climscen_use)),						sw_input_climscen_values = list(cols = colnames(sw_input_climscen_values), use = as.logical(sw_input_climscen_use))					)#
	for (iv in seq_along(map_vars)) {		iv_locs <- lapply(input_avail, function(ina) grep(map_vars[iv], ina$cols[ina$use], ignore.case = TRUE, value = TRUE))		iv_locs <- iv_locs[lengths(iv_locs) > 0]#
		if (length(iv_locs) > 0) {			dir.create(dir.inmapvar <- file.path(dir.inmap, map_vars[iv]), showWarnings = FALSE)			for (it1 in seq_along(iv_locs)) for (it2 in seq_along(iv_locs[[it1]])) {				dat <- as.numeric(get(names(iv_locs)[it1])[runIDs_sites, iv_locs[[it1]][it2]])#
				if (any(is.finite(dat))) {					names(dat) <- iv_locs[[it1]][it2]#
					map_flag <- paste(names(iv_locs)[it1], iv_locs[[it1]][it2], sim_cells_or_points, sep = "_")#
					# Convert data to spatial object					if (sim_cells_or_points == "point") {						sp_dat <- as(run_sites, "SpatialPointsDataFrame")						temp <- as.data.frame(dat)						colnames(temp) <-  iv_locs[[it1]][it2]						slot(sp_dat, "data") <- temp#
						if (!raster::compareCRS(crs_sites, sim_crs)) {							sp_dat <- sp::spTransform(sp_dat, CRS = sim_crs)						}#
					} else if (sim_cells_or_points == "cell") {						sp_dat <- sim_raster						stopifnot(raster::canProcessInMemory(sp_dat)) # if failing, then need a more sophisticated assignment of values than implemented below						temp <- run_sites						if (!raster::compareCRS(crs_sites, sim_crs)) {							temp <- sp::spTransform(temp, CRS = sim_crs)						}#
						sp_dat[raster::cellFromXY(sp_dat, sp::coordinates(temp))] <- dat					}#
					# Save to disk					saveRDS(sp_dat, file = file.path(dir.inmapvar, paste0(map_flag, ".rds")))#
					# Figure					png(height = 10, width = 6, units = "in", res = 200, file = file.path(dir.inmapvar, paste0(map_flag, ".png")))					par_old <- par(mfrow = c(2, 1), mar = c(2.5, 2.5, 0.5, 0.5), mgp = c(1.25, 0.25, 0), tcl = 0.5, cex = 1)#
					# panel a: map					n_cols <- 255					cols <- rev(terrain.colors(7))					cols[1] <- "gray"					cols <- colorRampPalette(c(cols, "dodgerblue3"))(n_cols)					if (sim_cells_or_points == "point") {						par1 <- par(mar = c(2.5, 2.5, 0.5, 8.5))						cdat <- cut(dat, n_cols)						p_size <- function(x) max(0.25, min(2, 100 / x))						sp::plot(sp_dat, col = cols[as.integer(cdat)], pch = 15, cex = p_size(length(dat)), axes = TRUE, asp = 1)						# legend						ids <- round(seq(1, n_cols, length.out = 12))						lusr <- par("usr")						lxy <- cbind(rep(lusr[2] + (lusr[2] - lusr[1]) / 15, 12),									 lusr[3] + (lusr[4] - lusr[3]) / 4 + seq(0, 1, length.out = 12) * (lusr[4] - lusr[3]) / 2)						points(lxy, col = cols[ids], pch = 15, cex = 2, xpd = NA)						text(lxy, pos = 4, labels = levels(cdat)[ids], xpd = NA)						par(par1)					} else if (sim_cells_or_points == "cell") {						raster::plot(sp_dat, col = cols, asp = 1)					}					mtext(side = 3, line = -1, adj = 0.03, text = paste0("(", letters[1], ")"), font = 2)					# panel b: histogram					hist(dat, xlab = paste(names(iv_locs)[it1], iv_locs[[it1]][it2]), main = "")					mtext(side = 3, line = -1, adj = 0.03, text = paste0("(", letters[2], ")"), font = 2)#
					par(par_old)					dev.off()				}			}		}	}#
	if (!be.quiet) print(paste("SWSF input maps: ended after",  round(difftime(Sys.time(), t1, units = "secs"), 2), "s"))}
swDataFromFiles <- sw_inputDataFromFiles(dir=dir.sw.in,files.in=swFilesIn) #This acts for the basis for all runs.	if (length(swDataFromFiles@weatherHistory) > 0)		swDataFromFiles@weatherHistory <- list(swClear(swDataFromFiles@weatherHistory[[1]])) # we don't need the example weather data; the code will get weather data separately	#Used for weather from files	filebasename <- basename(swFiles_WeatherPrefix(swDataFromFiles))	#objects to export	list.export <- c("filebasename","Tmax_crit_C","Tmin_crit_C", "increment_soiltemperature_deltaX_cm", "name.OutputDB","getScenarioWeatherDataFromDatabase","getCurrentWeatherDataFromDatabase","ExtractGriddedDailyWeatherFromMaurer2002_NorthAmerica", "create_filename_for_Maurer2002_NorthAmerica", "ExtractGriddedDailyWeatherFromDayMet_NorthAmerica", "dir.ex.daymet", "get_DayMet_NorthAmerica", "get_DayMet_cellID", "climate.conditions","dir.sw.in.tr","dbWeatherDataFile","dir.ex.maurer2002","AggLayer.daily","Depth_TopLayers","Depth_FirstAggLayer.daily","Depth_SecondAggLayer.daily","Depth_ThirdAggLayer.daily","Depth_FourthAggLayer.daily","adjustLayersDepth", "getLayersWidth", "setLayerSequence", "sw_dailyC4_TempVar","sw_SiteClimate_Ambient","PotentialNaturalVegetation_CompositionShrubsC3C4_Paruelo1996", "AdjMonthlyBioMass","siteparamin","soilsin","weatherin","cloudin","prodin","estabin","tr_input_TranspCoeff_Code","transferExpDesignToInput","sw_input_experimentals","getStartYear","get.month","adjust.WindspeedHeight","circ.mean","circ.range","circ.sd","dir.create2","do_OneSite","endDoyAfterDuration","EstimateInitialSoilTemperatureForEachSoilLayer","get.LookupEvapCoeffFromTable","get.LookupSnowDensityFromTable","get.LookupTranspRegionsFromTable","max.duration","setAggSoilLayerForAggDailyResponses","simTiming","simTiming_ForEachUsedTimeUnit","startDoyOfDuration","SWPtoVWC","TranspCoeffByVegType","VWCtoSWP",			"work", "do_OneSite", "accountNSHemispheres_veg","AggLayer.daily","be.quiet","bin.prcpfreeDurations","bin.prcpSizes","climate.conditions","continueAfterAbort","datafile.windspeedAtHeightAboveGround","adjust.soilDepth","DegreeDayBase","Depth_TopLayers","dir.out","dir.sw.runs","endyr","estabin","establishment.delay","establishment.duration","establishment.swp.surface","exec_c_prefix","filebasename.WeatherDataYear","germination.duration","germination.swp.surface","growing.season.threshold.tempC","makeInputForExperimentalDesign","ouput_aggregated_ts","output_aggregate_daily","parallel_backend","parallel_runs","print.debug","saveSoilWatInputOutput","season.end","season.start","shrub.fraction.limit","simstartyr","simulation_timescales","startyr","sw_aet","sw_deepdrain","sw_evapsurface","sw_evsoil","sw_hd","sw_inf_soil","sw_interception","sw_percolation","sw_pet","sw_precip","sw_runoff","sw_snow","sw_soiltemp","sw_swabulk","sw_swamatric","sw_swcbulk","sw_swpmatric","sw_temp","sw_transp","sw_vwcbulk","sw_vwcmatric","sw.inputs","sw.outputs","swcsetupin","swFilesIn","swOutSetupIn","SWPcrit_MPa","yearsin","dbOverallColumns","aon","create_experimentals","create_treatments","daily_no","dir.out.temp","dirname.sw.runs.weather","do.GetClimateMeans","ExpInput_Seperator","lmax","no.species_regeneration","param.species_regeneration","pcalcs","runsN_sites","runsN_todo","runsN_total", "scenario_No","simTime","simTime_ForEachUsedTimeUnit_North","simTime_ForEachUsedTimeUnit_South","SoilLayer_MaxNo","SoilWat.windspeedAtHeightAboveGround","st_mo","sw_input_climscen_use","sw_input_climscen_values_use","sw_input_cloud_use","sw_input_experimentals_use","sw_input_prod_use","sw_input_site_use","sw_input_soils_use","sw_input_weather_use","swDataFromFiles","counter.digitsN","timerfile","tr_cloud","tr_files","tr_input_climPPT","tr_input_climTemp","tr_input_EvapCoeff","tr_input_shiftedPPT","tr_input_SnowD","tr_input_TranspCoeff","tr_input_TranspRegions","tr_prod","tr_site","tr_soil","tr_VegetationComposition","tr_weather","expN","workersN", "it_Pid", "it_exp", "it_site", "runsN_master")	list.export <- ls()[ls() %in% list.export]	#ETA calculation	if(!be.quiet) print(paste("SWSF simulation runs:", runsN_todo, "out of", runsN_total, " runs will be carried out on", workersN, "cores: started at", t1 <- Sys.time()))	inputDataToSave <- list()
runs.completed <- 1
# Send a task, and then remove it from the task list						i_site <- it_site(runIDs_todo[runs.completed])						i_labels <- labels[i_site]						i_SWRunInformation <- SWRunInformation[i_site, ]						i_sw_input_soillayers <- sw_input_soillayers[i_site, ]						i_sw_input_treatments <- sw_input_treatments[i_site, ]						i_sw_input_cloud <- sw_input_cloud[i_site, ]						i_sw_input_prod <- sw_input_prod[i_site, ]						i_sw_input_site <- sw_input_site[i_site, ]						i_sw_input_soils <- sw_input_soils[i_site, ]						i_sw_input_weather <- sw_input_weather[i_site, ]						i_sw_input_climscen <- sw_input_climscen[i_site, ]						i_sw_input_climscen_values <- sw_input_climscen_values[i_site, ]
i_sim=runIDs_todo[runs.completed]
time.sys <- Sys.time()	flag.icounter <- formatC(i_sim, width=counter.digitsN, format = "d", flag="0")#-----------------------Check for experimentals	if(expN > 0 && length(create_experimentals) > 0) {		i_exp <- it_exp(i_sim)		i_labels <- paste(flag.icounter, sw_input_experimentals[i_exp,1], i_labels, sep="_")		#--put information from experimental design into appropriate input variables; create_treatments and the _use files were already adjusted for the experimental design when files were read in/created		transferExpDesignToInput <- function(i_sw_input){			ctemp <- (temp <- match(names(sw_input_experimentals)[sw_input_experimentals_use == 1], names(i_sw_input), nomatch=0))[!temp == 0]			if(length(ctemp) > 0){				cexp <- match(names(i_sw_input)[ctemp], names(sw_input_experimentals), nomatch=0)				i_sw_input[ctemp] <- sw_input_experimentals[i_exp, cexp]			}			return(i_sw_input)		}		i_sw_input_treatments <- transferExpDesignToInput(i_sw_input_treatments)		i_sw_input_soils <- transferExpDesignToInput(i_sw_input_soils)		i_sw_input_site <- transferExpDesignToInput(i_sw_input_site)		i_sw_input_prod <- transferExpDesignToInput(i_sw_input_prod)	}#
#------------------------Preparations for simulation run	if(!be.quiet) print(paste(i_sim, ":", i_labels, "started at ", time.sys))#
	#Check what needs to be done	#TODO this currently doesn't work in the database setup	isdone.overallAggs <- rep(FALSE, scenario_No)	if(any(simulation_timescales=="daily") && daily_no > 0){		isdone.dailyAggs <- matrix(data=FALSE, nrow=daily_no, ncol=scenario_No)	} else {		isdone.dailyAggs <- TRUE	}	#set up task list: code: -1, don't do; 0, failed; 1, to do; 2, success	tasks <- list(aggregate=1, #for now: ignoring to check time-series aggregations, i.e., assuming that if overallAggs is done, then time-series output was also completed					create=1,					execute=1)
#get treatment sw.input.filenames for this run		filesin <- swFilesIn		if(!is.null(create_treatments) & tasks$create == 1){			if(any(create_treatments == "sw")){				sw <- i_sw_input_treatments$sw			}			if(any(create_treatments == "filesin")){				filesin <- i_sw_input_treatments$filesin			}			if(any(create_treatments == "prodin")){				prodin <- i_sw_input_treatments$prodin			}			if(any(create_treatments == "siteparamin")){				siteparamin <- i_sw_input_treatments$siteparamin			}			if(any(create_treatments == "soilsin")){				soilsin <- i_sw_input_treatments$soilsin			}			if(any(create_treatments == "weathersetupin")){				weatherin <- i_sw_input_treatments$weathersetupin			}			if(any(create_treatments == "cloudin")){				cloudin <- i_sw_input_treatments$cloudin			}		}		#if action is not create then get sw.input.filenames from filesin for this run		if(tasks$create == -1){			stop("This currently doesn't work") #TODO make it work low PR			soilsin <- basename(unlist(strsplit(infiletext[10], split="[[:space:]]"))[1])		}		#------Learn about soil layer structure		#determine number of soil layers = d and soildepth		if(!any(create_treatments=="soilsin") & tasks$create == 1) {			soildepth <- i_sw_input_soillayers$SoilDepth_cm			layers_depth <- na.omit(as.numeric(i_sw_input_soillayers[2 + lmax]))			if(!(length(d <- which(soildepth == layers_depth)) > 0)){	#soildepth is one of the lower layer boundaries				d <- min(length(layers_depth), findInterval(soildepth, layers_depth)+1)	#soildepth is not one of the lower layer boundaries, the next deeper layer boundary is used			}		} else {# needs to be read from soilsin file			if(tasks$create == -1) stop("This currently doesn't work") #TODO make it work low PR			layers_depth <- swSoils_Layers(tr_soil[[soilsin]])[,1]			d <- length(layers_depth)			soildepth <- max(layers_depth)		}		#functions to obtain soil layer structures		#layer sequence		#########################Moved to Rsoilwat###########################		#adjustLayersDepth <- function(layers_depth, d) return(round(layers_depth[1:d])) #The wrapper only handles 1-cm resolution of soil depths (maily because of the trco)		#getLayersWidth <- function(layers_depth) return(diff(c(0, layers_depth)))		#setLayerSequence <- function(d) return(1:d)		#####################################################################		ld <- setLayerSequence(d)		layers_depth <- adjustLayersDepth(layers_depth, d)		layers_width <- getLayersWidth(layers_depth)		#top and bottom layer aggregation		setDeepestTopLayer <- function(d){			return(max(1, findInterval(Depth_TopLayers, layers_depth) ))		}		setTopLayer <- function(d){			return(1:(ifelse(d<DeepestTopLayer, d, DeepestTopLayer)))		}		setBottomLayer <- function(d){			if(d <= DeepestTopLayer){				val  <- NULL			} else {				val  <- ((DeepestTopLayer+1):d)			}			return(val)		}		DeepestTopLayer <- setDeepestTopLayer(d)		topL <- setTopLayer(d)		bottomL <- setBottomLayer(d)#
		#------Learn about simulation time		if(any(create_treatments == "YearStart") | any(create_treatments == "YearEnd")){			#------time frame of simulation			if(any(create_treatments == "YearStart")){				#year when SoilWat starts the simulation				simstartyr  <- i_sw_input_treatments$YearStart				#first year that is used for output aggregation, e.g., simstartyr + 1				startyr <- getStartYear(simstartyr)			}			if(any(create_treatments == "YearEnd")){				#year when SoilWat ends the simulation				endyr <- i_sw_input_treatments$YearEnd			}			#------simulation timing needs to be adjusted			simTime <- simTiming(startyr, simstartyr, endyr)			simTime2 <- simTiming_ForEachUsedTimeUnit(simTime, latitude=i_SWRunInformation$Y_WGS84)		} else {			if(i_SWRunInformation$Y_WGS84 >= 0){				simTime2 <- simTime_ForEachUsedTimeUnit_North			} else {				simTime2 <- simTime_ForEachUsedTimeUnit_South			}		}		#Prepare directory structure in case SoilWat input/output is requested to be stored on disk		if(saveSoilWatInputOutput) dir.create2(dir.sw.runs.sim <- file.path(dir.sw.runs, i_labels),showWarnings=F)
if(print.debug) print("Start of section 'create'")		EVCO_done <- TRCO_done <- FALSE	#to check whether we get information for evaporation and transpiration coefficients		TRRG_done <- FALSE #to check whether we get information for transpiration regions		#------1. Step: Information for this SoilWat-run from prepared SoilWat-run stored in dir.sw.in		#Make a local copy of the swInput object do not want to destroy orignal		swRunScenariosData<-list(scenario_No)		swRunScenariosData[[1]]<-swDataFromFiles		#get folder and file names		outsetupin <- swOutSetupIn		dir.sw.runs.weather <- i_sw_input_treatments$LookupWeatherFolder		if(print.debug) print("Start of LookupWeatherFolder")		#write input file names and paths to first file, unless filesin is a treatment		if(!any(create_treatments=="filesin")){			swFiles_Years(swRunScenariosData[[1]]) <- paste(sw.inputs, .Platform$file.sep, yearsin, sep="")			swFiles_LogFile(swRunScenariosData[[1]]) <- paste(ifelse(sw.outputs == "", "", paste(sw.outputs, .Platform$file.sep, sep="")), sep="")			swFiles_SiteParams(swRunScenariosData[[1]]) <- paste(sw.inputs, .Platform$file.sep, siteparamin, sep="")			swFiles_Soils(swRunScenariosData[[1]]) <- paste(sw.inputs, .Platform$file.sep, soilsin, sep="")			swFiles_WeatherSetup(swRunScenariosData[[1]]) <- paste(sw.inputs, .Platform$file.sep, weatherin, sep="")			swFiles_WeatherPrefix(swRunScenariosData[[1]]) <- paste(sw.inputs, .Platform$file.sep, dirname.sw.runs.weather, .Platform$file.sep, filebasename.WeatherDataYear, sep="")			swFiles_MarkovProbs(swRunScenariosData[[1]]) <- paste(sw.inputs, .Platform$file.sep, dirname.sw.runs.weather, .Platform$file.sep, sep="")			swFiles_MarkovCov(swRunScenariosData[[1]]) <- paste(sw.inputs, .Platform$file.sep, dirname.sw.runs.weather, .Platform$file.sep, sep="")			swFiles_Cloud(swRunScenariosData[[1]]) <- paste(sw.inputs, .Platform$file.sep, dirname.sw.runs.weather, .Platform$file.sep, cloudin, sep="")			swFiles_Prod(swRunScenariosData[[1]]) <- paste(sw.inputs, .Platform$file.sep, prodin, sep="")			swFiles_Estab(swRunScenariosData[[1]]) <- paste(sw.inputs, .Platform$file.sep, estabin, sep="")			swFiles_SWCsetup(swRunScenariosData[[1]]) <- paste(sw.inputs, .Platform$file.sep, swcsetupin, sep="")			swFiles_OutputPrefix(swRunScenariosData[[1]]) <- paste(ifelse(sw.outputs == "", "", paste(sw.outputs, .Platform$file.sep, sep="")), sep="")			swFiles_Output(swRunScenariosData[[1]]) <- paste(sw.inputs, .Platform$file.sep, outsetupin, sep="")		}		#adjust simulation years		swYears_StartYear(swRunScenariosData[[1]]) <- as.integer(simstartyr)		swYears_EndYear(swRunScenariosData[[1]]) <- as.integer(endyr)		##adjust soil temp equation parameters		if(any(create_treatments=="MaxTempDepth"))		  swRunScenariosData[[1]]@site@SoilTemperatureConstants[[10]] <- i_sw_input_treatments$MaxTempDepth		#------2. Step: a) Information for this SoilWat-run from treatment SoilWat input files stored in dir.sw.in.tr		if(any(create_treatments=="sw"))			print("SW treatment is not used because library Rsoilwat only uses one version of soilwat. Sorry")		if(any(create_treatments=="filesin"))			set_swFiles(swRunScenariosData[[1]]) <- tr_files[[filesin]]		if(any(create_treatments=="prodin"))			set_swProd(swRunScenariosData[[1]]) <- tr_prod[[prodin]]		if(any(create_treatments=="siteparamin")){			set_swSite(swRunScenariosData[[1]]) <- tr_site[[siteparamin]]			TRRG_done <- TRUE		}		if(any(create_treatments=="soilsin")){			set_swSoils(swRunScenariosData[[1]]) <- tr_soil[[soilsin]]			EVCO_done <- TRCO_done <- TRUE		}		if(any(create_treatments=="weathersetupin"))			set_swWeather(swRunScenariosData[[1]]) <- tr_weather[[weatherin]]		if(any(create_treatments=="cloudin"))			set_swCloud(swRunScenariosData[[1]]) <- tr_cloud[[cloudin]]		#------2. Step: b) Information for this SoilWat-run from treatment chunks stored in dir.sw.in.tr		#Do the lookup stuff for experimental design that was done for the treatment design before the call to call_OneSite, but couldn't for the experimental design because at that time information was unkown		if(any(names(sw_input_experimentals)[sw_input_experimentals_use == 1] == "LookupEvapCoeffFromTable")) {			if(any(is.na(i_sw_input_treatments$LookupEvapCoeffFromTable)) || !all(unique(i_sw_input_treatments$LookupEvapCoeffFromTable) %in% rownames(tr_input_EvapCoeff))) {				print("ERROR: LookupEvapCoeffFromTable column in expirementals cannot have any NAs or name is not in tr_input_EvapCoeff table.")				tasks$create <- 0			} else {				tempdat <- get.LookupEvapCoeffFromTable(evco_type=i_sw_input_treatments$LookupEvapCoeffFromTable, sw_input_soils_use=sw_input_soils_use, sw_input_soils=i_sw_input_soils)				if(all(colSums(tempdat$sw_input_soils,na.rm=T)>0) && !any(is.na(colSums(tempdat$sw_input_soils))) ) {					sw_input_soils_use <- tempdat$sw_input_soils_use					i_sw_input_soils <- tempdat$sw_input_soils				} else {					print("ERROR: get.LookupEvapCoeffFromTable returned a Layer that didn't have a sum greater then 0 or had a NA.")					tasks$create <- 0				}			}		}		if(any(names(sw_input_experimentals)[sw_input_experimentals_use == 1] == "LookupTranspRegionsFromTable")) {			if(any(is.na(i_sw_input_treatments$LookupTranspRegionsFromTable)) || !all(unique(i_sw_input_treatments$LookupTranspRegionsFromTable) %in% rownames(tr_input_TranspRegions))) {				print("ERROR: LookupTranspRegionsFromTable column in expirementals cannot have any NAs or name is not in LookupTranspRegionsFromTable data table.")				tasks$create <- 0			} else {				tempdat <- get.LookupTranspRegionsFromTable(trtype=i_sw_input_treatments$LookupTranspRegionsFromTable, sw_input_soils_use=sw_input_soils_use, sw_input_soils=i_sw_input_soils)				sw_input_soils_use <- tempdat$sw_input_soils_use				i_sw_input_soils <- tempdat$sw_input_soils			}		}		if(any(names(sw_input_experimentals)[sw_input_experimentals_use == 1] == "LookupSnowDensityFromTable")) {			if(any(is.na(i_sw_input_treatments$LookupSnowDensityFromTable)) || !all(unique(i_sw_input_treatments$LookupSnowDensityFromTable) %in% rownames(tr_input_SnowD))) {				print("ERROR: LookupSnowDensityFromTable column in expirementals cannot have any NAs or name is not in tr_input_SnowD data table.")				tasks$create <- 0			} else {				tempdat <- get.LookupSnowDensityFromTable(sdcategories=i_sw_input_treatments$LookupSnowDensityFromTable, sw_input_cloud_use=sw_input_cloud_use, sw_input_cloud=i_sw_input_cloud)				sw_input_cloud_use <- tempdat$sw_input_cloud_use				i_sw_input_cloud <- tempdat$sw_input_cloud			}		}		#Treatment chunks		if(print.debug) print("Start of LookupTranspCoeff")		if(print.debug) print(".........grass")		if(any(create_treatments == "LookupTranspCoeffFromTable_Grass")){			if(temp<-is.na(i_sw_input_treatments$LookupTranspCoeffFromTable_Grass)) print("LookupTranspCoeffFromTable_Grass for this run cannot be NA.")			if(temp1<-!all(i_sw_input_treatments$LookupTranspCoeffFromTable_Grass %in% colnames(tr_input_TranspCoeff))) print("LookupTranspCoeffFromTable_Grass name for this run are not in tr_input_TranspCoeff table column names.")			if(temp || temp1) {				tasks$create <- 0			} else {				trco <- TranspCoeffByVegType(soillayer_no=d, trco_type=i_sw_input_treatments[1,"LookupTranspCoeffFromTable_Grass"], layers_depth=layers_depth, adjustType="positive")				if(!any(is.na(trco)) || sum(trco,na.rm=T) > 0){#trco does not have NA and sum is greater than 0.					#set the use flags					i.temp <- grepl(pattern=paste("Grass", "_TranspCoeff", sep=""), x=names(sw_input_soils_use))					sw_input_soils_use[i.temp][1:length(trco)] <- rep(1, times=length(trco))					#add data to sw_input_soils					i_sw_input_soils[i.temp][1:length(trco)] <- trco				} else {					print("The function TranspCoeffByVegType returned NA or does not sum to greater than 0 for this run for type grass.")					tasks$create <- 0				}			}		}		if(print.debug) print(".........shrub")		if(any(create_treatments == "LookupTranspCoeffFromTable_Shrub")){			if(temp<-is.na(i_sw_input_treatments$LookupTranspCoeffFromTable_Shrub)) print("LookupTranspCoeffFromTable_Shrub for this run cannot be NA.")			if(temp1<-!all(i_sw_input_treatments$LookupTranspCoeffFromTable_Shrub %in% colnames(tr_input_TranspCoeff))) print("LookupTranspCoeffFromTable_Shrub name for this run are not in tr_input_TranspCoeff table column names.")			if(temp || temp1) {				tasks$create <- 0			} else {				trco <- TranspCoeffByVegType(soillayer_no=d, trco_type=i_sw_input_treatments[1,"LookupTranspCoeffFromTable_Shrub"], layers_depth=layers_depth, adjustType="inverse")				#set the use flags				if(!any(is.na(trco)) || sum(trco,na.rm=T) > 0){					i.temp <- grepl(pattern=paste("Shrub", "_TranspCoeff", sep=""), x=names(sw_input_soils_use))					sw_input_soils_use[i.temp][1:length(trco)] <- rep(1, times=length(trco))					#add data to sw_input_soils					i_sw_input_soils[i.temp][1:length(trco)] <- trco				}  else {					print("The function TranspCoeffByVegType returned NA or does not sum to greater than 0 for this run for type shrub.")					tasks$create <- 0				}			}		}		if(print.debug) print(".........tree")		if(any(create_treatments == "LookupTranspCoeffFromTable_Tree")){			if(temp<-is.na(i_sw_input_treatments$LookupTranspCoeffFromTable_Tree)) print("LookupTranspCoeffFromTable_Tree for this run cannot be NA.")			if(temp1<-!all(i_sw_input_treatments$LookupTranspCoeffFromTable_Tree %in% colnames(tr_input_TranspCoeff))) print("LookupTranspCoeffFromTable_Tree name for this run are not in tr_input_TranspCoeff table column names.")			if(temp || temp1) {				tasks$create <- 0			} else {				trco <- TranspCoeffByVegType(soillayer_no=d, trco_type=i_sw_input_treatments[1,"LookupTranspCoeffFromTable_Tree"], layers_depth=layers_depth, adjustType="inverse")				if(!any(is.na(trco)) || sum(trco,na.rm=T) > 0){					i.temp <- grepl(pattern=paste("Tree", "_TranspCoeff", sep=""), x=names(sw_input_soils_use))					sw_input_soils_use[i.temp][1:length(trco)] <- rep(1, times=length(trco))					#add data to sw_input_soils					i_sw_input_soils[i.temp][1:length(trco)] <- trco				} else {					print("The function TranspCoeffByVegType returned NA or does not sum to greater than 0 for this run for type Tree.")					tasks$create <- 0				}			}		}		if(print.debug) print(".........forb")		if(any(create_treatments == "LookupTranspCoeffFromTable_Forb")){			if(temp<-is.na(i_sw_input_treatments$LookupTranspCoeffFromTable_Forb)) print("LookupTranspCoeffFromTable_Forb for this run cannot be NA.")			if(temp1<-!all(i_sw_input_treatments$LookupTranspCoeffFromTable_Forb %in% colnames(tr_input_TranspCoeff))) print("LookupTranspCoeffFromTable_Forb name for this run are not in tr_input_TranspCoeff table column names.")			if(temp || temp1) {				tasks$create <- 0			} else {				trco <- TranspCoeffByVegType(soillayer_no=d, trco_type=i_sw_input_treatments[1,"LookupTranspCoeffFromTable_Forb"], layers_depth=layers_depth, adjustType="inverse")				if(!any(is.na(trco)) || sum(trco,na.rm=T) > 0){					i.temp <- grepl(pattern=paste("Forb", "_TranspCoeff", sep=""), x=names(sw_input_soils_use))					sw_input_soils_use[i.temp][1:length(trco)] <- rep(1, times=length(trco))					#add data to sw_input_soils					i_sw_input_soils[i.temp][1:length(trco)] <- trco				} else {					print("The function TranspCoeffByVegType returned NA or does not sum to greater than 0 for this run for type Forb.")					tasks$create <- 0				}			}		}		#the monthly ppt-shifts are extracted, but written to the weathersetup input file only at the end of the create section 'copy and make climate scenarios from datafiles', because they are multiplied with any climate change factors		ppt_scShift <- rep(1, times=12)		if(any(create_treatments=="LookupShiftedPPTScenarios")){			ppt_scShift <- tr_input_shiftedPPT[which(rownames(tr_input_shiftedPPT) == i_sw_input_treatments[1,"LookupShiftedPPTCategory"]),(ts <- which(colnames(tr_input_shiftedPPT) == paste(i_sw_input_treatments$LookupShiftedPPTScenarios, "_m1", sep=""))):(ts+11)][st_mo]		}		if(any(create_treatments=="LookupClimatePPTScenarios") | any(create_treatments=="LookupClimateTempScenarios")){			clim_scale <- swWeather_MonScalingParams(swRunScenariosData[[1]])[, 1:3]			#Treatment chunk = climate precipitation scenarios			if(any(create_treatments=="LookupClimatePPTScenarios") ) {				clim_scale[, 1] <- tr_input_climPPT[st_mo, which(colnames(tr_input_climPPT) == i_sw_input_treatments$LookupClimatePPTScenarios)]			}			#Treatment chunk = climate temperature scenarios			if(any(create_treatments=="LookupClimateTempScenarios") ) {				clim_scale[, 2] <- clim_scale[, 3] <- tr_input_climTemp[st_mo, which(colnames(tr_input_climTemp) == i_sw_input_treatments$LookupClimateTempScenarios)]			}			swWeather_MonScalingParams(swRunScenariosData[[1]])[, 1:3] <- clim_scale			rm(clim_scale)		}#
		#------4. Step: Information from datafiles are added if flagged 'use' to SoilWat input files		#add information from datafile to cloudin		if(print.debug) print("Start of cloudin")		wind <- with(i_sw_input_cloud, data.frame(wind_ms_1, wind_ms_2, wind_ms_3, wind_ms_4, wind_ms_5, wind_ms_6, wind_ms_7, wind_ms_8, wind_ms_9, wind_ms_10, wind_ms_11, wind_ms_12))		if(do.wind <- datafile.windspeedAtHeightAboveGround != SoilWat.windspeedAtHeightAboveGround)			wind <- adjust.WindspeedHeight(uz=wind, height=datafile.windspeedAtHeightAboveGround)		if(sum(sw_input_cloud_use[-1]) > 0 | do.wind){			#sky cover			if(sum(sw_input_cloud_use[grepl(pattern="SkyC", x=names(sw_input_cloud_use))]) > 0) {				sky <- with(i_sw_input_cloud, data.frame(SkyC_1, SkyC_2, SkyC_3, SkyC_4, SkyC_5, SkyC_6, SkyC_7, SkyC_8, SkyC_9, SkyC_10, SkyC_11, SkyC_12))				swCloud_SkyCover(swRunScenariosData[[1]]) <- round(as.double(sky), 0)			}			#wind speed			if(sum(sw_input_cloud_use[grepl(pattern="wind", x=names(sw_input_cloud_use))]) > 0 | do.wind) {				swCloud_WindSpeed(swRunScenariosData[[1]]) <- round(as.double(wind), 2)			}			#relative humidity			if(sum(sw_input_cloud_use[grepl(pattern="RH", x=names(sw_input_cloud_use))]) > 0) {				rh <- with(i_sw_input_cloud, data.frame(RH_1, RH_2, RH_3, RH_4, RH_5, RH_6, RH_7, RH_8, RH_9, RH_10, RH_11, RH_12))				swCloud_Humidity(swRunScenariosData[[1]]) <- round(as.double(rh), 0)			}			#snow density			if(sum(sw_input_cloud_use[grepl(pattern="snowd", x=names(sw_input_cloud_use))]) > 0) {				snowd <- with(i_sw_input_cloud, data.frame(snowd_1, snowd_2, snowd_3, snowd_4, snowd_5, snowd_6, snowd_7, snowd_8, snowd_9, snowd_10, snowd_11, snowd_12))				if(i_SWRunInformation$Y_WGS84 < 0 && i_sw_input_cloud$SnowD_Hemisphere == "N" || i_SWRunInformation$Y_WGS84 > 0 && i_sw_input_cloud$SnowD_Hemisphere == "S"){	#adjust for hemisphere only if location and data are opposite					snowd <- c(snowd[7:12], snowd[1:6])				}				swCloud_SnowDensity(swRunScenariosData[[1]]) <- round(as.double(snowd), 1)			}		}		#add vegetation information	from datafile to prodin		if(print.debug) print("Start of prodin")		if(sum(sw_input_prod_use[-1]) > 0){			#composition			if(sum(use_comp <- unlist(sw_input_prod_use[grepl(pattern="Composition", x=names(sw_input_prod_use))])) > 0) {				comp.datfile <- with(i_sw_input_prod, data.frame(Composition_GrassFraction, Composition_ShrubFraction, Composition_TreeFraction, Composition_ForbFraction, Composition_BareGround))				comp.datfile[is.na(comp.datfile)]<-0				swRunScenariosData[[1]]@prod@Composition[1:5]<- as.numeric(comp.datfile[1:length(use_comp)])			}			#albedo			if(sum(use_albedo <- unlist(sw_input_prod_use[grepl(pattern="Albedo", x=names(sw_input_prod_use))])) > 0) {				albedo.datfile <- with(i_sw_input_prod, data.frame(Grass_Albedo, Shrub_Albedo, Tree_Albedo, Forb_Albedo, BareGround_Albedo))				swProd_Albedo(swRunScenariosData[[1]])[use_albedo] <- albedo.datfile[use_albedo]			}			#constant canopy height			if(sum(use_height <- unlist(sw_input_prod_use[grepl(pattern="CanopyHeight_Constant", x=names(sw_input_prod_use))])) > 0) {				height.datfile <- with(i_sw_input_prod, data.frame(Grass_CanopyHeight_Constant_cm, Shrub_CanopyHeight_Constant_cm, Tree_CanopyHeight_Constant_cm,Forb_CanopyHeight_Constant_cm))				height.datfile[is.na(height.datfile)]<-0				swRunScenariosData[[1]]@prod@CanopyHeight[5,] <- as.numeric(height.datfile[1:length(use_height)])			}			#flag for hydraulic redistribution			if(sum(use_HD <- unlist(sw_input_prod_use[grepl(pattern="HydRed", x=names(sw_input_prod_use))])) > 0) {				HD.datfile <- with(i_sw_input_prod, data.frame(Grass_HydRed_OnOff, Shrub_HydRed_OnOff, Tree_HydRed_OnOff, Forb_HydRed_OnOff))				swProd_HydrRedstro_use(swRunScenariosData[[1]])[use_HD] <- as.logical(HD.datfile[use_HD])			}			#biomass components TODO Check This			biomassComponents <- function(FunctGroup){				if(	sum(litt <- sw_input_prod_use[grepl(pattern=paste(FunctGroup, "_Litter", sep=""), x=names(sw_input_prod_use))]) +						sum(biom <- sw_input_prod_use[grepl(pattern=paste(FunctGroup, "_Biomass", sep=""), x=names(sw_input_prod_use))]) +						sum(live <- sw_input_prod_use[grepl(pattern=paste(FunctGroup, "_FractionLive", sep=""), x=names(sw_input_prod_use))]) +						sum(laiconv <- sw_input_prod_use[grepl(pattern=paste(FunctGroup, "_LAIconv", sep=""), x=names(sw_input_prod_use))])			> 0) {					for (m in st_mo){					  input_in_veg<-with(i_sw_input_prod,eval(parse(text=paste0("swRunScenariosData[[1]]@prod@MonthlyProductionValues_",tolower(FunctGroup),"[m,]"))))						mo.dat <- with(i_sw_input_prod, c(	ifelse(litt[m], eval(parse(text=paste(FunctGroup, "_Litter_m", m, sep=""))),input_in_veg[1]),						        ifelse(biom[m], eval(parse(text=paste(FunctGroup, "_Biomass_m", m, sep=""))), input_in_veg[2]),										ifelse(live[m], eval(parse(text=paste(FunctGroup, "_FractionLive_m", m, sep=""))), input_in_veg[3]),										ifelse(laiconv[m], eval(parse(text=paste(FunctGroup, "_LAIconv_m", m, sep=""))), input_in_veg[4])))						if(FunctGroup=="Grass")						swRunScenariosData[[1]]@prod@MonthlyProductionValues_grass[m,]  <- mo.dat						if(FunctGroup=="Shrub")						  swRunScenariosData[[1]]@prod@MonthlyProductionValues_shrub[m,]  <- mo.dat						if(FunctGroup=="Tree")						  swRunScenariosData[[1]]@prod@MonthlyProductionValues_tree[m,]  <- mo.dat						if(FunctGroup=="Forb")						  swRunScenariosData[[1]]@prod@MonthlyProductionValues_forb[m,]  <- mo.dat					}				}				if(FunctGroup=="Grass")					return(swProd_MonProd_grass(swRunScenariosData[[1]]))				if(FunctGroup=="Shrub")					return(swProd_MonProd_shrub(swRunScenariosData[[1]]))				if(FunctGroup=="Tree")					return(swProd_MonProd_tree(swRunScenariosData[[1]]))				if(FunctGroup=="Forb")					return(swProd_MonProd_forb(swRunScenariosData[[1]]))			}			swProd_MonProd_grass(swRunScenariosData[[1]]) <- biomassComponents(FunctGroup="Grass")			swProd_MonProd_shrub(swRunScenariosData[[1]]) <- biomassComponents(FunctGroup="Shrub")			swProd_MonProd_tree(swRunScenariosData[[1]])  <- biomassComponents(FunctGroup="Tree")			swProd_MonProd_forb(swRunScenariosData[[1]])  <- biomassComponents(FunctGroup="Forb")		}		#Moved adjust to southern Hemi		#add site information to siteparamin		if(print.debug) print("Start of siteparamin")		if(sum(sw_input_site_use[-1]) > 0){			site_swc_use <- as.logical(c(sw_input_site_use$SWC_min,sw_input_site_use$SWC_init,sw_input_site_use$SWC_wet))			if(any(site_swc_use)){				swSite_SWClimits(swRunScenariosData[[1]])[temp] <- c(i_sw_input_site$SWC_min,i_sw_input_site$SWC_init,i_sw_input_site$SWC_wet)[temp]			}			site_modelflag_use <- as.logical(c(sw_input_site_use$SWC_YearlyReset,sw_input_site_use$SWC_Deepdrain))			if(any(site_modelflag_use)){				swSite_ModelFlags(swRunScenariosData[[1]])[site_modelflag_use] <- c(i_sw_input_site$SWC_YearlyReset,i_sw_input_site$SWC_Deepdrain)[site_modelflag_use]			}			site_modelcoef_use <- as.logical(c(sw_input_site_use$PET_multiplier,sw_input_site_use$RunoffPercent_fromPondedWater))			if(any(site_modelcoef_use)){				swSite_ModelCoefficients(swRunScenariosData[[1]])[site_modelcoef_use] <- c(i_sw_input_site$PET_multiplier, i_sw_input_site$RunoffPercent_fromPondedWater)[site_modelcoef_use]			}			#replace if in treatment file			if(sw_input_site_use$Param_UnsaturatedPercolation){				swSite_DrainageCoefficient(swRunScenariosData[[1]]) <- i_sw_input_site$Param_UnsaturatedPercolation			}			if(sw_input_site_use$Latitude) {				swSite_IntrinsicSiteParams(swRunScenariosData[[1]])[1] <- i_sw_input_site$Latitude			}			if(sw_input_site_use$Altitude) {				swSite_IntrinsicSiteParams(swRunScenariosData[[1]])[2] <- i_sw_input_site$Altitude			}			if(sw_input_site_use$Slope){				swSite_IntrinsicSiteParams(swRunScenariosData[[1]])[3] <- i_sw_input_site$Slope			}			if(sw_input_site_use$Aspect){				swSite_IntrinsicSiteParams(swRunScenariosData[[1]])[4] <- i_sw_input_site$Aspect			}			#Moved sw_input_site_use$SoilTempC_atLowerBoundary			if(sw_input_site_use$SoilTemp_Flag){				swSite_SoilTemperatureFlag(swRunScenariosData[[1]]) <- i_sw_input_site$SoilTemp_Flag			}			rm(site_swc_use,site_modelflag_use,site_modelcoef_use)		}		swSite_IntrinsicSiteParams(swRunScenariosData[[1]])[1] <- i_SWRunInformation$Y_WGS84 * pi / 180		if(is.finite(i_SWRunInformation$ELEV_m))	swSite_IntrinsicSiteParams(swRunScenariosData[[1]])[2] <- i_SWRunInformation$ELEV_m		#add soil information to soilsin		if(print.debug) print("Start of soilsin")		done.Imperm_L1 <- FALSE		if(sw_input_soils_use$Imperm_L1 == 1 && any(create_treatments == "soilsin")){			tempdat <- swSoils_Layers(swRunScenariosData[[1]])			tempdat[1, "impermeability_frac"] <- i_sw_input_soils$Imperm_L1			swSoils_Layers(swRunScenariosData[[1]]) <- tempdat			done.Imperm_L1 <- TRUE		}		if(sum(sw_input_soils_use[-1] + ifelse(done.Imperm_L1, -1, 0)) - sum(use_transpregion <- as.numeric(sw_input_soils_use[paste("TranspRegion_L", ld, sep="")])) > 0){			tempdat <- matrix(data=NA, nrow=SoilLayer_MaxNo, ncol=12)			colnames(tempdat) <- c("depth", "matricd", "gravelContent", "evco", "trco_grass", "trco_shrub", "trco_tree", "trco_forb", "sand", "clay", "imperm", "soiltemp")			#recalculate soil layer structure, because any(create_treatments=="soilsin") and soilsin may have a different soil layer structure than the datafiles			layers_depth.datafile <- (temp <- as.numeric(na.omit(unlist(i_sw_input_soillayers[match(paste("depth_L", 1:SoilLayer_MaxNo, sep=""), colnames(i_sw_input_soillayers))]))))[temp <= as.numeric(i_sw_input_soillayers["SoilDepth_cm"])]			layers_depth.soilsin <- swSoils_Layers(swRunScenariosData[[1]])[,1]			mergeDatafileWithSoilsin <- FALSE			if(identical(layers_depth.datafile, layers_depth.soilsin)){	#same soil layer structure in soilsin and datafile => combine data				#soil texture data from SoilWat input file				tempdat <- swSoils_Layers(swRunScenariosData[[1]])				colnames(tempdat) <- c("depth", "matricd", "gravelContent", "evco", "trco_grass", "trco_shrub", "trco_tree", "trco_forb", "sand", "clay", "imperm", "soiltemp")#names might be diff				mergeDatafileWithSoilsin <- TRUE			} else { #different soil layer structure in soilsin and datafile AND since variables are flagged in sw_input_soils_use => use only datafile values				d <- max(1, min(length(layers_depth.datafile), findInterval(i_sw_input_soillayers$SoilDepth_cm - sqrt(.Machine$double.neg.eps), c(0, layers_depth.datafile)), na.rm=TRUE), na.rm=TRUE)				layers_depth <- adjustLayersDepth(layers_depth.datafile, d)				layers_width <- getLayersWidth(layers_depth)				ld <- setLayerSequence(d)				DeepestTopLayer <- setDeepestTopLayer(d)				topL <- setTopLayer(d)				bottomL <- setBottomLayer(d)			}			#flags for use of texture data from datafile			use_matricd <- as.numeric(sw_input_soils_use[paste("Matricd_L", ld, sep="")])			use_gravelC <- as.numeric(sw_input_soils_use[paste("GravelContent_L", ld, sep="")])			#use_pwp <- as.numeric(sw_input_soils_use[paste("WiltP_L", ld, sep="")])			sum_use_evco <- sum(sw_input_soils_use[paste("EvapCoeff_L", ld, sep="")])			sum_use_trco_grass <- sum(sw_input_soils_use[paste("Grass_TranspCoeff_L", ld, sep="")])			sum_use_trco_shrub <- sum(sw_input_soils_use[paste("Shrub_TranspCoeff_L", ld, sep="")])			sum_use_trco_tree <- sum(sw_input_soils_use[paste("Tree_TranspCoeff_L", ld, sep="")])			sum_use_trco_forb <- sum(sw_input_soils_use[paste("Forb_TranspCoeff_L", ld, sep="")])			use_sand <- as.numeric(sw_input_soils_use[paste("Sand_L", ld, sep="")])			use_clay <- as.numeric(sw_input_soils_use[paste("Clay_L", ld, sep="")])			use_imperm <- as.numeric(sw_input_soils_use[paste("Imperm_L", ld, sep="")])			if(mergeDatafileWithSoilsin || sum_use_evco > 0) EVCO_done <- TRUE			if(mergeDatafileWithSoilsin || (sum_use_trco_grass > 0 && sum_use_trco_shrub > 0 && sum_use_trco_tree > 0)) TRCO_done <- TRUE			#tr and ev coefficients data from datafile			evco <- as.numeric(i_sw_input_soils[paste("EvapCoeff_L", ld, sep="")])			trco_grass <- as.numeric(i_sw_input_soils[paste("Grass_TranspCoeff_L", ld, sep="")])			trco_shrub <- as.numeric(i_sw_input_soils[paste("Shrub_TranspCoeff_L", ld, sep="")])			trco_tree <- as.numeric(i_sw_input_soils[paste("Tree_TranspCoeff_L", ld, sep="")])			trco_forb <- as.numeric(i_sw_input_soils[paste("Forb_TranspCoeff_L", ld, sep="")])			#normalize transpiration and evaporation coefficients from datafile			if(sum_use_evco) evco <- evco / ifelse((temp <- sum(evco, na.rm=TRUE)) == 0 & is.na(temp), 1, temp)			if(sum_use_trco_grass) trco_grass <- trco_grass / ifelse((temp <- sum(trco_grass, na.rm=TRUE)) == 0 & is.na(temp), 1, temp)			if(sum_use_trco_shrub) trco_shrub <- trco_shrub / ifelse((temp <- sum(trco_shrub, na.rm=TRUE)) == 0 & is.na(temp), 1, temp)			if(sum_use_trco_tree) trco_tree <- trco_tree / ifelse((temp <- sum(trco_tree, na.rm=TRUE)) == 0 & is.na(temp), 1, temp)			if(sum_use_trco_forb) trco_forb <- trco_forb / ifelse((temp <- sum(trco_forb, na.rm=TRUE)) == 0 & is.na(temp), 1, temp)			#compile soil information from both sources			#changed ncol to 12, and added "soil_temp" to colnames...			soildat <- matrix(data=NA, nrow=d, ncol=12)			colnames(soildat) <- c("depth", "matricd", "gravelContent", "evco", "trco_grass", "trco_shrub", "trco_tree", "trco_forb", "sand", "clay", "imperm", "soiltemp")			for (l in ld){				soildat[l, ] <- c(	layers_depth.datafile[l],						ifelse(use_matricd[l], as.numeric(i_sw_input_soils[paste("Matricd_L", l, sep="")]), tempdat[l, "matricd"]),						ifelse(use_gravelC[l], as.numeric(i_sw_input_soils[paste("GravelContent_L", l, sep="")]), tempdat[l, "gravelContent"]),						ifelse(!is.na(temp <- ifelse(sum_use_evco, evco[l], tempdat[l, "evco"])), temp, 0),						ifelse(!is.na(temp <- ifelse(sum_use_trco_grass, trco_grass[l], tempdat[l, "trco_grass"])), temp, 0),						ifelse(!is.na(temp <- ifelse(sum_use_trco_shrub, trco_shrub[l], tempdat[l, "trco_shrub"])), temp, 0),						ifelse(!is.na(temp <- ifelse(sum_use_trco_tree, trco_tree[l], tempdat[l, "trco_tree"])), temp, 0),						ifelse(!is.na(temp <- ifelse(sum_use_trco_forb, trco_forb[l], tempdat[l, "trco_forb"])), temp, 0),						ifelse(use_sand[l], as.numeric(i_sw_input_soils[paste("Sand_L", l, sep="")]), tempdat[l, "sand"]),						ifelse(use_clay[l], as.numeric(i_sw_input_soils[paste("Clay_L", l, sep="")]), tempdat[l, "clay"]),						ifelse(!is.na(temp <- ifelse(use_imperm[l], as.numeric(i_sw_input_soils[paste("Imperm_L", l, sep="")]), tempdat[l, "imperm"])), temp, 0),						0	#soiltemp information may depend on climatic conditions; it will be only added after weather/climate scenarios are completed				)			}			if(adjust.soilDepth){#adjust deepest soil layer if there is no soil information for the lowest layers, but needs to recalculate soil layer structure				for(temp in d:1){					#TODO: bulkd to matricd?					if(all(!is.na(soildat[temp, "matricd"]), soildat[temp, "matricd"] > 0, !is.na(soildat[temp, "sand"]), soildat[temp, "sand"] > 0, !is.na(soildat[temp, "clay"]), soildat[temp, "clay"] > 0)) break				}				if(d != temp){					d <- temp					layers_depth <- adjustLayersDepth(layers_depth, d)					layers_width <- getLayersWidth(layers_depth)					ld <- setLayerSequence(d)					DeepestTopLayer <- setDeepestTopLayer(d)					topL <- setTopLayer(d)					bottomL <- setBottomLayer(d)				}			}			# Resize swSoils Layers to proper size			if(length(ld)==1) {				swSoils_Layers(swRunScenariosData[[1]]) <- matrix(data=swSoils_Layers(swRunScenariosData[[1]])[ld,], nrow=length(ld), ncol=12, byrow=TRUE, dimnames=list(numeric(),c("depth", "matricd", "gravelContent", "evco", "trco_grass", "trco_shrub", "trco_tree", "trco_forb", "sand", "clay", "imperm", "soiltemp")))			} else {				if(nrow(swSoils_Layers(swRunScenariosData[[1]])) != d) {					if(nrow(swSoils_Layers(swRunScenariosData[[1]])) > d) {						swSoils_Layers(swRunScenariosData[[1]]) <- swSoils_Layers(swRunScenariosData[[1]])[ld,]					} else {						swSoils_Layers(swRunScenariosData[[1]]) <- rbind( swSoils_Layers(swRunScenariosData[[1]]), matrix(NA,nrow=d-nrow(swSoils_Layers(swRunScenariosData[[1]])), ncol=ncol(swSoils_Layers(swRunScenariosData[[1]]))) )					}				}			}			this_soil <- soildat[1, ]			for (l in ld){				if(all(soildat[l, c("matricd", "sand", "clay")] > 0, soildat[l, "gravelContent"] >= 0, !is.na(soildat[l, ]))){					this_soil <- soildat[l, ]				} else {					#swLog_setLine(swRunScenariosData[[1]]) <- missingtext					print(paste("Site", i_sim, i_labels, ": Layer ",l,": soil data missing for this layer -> data used from previous layer */"))					this_soil <- c(soildat[l, "depth"], this_soil[2:3], soildat[l, "evco"], soildat[l, "trco_grass"], soildat[l, "trco_shrub"], soildat[l, "trco_tree"], soildat[l,"trco_forb"], this_soil[9:10], soildat[l, "imperm"], soildat[l, "soiltemp"])				}				swSoils_Layers(swRunScenariosData[[1]])[l,] <- this_soil			}		}		# Check soil		this_soil <- swSoils_Layers(swRunScenariosData[[1]])		temp <- this_soil[, grep("depth", colnames(this_soil), ignore.case = TRUE)]		check_depth <- !is.na(temp) & temp > 0 & diff(c(0, temp)) > 0		temp <- this_soil[, grep("density", colnames(this_soil), ignore.case = TRUE)]		check_density <- !is.na(temp) & temp > 0.3 & temp <= 2.65		temp <- this_soil[, grep("gravel", colnames(this_soil), ignore.case = TRUE)]		check_gravel <- !is.na(temp) & temp >= 0 & temp < 1		temp <- this_soil[, grep("sand", colnames(this_soil), ignore.case = TRUE)]		check_sand <- !is.na(temp) & temp > 0 & temp <= 1		temp <- this_soil[, grep("clay", colnames(this_soil), ignore.case = TRUE)]		check_clay <- !is.na(temp) & temp > 0 & temp <= 1#
		if (!all(check_depth, check_density, check_gravel, check_sand, check_clay)) {			print(paste("Run:", i_sim, i_labels, ": soil data didn't pass quality test."))			print(this_soil)			tasks$create <- 0		}#
		#add transpiration regions information to siteparamin		if(print.debug) print("Start of transpregion")		if(sum(use_transpregion) > 0){			tr <- max(tr.layers <- na.omit(as.numeric(i_sw_input_soils[paste("TranspRegion_L", ld, sep="")]))) # max transpiration region			TranspirationRegions <- matrix(data=NA,nrow=4,ncol=2)			colnames(TranspirationRegions)<-c("ndx","layer")			ltreg.last <- 0			for(tri in 1:4){				ltreg <- ifelse(length(ind <- which(tr.layers==tri)) > 0, max(ind), -1)				ltreg <- ifelse(ltreg>ltreg.last, ltreg, ltreg.last+1)				ltreg <- ifelse(ltreg>d & tri==1, d, ltreg)				if(tri <= tr & tri <= d & ltreg <= d | tri == 1) TranspirationRegions[tri,] <- as.integer(c(tri,ltreg))				ltreg.last <- ltreg			}			tr_rows<-rowSums(is.na(TranspirationRegions))!=2 #used to get rid of NA rows			if(sum(tr_rows) == 0) {				stop("Transpiration Regions in Site can not be empty")			} else if(sum(tr_rows) == 1) {				swSite_TranspirationRegions(swRunScenariosData[[1]]) <- matrix(data=TranspirationRegions[tr_rows,],nrow=1,ncol=2,byrow=T,dimnames=list(numeric(),c("ndx","layer")))				TRRG_done <- TRUE			} else {				swSite_TranspirationRegions(swRunScenariosData[[1]]) <- TranspirationRegions[tr_rows,]				TRRG_done <- TRUE			}		}		#add weather setup information to weatherin		if(sw_input_weather_use$SnowFlag)			swWeather_UseSnow(swRunScenariosData[[1]]) <- as.logical(i_sw_input_weather$SnowFlag)		if(sw_input_weather_use$SnowDrift_Percent)			swWeather_pct_SnowDrift(swRunScenariosData[[1]]) <- i_sw_input_weather$SnowDrift_Percent		if(sw_input_weather_use$RunOffOnPerSnowmelt_Percent)			swWeather_pct_SnowRunoff(swRunScenariosData[[1]]) <- i_sw_input_weather$RunOffOnPerSnowmelt_Percent		swWeather_FirstYearHistorical(swRunScenariosData[[1]]) <- simstartyr#
		swOUT_TimeStep(swRunScenariosData[[1]]) <- sapply(simulation_timescales, function(x) ifelse(x=="daily", 1, ifelse(x=="weekly", 2, ifelse(x=="monthly", 3, ifelse(x=="yearly",4,5)))) )-1		#############Get Weather Data################		if (print.debug) print("Start of daily weather")		i_sw_weatherList <- list()#
		.local_weatherDirName <- function(i_sim) {	# Get name of weather file from output database			con <<- DBI::dbConnect(RSQLite::SQLite(), dbname = name.OutputDB)			temp <- dbGetQuery(con, paste("SELECT WeatherFolder FROM header WHERE P_id=", it_Pid(i_sim, 1)))[1,1]			dbDisconnect(con)			temp		}
weather_label_cur <- try(.local_weatherDirName(i_sim), silent = TRUE)
weather_label_cur
inherits(weather_label_cur, "try-error")
dbW_setConnection(dbFilePath = dbWeatherDataFile)
i <- i_sim
# Extract weather data from db					dat <- list()					sn <- if (getScenarioWeatherDataFromDatabase) scenario_No else 1L					for (k in seq_len(sn)) {						dat[[k]] <- dbW_getWeatherData(Label = weather_label_cur,													startYear = simstartyr,													endYear = endyr,													Scenario = climate.conditions[k])					}
k
Label = weather_label_cur
startYear = simstartyr
endYear = endyr
Scenario = climate.conditions[k]
Scenario
